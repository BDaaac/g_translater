#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Telegram –±–æ—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ñ–∞–π–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TransGemini.py
"""

import os
import sys
import re
import tempfile
import asyncio
import logging
import subprocess
import zipfile
import uuid
from pathlib import Path
from typing import Dict, Any, Optional

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ Telegram
from telegram.error import BadRequest

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –µ—Å–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
def ensure_package(package_name, import_name=None):
    import_name = import_name or package_name
    try:
        __import__(import_name.split('.')[0])
    except ImportError:
        print(f"–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é {package_name}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package_name])

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã
ensure_package("python-telegram-bot==20.7")
ensure_package("google-generativeai", "google.generativeai")
ensure_package("python-docx", "docx")
ensure_package("beautifulsoup4", "bs4")
ensure_package("lxml")
ensure_package("PyQt6", "PyQt6")
ensure_package("ebooklib")

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Telegram
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, ContextTypes, filters
from telegram.constants import ParseMode

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ TransGemini.py
from TransGemini import (
    MODELS,
    OUTPUT_FORMATS,
    Worker,
    write_to_epub
)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º Google API –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–ª—é—á–∞
try:
    import google.generativeai as genai
    from google.api_core import exceptions as google_exceptions
except ImportError:
    genai = None
    google_exceptions = None

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤ (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç TransGemini.py)
SUPPORTED_FORMATS = {
    'txt': ['.txt'],
    'docx': ['.docx'], 
    'html': ['.html', '.htm'],
    'epub': ['.epub'],
    'xml': ['.xml'],
    'fb2': ['.fb2']
}

def get_possible_output_formats(input_format: str) -> list:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º OUTPUT_FORMATS –∏–∑ TransGemini.py
    available_formats = []
    for display_name, format_code in OUTPUT_FORMATS.items():
        # –¢–µ–ø–µ—Ä—å –≤–∫–ª—é—á–∞–µ–º EPUB –¥–ª—è –≤—Å–µ—Ö –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π
        if format_code in ['txt', 'docx', 'html', 'md', 'epub']:
            available_formats.append((display_name, format_code))
    return available_formats

def process_text_block_for_chapter_html(text_block: str) -> str:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è HTML, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞–∫ –≤ TransGemini"""
    from html import escape
    import re
    
    # –ó–∞—â–∏—â–∞–µ–º –∞–º–ø–µ—Ä—Å–∞–Ω–¥—ã
    text_block_escaped_amp = text_block.replace('&', '&amp;')
    
    # –ó–∞—â–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ <br/> —Ç–µ–≥–∏
    text_block_br_protected = re.sub(r'<br\s*/?>', '__TEMP_BR_TAG__', text_block_escaped_amp, flags=re.IGNORECASE)
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º < –∏ >
    text_block_lt_gt_escaped = text_block_br_protected.replace('<', '&lt;').replace('>', '&gt;')
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    temp_md_text = text_block_lt_gt_escaped
    temp_md_text = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', temp_md_text, flags=re.DOTALL)
    temp_md_text = re.sub(r'(?<!\*)\*(?!\*)(.*?)(?<!\*)\*(?!\*)', r'<em>\1</em>', temp_md_text, flags=re.DOTALL)
    temp_md_text = re.sub(r'`(.*?)`', r'<code>\1</code>', temp_md_text, flags=re.DOTALL)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ç–µ–≥–∏
    final_text = temp_md_text.replace('__TEMP_BR_TAG__', '<br/>')
    
    return final_text

def create_chapter_html(chapter_title: str, content: str, chapter_num: int) -> str:
    """–°–æ–∑–¥–∞–µ—Ç HTML –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –≥–ª–∞–≤—ã –≤ —Å—Ç–∏–ª–µ TransGemini —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
    from html import escape
    import re
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
    title_escaped = escape(chapter_title)
    
    # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç –º—É—Å–æ—Ä–Ω—ã—Ö —Ñ—Ä–∞–∑ AI
    content = clean_ai_response(content)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É)
    lines = content.splitlines()
    
    html_body_content = ""
    paragraph_buffer = []
    current_list_type = None
    in_code_block = False
    code_block_lines = []
    
    def flush_paragraph_buffer():
        """–û—á–∏—â–∞–µ—Ç –±—É—Ñ–µ—Ä –∞–±–∑–∞—Ü–∞ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –µ–≥–æ –≤ HTML"""
        nonlocal html_body_content, paragraph_buffer
        if paragraph_buffer:
            # –°–æ–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏ –∞–±–∑–∞—Ü–∞ —á–µ—Ä–µ–∑ <br/>
            para_content = process_text_block_for_chapter_html('<br/>'.join(paragraph_buffer))
            if para_content.strip():
                html_body_content += f"    <p>{para_content}</p>\n"
            paragraph_buffer = []
    
    def close_current_list():
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫"""
        nonlocal html_body_content, current_list_type
        if current_list_type:
            html_body_content += f"    </{current_list_type}>\n"
            current_list_type = None
    
    for line in lines:
        stripped_line = line.strip()
        is_code_fence = stripped_line == '```'
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
        if is_code_fence:
            if not in_code_block:
                flush_paragraph_buffer()
                close_current_list()
                in_code_block = True
                code_block_lines = []
            else:
                in_code_block = False
                escaped_code = escape("\n".join(code_block_lines))
                html_body_content += f"    <pre><code>{escaped_code}</code></pre>\n"
            continue
        
        if in_code_block:
            code_block_lines.append(line)
            continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        heading_match = re.match(r'^(#{1,6})\s+(.*)', stripped_line)
        hr_match = stripped_line == '---'
        ul_match = re.match(r'^[\*\-]\s+(.*)', stripped_line)
        ol_match = re.match(r'^\d+\.\s+(.*)', stripped_line)
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if current_list_type and not ((current_list_type == 'ul' and ul_match) or (current_list_type == 'ol' and ol_match)):
            close_current_list()
        
        # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –ø–µ—Ä–µ–¥ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏
        if paragraph_buffer and (heading_match or hr_match or ul_match or ol_match):
            flush_paragraph_buffer()
        
        if heading_match:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            level = len(heading_match.group(1))
            heading_text = process_text_block_for_chapter_html(heading_match.group(2).strip())
            if heading_text:
                html_body_content += f"    <h{level}>{heading_text}</h{level}>\n"
        elif hr_match:
            # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è
            html_body_content += "    <hr/>\n"
        elif ul_match:
            # –ù–µ—É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
            if current_list_type != 'ul':
                html_body_content += "    <ul>\n"
                current_list_type = 'ul'
            list_text = process_text_block_for_chapter_html(ul_match.group(1).strip())
            html_body_content += f"      <li>{list_text}</li>\n"
        elif ol_match:
            # –£–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
            if current_list_type != 'ol':
                html_body_content += "    <ol>\n"
                current_list_type = 'ol'
            list_text = process_text_block_for_chapter_html(ol_match.group(1).strip())
            html_body_content += f"      <li>{list_text}</li>\n"
        elif line.strip():
            # –û–±—ã—á–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ - –¥–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä –∞–±–∑–∞—Ü–∞
            paragraph_buffer.append(line)
        elif not stripped_line and paragraph_buffer:
            # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ - –∑–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â–∏–π –∞–±–∑–∞—Ü
            flush_paragraph_buffer()
    
    # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —ç–ª–µ–º–µ–Ω—Ç—ã
    close_current_list()
    flush_paragraph_buffer()
    
    if in_code_block:
        escaped_code = escape("\n".join(code_block_lines))
        html_body_content += f"    <pre><code>{escaped_code}</code></pre>\n"
    
    # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –ø—É—Å—Ç–æ–π, —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∞–±–∑–∞—Ü
    if not html_body_content.strip():
        processed_content = process_text_block_for_chapter_html(content.strip())
        html_body_content = f"    <p>{processed_content}</p>\n"
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π HTML –≤ —Å—Ç–∏–ª–µ TransGemini
    html_content = f'''<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title>{title_escaped}</title>
  <link rel="stylesheet" type="text/css" href="../style/default.css"/>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
</head>
<body>
  <h1>{title_escaped}</h1>
{html_body_content.rstrip()}
</body>
</html>'''
    
    return html_content

def clean_ai_response(content: str) -> str:
    """–û—á–∏—â–∞–µ—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ñ—Ä–∞–∑ AI"""
    try:
        # –°–ø–∏—Å–æ–∫ —Ñ—Ä–∞–∑, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –∏–∑ –Ω–∞—á–∞–ª–∞ —Ç–µ–∫—Å—Ç–∞
        ai_garbage_patterns = [
            r'^(?:–∫–æ–Ω–µ—á–Ω–æ[,!]?\s*)?–≤–æ—Ç\s+–ø–µ—Ä–µ–≤–æ–¥[:\s]*',
            r'^–≤–æ—Ç\s+–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π\s+—Ç–µ–∫—Å—Ç[:\s]*',
            r'^–ø–µ—Ä–µ–≤–æ–¥[:\s]*',
            r'^–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π\s+—Ç–µ–∫—Å—Ç[:\s]*',
            r'^–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ[:\s]*',
            r'^—Ä–µ–∑—É–ª—å—Ç–∞—Ç\s+–ø–µ—Ä–µ–≤–æ–¥–∞[:\s]*',
            r'^–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–∞—è\s+–≤–µ—Ä—Å–∏—è[:\s]*',
            r'^–≤–æ—Ç\s+—Ä–µ–∑—É–ª—å—Ç–∞—Ç[:\s]*',
            r'^–∫–æ–Ω–µ—á–Ω–æ[,!]?\s*',
            r'^–¥–∞[,!]?\s*–≤–æ—Ç\s*',
            r'^—Ö–æ—Ä–æ—à–æ[,!]?\s*',
            r'^–æ—Ç–ª–∏—á–Ω–æ[,!]?\s*',
            r'^–≥–æ—Ç–æ–≤–æ[,!]?\s*',
            r'^–≤–æ—Ç\s+–æ–Ω[:\s]*',
            r'^—Å–º–æ—Ç—Ä–∏[,!]?\s*',
            r'^–¥–µ—Ä–∂–∏[,!]?\s*',
            r'^–ø–æ–∂–∞–ª—É–π—Å—Ç–∞[,!]?\s*',
            r'^\*\*–ø–µ—Ä–µ–≤–æ–¥\*\*[:\s]*',
            r'^\*\*–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π\s+—Ç–µ–∫—Å—Ç\*\*[:\s]*',
            r'^here\s+is\s+the\s+translation[:\s]*',
            r'^translation[:\s]*',
            r'^translated\s+text[:\s]*',
            r'^of\s+course[,!]?\s*here\s*',
            r'^sure[,!]?\s*here\s*',
            r'^here\s+you\s+go[:\s]*',
            r'^–≤–æ—Ç\s+–∏\s+–≤—Å—ë[,!]?\s*',
            r'^–≥–æ—Ç–æ–≤–æ[,!]?\s*–≤–æ—Ç\s*'
        ]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –Ω–∞—á–∞–ª–∞
        cleaned_content = content.strip()
        for pattern in ai_garbage_patterns:
            cleaned_content = re.sub(pattern, '', cleaned_content, flags=re.IGNORECASE | re.MULTILINE)
            cleaned_content = cleaned_content.strip()
        
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –Ω–∞—á–∞–ª–µ
        while cleaned_content.startswith('\n'):
            cleaned_content = cleaned_content[1:]
        
        # –£–¥–∞–ª—è–µ–º markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
        cleaned_content = re.sub(r'^```[a-z]*\n?', '', cleaned_content, flags=re.MULTILINE)
        cleaned_content = re.sub(r'\n?```$', '', cleaned_content, flags=re.MULTILINE)
        
        # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        cleaned_content = re.sub(r'\n{3,}', '\n\n', cleaned_content)
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫
        cleaned_content = re.sub(r'^\s+', '', cleaned_content, flags=re.MULTILINE)
        
        if len(content) != len(cleaned_content):
            logger.info(f"üßπ –û—á–∏—â–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç: –±—ã–ª–æ {len(content)} —Å–∏–º–≤–æ–ª–æ–≤, —Å—Ç–∞–ª–æ {len(cleaned_content)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return cleaned_content.strip()
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ AI –æ—Ç–≤–µ—Ç–∞: {e}")
        return content

def smart_split_content(content: str, target_chapters: int) -> list:
    """–£–º–Ω–æ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –≥–ª–∞–≤—ã, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏–∞–ª–æ–≥–æ–≤ –∏ –∞–±–∑–∞—Ü–µ–≤"""
    try:
        logger.info(f"üìù –£–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤) –Ω–∞ {target_chapters} –≥–ª–∞–≤")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ —è–≤–Ω—ã–º –º–∞—Ä–∫–µ—Ä–∞–º –≥–ª–∞–≤
        chapter_patterns = [
            r'\n\s*(–ì–ª–∞–≤–∞|–ì–õ–ê–í–ê|Chapter|CHAPTER)\s+\d+',
            r'\n\s*(–ß–∞—Å—Ç—å|–ß–ê–°–¢–¨|Part|PART)\s+\d+',
            r'\n\s*\d+\.\s*[–ê-–ØA-Z]',
            r'\n\s*[IVX]+\.\s*[–ê-–ØA-Z]',
        ]
        
        for pattern in chapter_patterns:
            splits = re.split(pattern, content, flags=re.MULTILINE | re.IGNORECASE)
            if len(splits) > 1 and len(splits) <= target_chapters * 2:
                # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —á–∞—Å—Ç–∏ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
                chapters = []
                for i, part in enumerate(splits):
                    if part.strip():
                        chapters.append(part.strip())
                if len(chapters) >= 2:
                    logger.info(f"üìñ –†–∞–∑–¥–µ–ª–∏–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É –Ω–∞ {len(chapters)} —á–∞—Å—Ç–µ–π")
                    return chapters
        
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –Ω–∞–π—Ç–∏ —è–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã, —Ä–∞–∑–¥–µ–ª—è–µ–º –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–º –≥—Ä–∞–Ω–∏—Ü–∞–º
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫)
        
        # –ò—â–µ–º –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã (–¥–≤–æ–π–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫)
        sections = content.split('\n\n')
        
        if len(sections) <= target_chapters:
            # –°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Å–µ–∫—Ü–∏–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
            return [content]
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–µ–∫—Ü–∏–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É
        sections_per_chapter = max(1, len(sections) // target_chapters)
        chapters = []
        
        for i in range(0, len(sections), sections_per_chapter):
            chapter_sections = sections[i:i + sections_per_chapter]
            if chapter_sections:
                # –°–æ–µ–¥–∏–Ω—è–µ–º —Å–µ–∫—Ü–∏–∏ –æ–±—Ä–∞—Ç–Ω–æ –¥–≤–æ–π–Ω—ã–º–∏ –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                chapter_content = '\n\n'.join(sec.strip() for sec in chapter_sections if sec.strip())
                if chapter_content:
                    chapters.append(chapter_content)
        
        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è –≥–ª–∞–≤–∞ –ø–æ–ª—É—á–∏–ª–∞—Å—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–π, –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π
        if len(chapters) > 1 and len(chapters[-1]) < 200:  # –£–≤–µ–ª–∏—á–∏–ª–∏ –º–∏–Ω–∏–º—É–º
            chapters[-2] = chapters[-2] + '\n\n' + chapters[-1]
            chapters.pop()
        
        logger.info(f"üìù –†–∞–∑–¥–µ–ª–∏–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–º –≥—Ä–∞–Ω–∏—Ü–∞–º –Ω–∞ {len(chapters)} –≥–ª–∞–≤")
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞–∂–¥–æ–π –≥–ª–∞–≤—ã
        for i, chapter in enumerate(chapters[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            lines_count = len(chapter.split('\n'))
            paragraphs_count = len([p for p in chapter.split('\n\n') if p.strip()])
            logger.info(f"  –ì–ª–∞–≤–∞ {i+1}: {len(chapter)} —Å–∏–º–≤–æ–ª–æ–≤, {lines_count} —Å—Ç—Ä–æ–∫, {paragraphs_count} –∞–±–∑–∞—Ü–µ–≤")
        
        return chapters
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–º–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
        return [content]

def create_epub_from_original(original_epub_path: str, translated_content: str, output_path: str, title_override: str = None) -> bool:
    """
    –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è EPUB - —Ç–µ–ø–µ—Ä—å TransGemini.py –¥–µ–ª–∞–µ—Ç —ç—Ç–æ —Å–∞–º
    """
    logger.info("create_epub_from_original: TransGemini.py —Ç–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–µ—Ç EPUB —Ñ–∞–π–ª—ã –Ω–∞–ø—Ä—è–º—É—é")
    return False  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, —Ç–∞–∫ –∫–∞–∫ TransGemini —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª—ã —Å–∞–º
        
        from ebooklib import epub
        import uuid
        from html import escape
        from bs4 import BeautifulSoup
        import re
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–Ω–∏–≥—É
        book = epub.EpubBook()
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        book_title = title_override or Path(original_epub_path).stem
        book.set_identifier(f'urn:uuid:{uuid.uuid4()}')
        book.set_title(book_title)
        book.set_language('ru')
        book.add_author('Translator')
        
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É EPUB
        original_chapters = []
        try:
            with zipfile.ZipFile(original_epub_path, 'r') as epub_zip:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ HTML —Ñ–∞–π–ª—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ (–∫–∞–∫ –≤ TransGemini)
                html_files = sorted([
                    name for name in epub_zip.namelist()
                    if name.lower().endswith(('.html', '.xhtml', '.htm'))
                    and not name.startswith(('__MACOSX', 'META-INF/'))
                ])
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ—á–Ω—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é TransGemini –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≥–ª–∞–≤
                content_files = []
                TRANSLATED_SUFFIX = '_translated'
                
                for html_file in html_files:
                    filename_lower = Path(html_file).name.lower()
                    filename_base = Path(html_file).stem.split('.')[0].lower()
                    
                    # –°–ø–∏—Å–∫–∏ –∏–∑ TransGemini
                    skip_indicators = ['toc', 'nav', 'ncx', 'cover', 'title', 'index', 'copyright', 'about', 'meta', 'opf',
                                      'masthead', 'colophon', 'imprint', 'acknowledgments', 'dedication',
                                      'glossary', 'bibliography', 'notes', 'annotations', 'epigraph', 'halftitle',
                                      'frontmatter', 'backmatter', 'preface', 'introduction', 'appendix', 'biography',
                                      'isbn', 'legal', 'notice', 'otherbooks', 'prelims', 'team', 'promo', 'bonus']
                    
                    content_indicators = ['chapter', 'part', 'section', 'content', 'text', 'page', 'body', 'main', 'article',
                                        'chp', 'chap', 'prt', 'sec', 'glava', 'prologue', 'epilogue']
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞–∫ –≤ TransGemini
                    is_likely_skip = any(skip in filename_base for skip in skip_indicators)
                    parent_dir_lower = str(Path(html_file).parent).lower()
                    is_likely_skip = is_likely_skip or any(skip in parent_dir_lower for skip in ['toc', 'nav', 'meta', 'frontmatter', 'backmatter', 'index', 'notes'])
                    is_likely_content = any(indicator in filename_base for indicator in content_indicators)
                    is_chapter_like = (re.fullmatch(r'(ch|gl|chap|chapter|part|section|sec|glava)[\d_-]+.*', filename_base) or 
                                      re.fullmatch(r'[\d]+', filename_base) or 
                                      re.match(r'^[ivxlcdm]+$', filename_base))
                    is_translated = filename_base.endswith(TRANSLATED_SUFFIX)
                    
                    # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                    try:
                        file_info = epub_zip.getinfo(html_file)
                        file_size = file_info.file_size
                    except:
                        file_size = 0
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –≥–ª–∞–≤–æ–π (–∫–∞–∫ –≤ TransGemini)
                    if not is_likely_skip and not is_translated and file_size > 500:
                        if is_likely_content or is_chapter_like or ('text' in filename_base and file_size > 1000):
                            content_files.append({
                                'path': html_file,
                                'name': Path(html_file).name,
                                'title': Path(html_file).stem.split('.')[0],
                                'size': file_size,
                                'sort_key': html_file.lower()  # –î–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
                            })
                
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ –≥–ª–∞–≤ (–∫–∞–∫ –≤ TransGemini)
                content_files.sort(key=lambda x: x['sort_key'])
                original_chapters = content_files
                
                logger.info(f"üìñ –ù–∞–π–¥–µ–Ω–æ {len(original_chapters)} –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –≥–ª–∞–≤ –ø–æ –ª–æ–≥–∏–∫–µ TransGemini:")
                for i, ch in enumerate(original_chapters[:10]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                    logger.info(f"  {i+1}. {ch['name']} ({ch['size']} bytes)")
                        
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É: {e}")
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –≥–ª–∞–≤—ã
        chapters = [ch.strip() for ch in translated_content.split('--- –ì–õ–ê–í–ê ---') if ch.strip()]
        
        if not chapters:
            logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –º–∞—Ä–∫–µ—Ä–æ–≤ –≥–ª–∞–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
            target_chapters = len(original_chapters) if original_chapters else 5
            chapters = smart_split_content(translated_content, target_chapters)
        
        if not chapters:
            logger.warning("‚ö†Ô∏è –£–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å, —Å–æ–∑–¥–∞–µ–º –æ–¥–Ω—É –≥–ª–∞–≤—É")
            chapters = [translated_content.strip()]
        
        logger.info(f"üìö –ò—Ç–æ–≥–æ –≥–ª–∞–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è EPUB: {len(chapters)}")
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å —Ç–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ,
        # —É–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–ª–∞–≤ —Å–æ–≤–ø–∞–¥–∞–µ—Ç
        if original_chapters and len(original_chapters) > 0:
            if len(chapters) != len(original_chapters):
                logger.warning(f"‚ö†Ô∏è –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–ª–∞–≤: –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ {len(chapters)}, –æ—Ä–∏–≥–∏–Ω–∞–ª {len(original_chapters)}")
                
                # –ï—Å–ª–∏ —É –Ω–∞—Å –æ–¥–Ω–∞ –±–æ–ª—å—à–∞—è –≥–ª–∞–≤–∞, –∞ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–Ω–æ–≥–æ
                if len(chapters) == 1 and len(original_chapters) > 1:
                    logger.info("üìù –†–∞–∑–¥–µ–ª—è–µ–º –µ–¥–∏–Ω—ã–π –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ...")
                    chapters = smart_split_content(chapters[0], len(original_chapters))
                
                # –ï—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–ª–∞–≤ –±–ª–∏–∑–∫–æ, –Ω–æ –Ω–µ —Ç–æ—á–Ω–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç
                elif abs(len(chapters) - len(original_chapters)) <= 2:
                    logger.info(f"üìù –ë–ª–∏–∑–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–ª–∞–≤, –ø–æ–¥–≥–æ–Ω—è–µ–º –ø–æ–¥ –æ—Ä–∏–≥–∏–Ω–∞–ª ({len(original_chapters)} –≥–ª–∞–≤)")
                    if len(chapters) > len(original_chapters):
                        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ª–∏—à–Ω–∏–µ –≥–ª–∞–≤—ã
                        while len(chapters) > len(original_chapters):
                            chapters[-2] = chapters[-2] + '\n\n' + chapters[-1]
                            chapters.pop()
                    elif len(chapters) < len(original_chapters):
                        # –†–∞–∑–¥–µ–ª—è–µ–º –±–æ–ª—å—à–∏–µ –≥–ª–∞–≤—ã
                        while len(chapters) < len(original_chapters) and len(chapters) > 0:
                            # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—É—é –±–æ–ª—å—à—É—é –≥–ª–∞–≤—É –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º –µ—ë
                            max_idx = max(range(len(chapters)), key=lambda i: len(chapters[i]))
                            big_chapter = chapters[max_idx]
                            split_parts = smart_split_content(big_chapter, 2)
                            if len(split_parts) >= 2:
                                chapters[max_idx] = split_parts[0]
                                chapters.insert(max_idx + 1, split_parts[1])
                            else:
                                break
                
                logger.info(f"‚úÖ –ü–æ–¥–æ–≥–Ω–∞–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–ª–∞–≤: {len(chapters)} –≥–ª–∞–≤")
        
        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –º–∏–Ω–∏–º—É–º –æ–¥–Ω—É –≥–ª–∞–≤—É
        if not chapters:
            chapters = [translated_content.strip()]
        
        # –°–æ–∑–¥–∞–µ–º CSS —Å—Ç–∏–ª–∏ –≤ —Å—Ç–∏–ª–µ TransGemini —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –¥–∏–∞–ª–æ–≥–æ–≤
        default_css = epub.EpubItem(
            uid="default",
            file_name="style/default.css",
            media_type="text/css",
            content="""
body {
    font-family: "Times New Roman", Times, serif;
    font-size: 1em;
    line-height: 1.6;
    margin: 1em;
    text-align: justify;
    color: #333;
    background-color: #fdfdfd;
}

h1, h2, h3, h4, h5, h6 {
    text-align: center;
    margin: 1.8em 0 1em 0;
    font-weight: bold;
    page-break-after: avoid;
    line-height: 1.3;
    color: #111;
    border-bottom: 1px solid #eee;
    padding-bottom: 0.2em;
}

h1 { 
    font-size: 1.8em; 
    margin-bottom: 1.5em;
    border-bottom: 2px solid #333;
    padding-bottom: 0.5em;
}

h2 { font-size: 1.5em; }
h3 { font-size: 1.3em; }
h4 { font-size: 1.2em; }
h5 { font-size: 1.1em; }
h6 { font-size: 1em; }

p {
    margin: 0.5em 0 1em 0;
    text-indent: 0;
    orphans: 2;
    widows: 2;
    word-wrap: break-word;
}

/* –°—Ç–∏–ª—å –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤ - –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –æ—Ç—Å—Ç—É–ø–æ–º */
p br {
    line-height: 1.6;
}

/* –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫ */
br {
    display: block;
    margin: 0.2em 0;
    content: "";
}

.chapter-break {
    page-break-before: always;
}

blockquote {
    margin: 1em 2em;
    font-style: italic;
    border-left: 3px solid #ddd;
    padding-left: 1em;
}

em, i {
    font-style: italic;
}

strong, b {
    font-weight: bold;
}

code {
    background-color: #f0f0f0;
    padding: 0.1em 0.3em;
    border-radius: 3px;
    font-family: Consolas, Monaco, monospace;
    font-size: 0.9em;
}

pre {
    background-color: #f5f5f5;
    border: 1px solid #ddd;
    border-radius: 4px;
    padding: 1em;
    overflow-x: auto;
    white-space: pre-wrap;
    margin: 1em 0;
}

pre code {
    background-color: transparent;
    padding: 0;
    border-radius: 0;
    font-size: 0.9em;
}

ul, ol {
    margin: 1em 0;
    padding-left: 2em;
}

li {
    margin-bottom: 0.4em;
}

hr {
    border: none;
    border-top: 1px solid #ccc;
    margin: 2.5em 0;
}

/* –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å—Ç–∏–ª–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã */
.dialogue {
    text-indent: 0;
    margin-left: 1em;
}

.narrative {
    text-indent: 1.5em;
}
            """.strip()
        )
        book.add_item(default_css)
        
        # –°–æ–∑–¥–∞–µ–º –≥–ª–∞–≤—ã
        epub_chapters = []
        
        for i, chapter_content in enumerate(chapters):
            if not chapter_content.strip():
                continue
                
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≥–ª–∞–≤—ã - –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –Ω—É–º–µ—Ä–∞—Ü–∏—é
            chapter_title = f"–ì–ª–∞–≤–∞ {i+1}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –ø—É—Å—Ç–æ–π
            if not chapter_content.strip():
                logger.warning(f"‚õî –ü—Ä–æ–ø—É—â–µ–Ω–∞ –ø—É—Å—Ç–∞—è –≥–ª–∞–≤–∞: {chapter_title}")
                continue
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –æ—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –∫–∞–∂–¥–æ–π –≥–ª–∞–≤—ã –æ—Ç –æ—Å—Ç–∞—Ç–∫–æ–≤ AI –º—É—Å–æ—Ä–∞
            chapter_content = clean_ai_response(chapter_content)
            
            # –°–æ–∑–¥–∞–µ–º HTML –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –≥–ª–∞–≤—ã
            html_content = create_chapter_html(chapter_title, chapter_content, i+1)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ HTML –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –ø—É—Å—Ç–æ–π
            if not html_content.strip():
                logger.warning(f"‚õî –ü—Ä–æ–ø—É—â–µ–Ω–∞ –≥–ª–∞–≤–∞ —Å –ø—É—Å—Ç—ã–º HTML –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º: {chapter_title}")
                continue
            
            # –°–æ–∑–¥–∞–µ–º EPUB –≥–ª–∞–≤—É
            chapter = epub.EpubHtml(
                title=chapter_title,
                file_name=f'chapter_{i+1:03d}.xhtml',
                lang='ru'
            )
            chapter.content = html_content.encode('utf-8')
            
            book.add_item(chapter)
            epub_chapters.append(chapter)
            
            logger.info(f"üìÑ –°–æ–∑–¥–∞–Ω–∞ –≥–ª–∞–≤–∞ {i+1}: '{chapter_title}' ({len(chapter_content)} —Å–∏–º–≤–æ–ª–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞)")
        
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –≥–ª–∞–≤—ã
        if not epub_chapters:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –≥–ª–∞–≤—ã –∏–∑ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
            return False
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–Ω–∏–≥–∏
        book.toc = epub_chapters
        book.spine = ['nav'] + epub_chapters
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–≤–∏–≥–∞—Ü–∏—é
        book.add_item(epub.EpubNcx())
        book.add_item(epub.EpubNav())
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        output_dir = os.path.dirname(output_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º EPUB
        epub.write_epub(output_path, book, {})
        
        logger.info(f"‚úÖ EPUB —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {output_path} ({len(epub_chapters)} –≥–ª–∞–≤)")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è EPUB –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞: {e}", exc_info=True)
        return False


def create_epub_from_text(content: str, title: str, author: str, output_path: str, chapters_info: dict = None) -> bool:
    """
    –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è EPUB - —Ç–µ–ø–µ—Ä—å TransGemini.py –¥–µ–ª–∞–µ—Ç —ç—Ç–æ —Å–∞–º
    """
    logger.info("create_epub_from_text: TransGemini.py —Ç–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–µ—Ç EPUB —Ñ–∞–π–ª—ã –Ω–∞–ø—Ä—è–º—É—é")
    return False  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, —Ç–∞–∫ –∫–∞–∫ TransGemini —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª—ã —Å–∞–º

# –°–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
USER_STATES = {}

class UserState:
    def __init__(self):
        self.step = "waiting_file"  # waiting_file -> format_selection -> api_key -> chapter_selection -> translating
        self.file_path: Optional[str] = None
        self.file_name: Optional[str] = None
        self.file_format: Optional[str] = None
        self.output_format: Optional[str] = None
        self.api_key: Optional[str] = None
        self.target_language: str = "—Ä—É—Å—Å–∫–∏–π"
        self.model: str = list(MODELS.keys())[0] if MODELS else "Gemini 2.0 Flash"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
        self.start_chapter: int = 1
        self.chapter_count: int = 0  # 0 = –≤—Å–µ –≥–ª–∞–≤—ã
        self.total_chapters: int = 0  # –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞
        self.chapters_info: Optional[Dict[str, Any]] = None  # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥–ª–∞–≤–∞—Ö

def get_user_state(user_id: int) -> UserState:
    if user_id not in USER_STATES:
        USER_STATES[user_id] = UserState()
    return USER_STATES[user_id]

def reset_user_state(user_id: int):
    if user_id in USER_STATES:
        del USER_STATES[user_id]

def get_possible_output_formats_old(input_format: str) -> list:
    """–°—Ç–∞—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –∑–∞–º–µ–Ω–µ–Ω–∞ –Ω–∞ –≤–µ—Ä—Å–∏—é —Å OUTPUT_FORMATS"""
    if input_format in ['txt', 'docx', 'html', 'xml']:
        return ['txt', 'docx', 'html']
    elif input_format == 'epub':
        return ['txt', 'docx', 'html', 'epub']
    else:
        return ['txt']

def determine_input_format(file_extension: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é"""
    for fmt, extensions in SUPPORTED_FORMATS.items():
        if file_extension in extensions:
            return fmt
    return 'txt'  # fallback

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user_id = update.effective_user.id
    reset_user_state(user_id)
    
    welcome_message = """
ü§ñ **–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –±–æ—Ç –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞ —Ñ–∞–π–ª–æ–≤!**

–Ø –º–æ–≥—É –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É—è Google Gemini AI.

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:**
‚Ä¢ TXT - —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
‚Ä¢ DOCX - –¥–æ–∫—É–º–µ–Ω—Ç—ã Word
‚Ä¢ HTML - –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã
‚Ä¢ EPUB - —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏
‚Ä¢ XML - XML –¥–æ–∫—É–º–µ–Ω—Ç—ã

**–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
2. –í—ã–±–µ—Ä–∏—Ç–µ –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç
3. –í–≤–µ–¥–∏—Ç–µ API –∫–ª—é—á Google Gemini
4. –ü–æ–ª—É—á–∏—Ç–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª

–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å! üìÅ
    """
    
    await update.message.reply_text(
        welcome_message,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    user_id = update.effective_user.id
    state = get_user_state(user_id)
    
    if state.step != "waiting_file":
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≤–µ—Ä—à–∏—Ç–µ —Ç–µ–∫—É—â–∏–π –ø—Ä–æ—Ü–µ—Å—Å –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –Ω–∞—á–∞–ª–∞ –∑–∞–Ω–æ–≤–æ.")
        return
    
    document = update.message.document
    if not document:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª.")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–º–∞–∫—Å–∏–º—É–º 20MB –¥–ª—è Telegram)
    if document.file_size > 20 * 1024 * 1024:
        await update.message.reply_text("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 20MB")
        return
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
    file_name = document.file_name
    file_extension = Path(file_name).suffix.lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
    supported_extensions = {'.txt', '.docx', '.html', '.htm', '.epub', '.xml'}
    if file_extension not in supported_extensions:
        await update.message.reply_text(
            f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_extension}\n"
            f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(supported_extensions)}"
        )
        return
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        file = await context.bot.get_file(document.file_id)
        
        # –°–æ–∑–¥–∞–µ–º temporary —Ñ–∞–π–ª
        temp_dir = tempfile.mkdtemp()
        file_path = os.path.join(temp_dir, file_name)
        
        await file.download_to_drive(file_path)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
        state.file_format = determine_input_format(file_extension)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
        state.file_path = file_path
        state.file_name = file_name
        state.step = "format_selection"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        await show_format_selection(update, state)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")

async def show_format_selection(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã–±–æ—Ä –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É—è OUTPUT_FORMATS –∏–∑ TransGemini.py"""
    # –ü–æ–ª—É—á–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
    possible_formats = get_possible_output_formats(state.file_format)
    
    keyboard = []
    for display_name, format_code in possible_formats:
        keyboard.append([InlineKeyboardButton(display_name, callback_data=f"format_{format_code}")])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(
        f"üìÅ –§–∞–π–ª –ø–æ–ª—É—á–µ–Ω: `{state.file_name}`\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç:",
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_format_selection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ —Ñ–æ—Ä–º–∞—Ç–∞"""
    query = update.callback_query
    user_id = query.from_user.id
    state = get_user_state(user_id)
    
    if state.step != "format_selection":
        await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–π —à–∞–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    callback_data = query.data
    if not callback_data.startswith("format_"):
        await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        return
    
    selected_format = callback_data.replace("format_", "")
    state.output_format = selected_format
    state.step = "api_key"
    
    await query.answer()
    try:
        await query.edit_message_text(
            f"‚úÖ –í—ã–±—Ä–∞–Ω —Ñ–æ—Ä–º–∞—Ç: **{selected_format.upper()}**\n\n"
            f"–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à API –∫–ª—é—á Google Gemini.\n\n"
            f"**–ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á:**\n"
            f"1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ https://aistudio.google.com/\n"
            f"2. –í–æ–π–¥–∏—Ç–µ –≤ –∞–∫–∫–∞—É–Ω—Ç Google\n"
            f"3. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π API –∫–ª—é—á\n"
            f"4. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ–≥–æ –º–Ω–µ\n\n"
            f"‚ö° **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞:** –í–∞—à –∫–ª—é—á –±—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω –Ω–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –ø–µ—Ä–µ–≤–æ–¥–∞.\n\n"
            f"üîê –û—Ç–ø—Ä–∞–≤—å—Ç–µ API –∫–ª—é—á:",
            parse_mode=ParseMode.MARKDOWN
        )
    except BadRequest as e:
        if "Message is not modified" not in str(e):
            raise

async def handle_text_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user_id = update.effective_user.id
    state = get_user_state(user_id)
    
    if state.step == "api_key":
        await handle_api_key(update, context)
    elif state.step == "chapter_input":
        await handle_chapter_input(update, context)
    else:
        # –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        await update.message.reply_text(
            "ü§î –Ø –Ω–µ –ø–æ–Ω–∏–º–∞—é, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å.\n"
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã –∏–ª–∏ /help –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏."
        )

async def validate_api_key(api_key: str) -> tuple[bool, str]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞ —á–µ—Ä–µ–∑ Google Gemini API"""
    try:
        if not genai or not google_exceptions:
            return False, "Google API –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã"
            
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º API
        genai.configure(api_key=api_key)
        
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–ª—é—á–∞
        models = genai.list_models()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Gemini
        gemini_models = [m for m in models if m.name.startswith("models/")]
        
        if gemini_models:
            return True, "API –∫–ª—é—á –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω."
        else:
            return False, "–ö–ª—é—á –ø—Ä–∏–Ω—è—Ç API, –Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Gemini."
            
    except google_exceptions.Unauthenticated as e:
        return False, f"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–Ω–µ–≤–µ—Ä–Ω—ã–π –∫–ª—é—á): {str(e)}"
    except Exception as e:
        return False, f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ API –∫–ª—é—á–∞: {str(e)}"

async def handle_api_key(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ API –∫–ª—é—á–∞"""
    user_id = update.effective_user.id
    state = get_user_state(user_id)
    
    if state.step != "api_key":
        return
    
    api_key = update.message.text.strip()
    
    # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞
    if len(api_key) < 30 or not api_key.startswith('AI'):
        await update.message.reply_text(
            "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç API –∫–ª—é—á–∞.\n"
            "API –∫–ª—é—á –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å 'AI' –∏ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–º.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
        )
        return
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–ª—é—á–∞
    checking_message = await update.message.reply_text(
        "üîç **–ü—Ä–æ–≤–µ—Ä—è—é API –∫–ª—é—á...**\n\n"
        "‚è≥ –í—ã–ø–æ–ª–Ω—è—é —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ Google Gemini API...",
        parse_mode=ParseMode.MARKDOWN
    )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞
    is_valid, validation_message = await validate_api_key(api_key)
    
    if is_valid:
        # –ö–ª—é—á –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω
        state.api_key = api_key
        state.step = "chapter_selection"
        
        await checking_message.edit_text(
            "‚úÖ **API –∫–ª—é—á –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω!**\n\n"
            "üîë –ö–ª—é—á —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω\n"
            "üìù –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ñ–∞–π–ª –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≥–ª–∞–≤...",
            parse_mode=ParseMode.MARKDOWN
        )
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–ª–∞–≤
        await analyze_file_chapters(update, state)
        
    else:
        # –ö–ª—é—á –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω
        await checking_message.edit_text(
            "‚ùå **API –∫–ª—é—á –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω**\n\n"
            f"üö´ {validation_message}\n\n"
            "**–ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á:**\n"
            "1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ https://aistudio.google.com/\n"
            "2. –í–æ–π–¥–∏—Ç–µ –≤ –∞–∫–∫–∞—É–Ω—Ç Google\n"
            "3. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π API –∫–ª—é—á\n"
            "4. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ–≥–æ –º–Ω–µ\n\n"
            "üîê –û—Ç–ø—Ä–∞–≤—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π API –∫–ª—é—á:",
            parse_mode=ParseMode.MARKDOWN
        )

async def analyze_file_chapters(update: Update, state: UserState):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–ª–∞–≤"""
    try:
        chapters_found = 0
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É TransGemini
        if state.file_format == 'epub':
            transgemini_info = await get_transgemini_chapters_info(state.file_path, state.file_format)
            if transgemini_info['total_content'] > 0:
                chapters_found = transgemini_info['total_content']
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                state.chapters_info = transgemini_info
                logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Ç–æ—á–Ω–∞—è –ª–æ–≥–∏–∫–∞ TransGemini: –Ω–∞–π–¥–µ–Ω–æ {chapters_found} –≥–ª–∞–≤")
            else:
                # Fallback –∫ —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–µ
                chapters_found = await count_chapters_in_file(state.file_path, state.file_format)
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –ª–æ–≥–∏–∫—É
            chapters_found = await count_chapters_in_file(state.file_path, state.file_format)
        
        state.total_chapters = max(1, chapters_found)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–ø—Ü–∏–∏ –≤—ã–±–æ—Ä–∞ –≥–ª–∞–≤
        await show_chapter_selection(update, state)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≥–ª–∞–≤: {e}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ - —Å—Ä–∞–∑—É –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º –ø–µ—Ä–µ–≤–æ–¥–∞
        state.step = "translating"
        await show_translation_options(update, state)

async def get_transgemini_chapters_info(file_path: str, file_format: str) -> dict:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–ª–∞–≤–∞—Ö –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É TransGemini"""
    try:
        if file_format == 'epub':
            with zipfile.ZipFile(file_path, 'r') as epub_zip:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ HTML —Ñ–∞–π–ª—ã (–∫–∞–∫ –≤ TransGemini)
                html_files = sorted([
                    name for name in epub_zip.namelist()
                    if name.lower().endswith(('.html', '.xhtml', '.htm'))
                    and not name.startswith(('__MACOSX', 'META-INF/'))
                ])
                
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ NAV —Ñ–∞–π–ª (–∫–∞–∫ –≤ TransGemini)
                nav_path = None
                for html_file in html_files:
                    if 'nav' in Path(html_file).name.lower():
                        nav_path = html_file
                        break
                
                chapters_info = {
                    'all_files': [],
                    'content_files': [],
                    'skip_files': [],
                    'nav_file': nav_path,
                    'total_all': len(html_files),
                    'total_content': 0,
                    'original_path': file_path  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É EPUB
                }
                
                TRANSLATED_SUFFIX = '_translated'  # –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –∏–∑ TransGemini
                
                for file_path_in_epub in html_files:
                    try:
                        file_info = epub_zip.getinfo(file_path_in_epub)
                        file_size = file_info.file_size
                    except:
                        file_size = 0
                    
                    is_nav = (nav_path and file_path_in_epub == nav_path)
                    is_translated = Path(file_path_in_epub).stem.endswith(TRANSLATED_SUFFIX)
                    
                    file_data = {
                        'path': file_path_in_epub,
                        'name': Path(file_path_in_epub).name,
                        'size': file_size,
                        'is_nav': is_nav,
                        'is_translated': is_translated,
                        'is_selected': False,
                        'category': 'unknown'
                    }
                    
                    if is_nav:
                        file_data['category'] = 'nav'
                        file_data['is_selected'] = False
                        chapters_info['skip_files'].append(file_data)
                    else:
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É TransGemini –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
                        item_text_lower = file_path_in_epub.lower()
                        path = Path(item_text_lower)
                        filename_lower = path.name
                        filename_base = path.stem.split('.')[0]  # Get stem before first dot
                        
                        skip_indicators = ['toc', 'nav', 'ncx', 'cover', 'title', 'index', 'copyright', 'about', 'meta', 'opf',
                                          'masthead', 'colophon', 'imprint', 'acknowledgments', 'dedication',
                                          'glossary', 'bibliography', 'notes', 'annotations', 'epigraph', 'halftitle',
                                          'frontmatter', 'backmatter', 'preface', 'introduction', 'appendix', 'biography',
                                          'isbn', 'legal', 'notice', 'otherbooks', 'prelims', 'team', 'promo', 'bonus']
                        content_indicators = ['chapter', 'part', 'section', 'content', 'text', 'page', 'body', 'main', 'article',
                                            'chp', 'chap', 'prt', 'sec', 'glava', 'prologue', 'epilogue']
                        
                        is_likely_skip = any(skip in filename_base for skip in skip_indicators)
                        parent_dir_lower = str(path.parent).lower()
                        is_likely_skip = is_likely_skip or any(skip in parent_dir_lower for skip in ['toc', 'nav', 'meta', 'frontmatter', 'backmatter', 'index', 'notes'])
                        is_likely_content = any(indicator in filename_base for indicator in content_indicators)
                        is_chapter_like = (re.fullmatch(r'(ch|gl|chap|chapter|part|section|sec|glava)[\d_-]+.*', filename_base) or 
                                          re.fullmatch(r'[\d]+', filename_base) or 
                                          re.match(r'^[ivxlcdm]+$', filename_base))
                        
                        if not is_likely_skip and (is_likely_content or is_chapter_like):
                            file_data['category'] = 'content'
                            file_data['is_selected'] = True
                            chapters_info['content_files'].append(file_data)
                        else:
                            if not is_likely_skip and 'text' in filename_base:
                                file_data['category'] = 'text'
                                file_data['is_selected'] = True
                                chapters_info['content_files'].append(file_data)
                            else:
                                file_data['category'] = 'skip'
                                file_data['is_selected'] = False
                                chapters_info['skip_files'].append(file_data)
                    
                    chapters_info['all_files'].append(file_data)
                
                chapters_info['total_content'] = len(chapters_info['content_files'])
                logger.info(f"TransGemini –∞–Ω–∞–ª–∏–∑ EPUB: {chapters_info['total_content']} –≥–ª–∞–≤ –∏–∑ {chapters_info['total_all']} —Ñ–∞–π–ª–æ–≤")
                return chapters_info
                
        return {'total_all': 0, 'total_content': 0, 'all_files': [], 'content_files': [], 'skip_files': [], 'nav_file': None}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ TransGemini –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return {'total_all': 0, 'total_content': 0, 'all_files': [], 'content_files': [], 'skip_files': [], 'nav_file': None}

async def get_chapters_info(file_path: str, file_format: str) -> dict:
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–ª–∞–≤–∞—Ö –≤ —Ñ–∞–π–ª–µ"""
    try:
        if file_format == 'epub':
            with zipfile.ZipFile(file_path, 'r') as epub_zip:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ HTML —Ñ–∞–π–ª—ã
                all_html_files = sorted([
                    name for name in epub_zip.namelist()
                    if name.lower().endswith(('.html', '.xhtml', '.htm'))
                    and not name.startswith(('__MACOSX', 'META-INF/'))
                ])
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
                chapters_info = {
                    'all_files': [],
                    'content_files': [],
                    'skip_files': [],
                    'total_all': len(all_html_files),
                    'total_content': 0,
                    'original_path': file_path  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É EPUB
                }
                
                skip_indicators = [
                    'toc', 'nav', 'ncx', 'cover', 'title', 'index', 'copyright', 'about', 'meta', 'opf',
                    'masthead', 'colophon', 'imprint', 'acknowledgments', 'dedication',
                    'glossary', 'bibliography', 'notes', 'annotations', 'epigraph', 'halftitle',
                    'frontmatter', 'backmatter', 'preface', 'introduction', 'appendix', 'biography',
                    'isbn', 'legal', 'notice', 'otherbooks', 'prelims', 'team', 'promo', 'bonus'
                ]
                
                for html_file in all_html_files:
                    filename_base = Path(html_file).stem.split('.')[0].lower()
                    
                    try:
                        file_info = epub_zip.getinfo(html_file)
                        file_size = file_info.file_size
                    except:
                        file_size = 0
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª —Å–ª—É–∂–µ–±–Ω—ã–º
                    is_skip_file = any(skip_word in filename_base for skip_word in skip_indicators)
                    is_translated = filename_base.endswith('_translated')
                    
                    file_data = {
                        'path': html_file,
                        'name': Path(html_file).name,
                        'size': file_size,
                        'is_skip': is_skip_file,
                        'is_translated': is_translated
                    }
                    
                    chapters_info['all_files'].append(file_data)
                    
                    if not is_skip_file and not is_translated and file_size > 500:
                        chapters_info['content_files'].append(file_data)
                    else:
                        chapters_info['skip_files'].append(file_data)
                
                chapters_info['total_content'] = len(chapters_info['content_files'])
                return chapters_info
                
        return {'total_all': 0, 'total_content': 0, 'all_files': [], 'content_files': [], 'skip_files': []}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≥–ª–∞–≤: {e}")
        return {'total_all': 0, 'total_content': 0, 'all_files': [], 'content_files': [], 'skip_files': []}

async def count_chapters_in_file(file_path: str, file_format: str) -> int:
    """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–ª–∞–≤ –≤ —Ñ–∞–π–ª–µ"""
    try:
        if file_format == 'txt':
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
            content = ""
            encodings = ['utf-8', 'cp1251', 'latin-1', 'cp866']
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    break
                except UnicodeDecodeError:
                    continue
            else:
                # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–æ–≥–ª–æ, —á–∏—Ç–∞–µ–º –≤ –±–∏–Ω–∞—Ä–Ω–æ–º —Ä–µ–∂–∏–º–µ
                with open(file_path, 'rb') as f:
                    raw_content = f.read()
                    content = raw_content.decode('utf-8', errors='ignore')
            
            # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≥–ª–∞–≤
            import re
            patterns = [
                r'^\s*(–ì–ª–∞–≤–∞|Chapter|–ì–õ–ê–í–ê|CHAPTER)\s+\d+',
                r'^\s*(–ß–∞—Å—Ç—å|Part|–ß–ê–°–¢–¨|PART)\s+\d+',
                r'^\s*\d+\.\s*[–ê-–ØA-Z]',
                r'^#{1,3}\s+',  # Markdown –∑–∞–≥–æ–ª–æ–≤–∫–∏
            ]
            
            total_matches = 0
            for pattern in patterns:
                matches = re.findall(pattern, content, re.MULTILINE | re.IGNORECASE)
                total_matches = max(total_matches, len(matches))
            
            return max(1, total_matches)
                
        elif file_format == 'docx':
            # –î–ª—è DOCX –∏—Å–ø–æ–ª—å–∑—É–µ–º python-docx
            try:
                from docx import Document
                doc = Document(file_path)
                chapter_count = 0
                
                for para in doc.paragraphs:
                    text = para.text.strip()
                    if text and (
                        text.lower().startswith(('–≥–ª–∞–≤–∞', 'chapter', '—á–∞—Å—Ç—å', 'part')) or
                        para.style.name.startswith('Heading')
                    ):
                        chapter_count += 1
                
                return max(1, chapter_count)
            except ImportError:
                return 5  # Fallback –µ—Å–ª–∏ docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
                
        elif file_format == 'html':
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è HTML
            content = ""
            encodings = ['utf-8', 'cp1251', 'latin-1']
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    break
                except UnicodeDecodeError:
                    continue
            else:
                with open(file_path, 'rb') as f:
                    raw_content = f.read()
                    content = raw_content.decode('utf-8', errors='ignore')
            
            import re
            # –ò—â–µ–º HTML –∑–∞–≥–æ–ª–æ–≤–∫–∏
            headers = re.findall(r'<h[1-6][^>]*>(.*?)</h[1-6]>', content, re.IGNORECASE | re.DOTALL)
            return max(1, len(headers))
        
        elif file_format == 'epub':
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É TransGemini.py –¥–ª—è EPUB —Ñ–∞–π–ª–æ–≤
            try:
                chapter_count = 0
                with zipfile.ZipFile(file_path, 'r') as epub_zip:
                    # –ü–æ–ª—É—á–∞–µ–º HTML —Ñ–∞–π–ª—ã —Ç–∞–∫ –∂–µ, –∫–∞–∫ –≤ TransGemini
                    html_files_in_epub = sorted([
                        name for name in epub_zip.namelist()
                        if name.lower().endswith(('.html', '.xhtml', '.htm'))
                        and not name.startswith(('__MACOSX', 'META-INF/'))  # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–∞–ø–∫–∏
                    ])
                    
                    if not html_files_in_epub:
                        logger.warning(f"–í EPUB —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ HTML/XHTML —Ñ–∞–π–ª–æ–≤")
                        return 5
                    
                    logger.info(f"–í—Å–µ–≥–æ HTML —Ñ–∞–π–ª–æ–≤ –≤ EPUB: {len(html_files_in_epub)}")
                    for html_file in html_files_in_epub:
                        logger.debug(f"HTML —Ñ–∞–π–ª: {html_file}")
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –≥–ª–∞–≤—ã, –∏—Å–∫–ª—é—á–∞—è —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã (–∫–∞–∫ –≤ TransGemini)
                    content_files = []
                    for file_path_in_epub in html_files_in_epub:
                        filename_lower = Path(file_path_in_epub).name.lower()
                        filename_base = Path(file_path_in_epub).stem.split('.')[0].lower()
                        
                        # –°–ø–∏—Å–æ–∫ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–∫–∞–∫ –≤ TransGemini)
                        skip_indicators = [
                            'toc', 'nav', 'ncx', 'cover', 'title', 'index', 'copyright', 'about', 'meta', 'opf',
                            'masthead', 'colophon', 'imprint', 'acknowledgments', 'dedication',
                            'glossary', 'bibliography', 'notes', 'annotations', 'epigraph', 'halftitle',
                            'frontmatter', 'backmatter', 'preface', 'introduction', 'appendix', 'biography',
                            'isbn', 'legal', 'notice', 'otherbooks', 'prelims', 'team', 'promo', 'bonus'
                        ]
                        
                        # –°–ø–∏—Å–æ–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–≥–ª–∞–≤—ã)
                        content_indicators = [
                            'chapter', 'part', 'section', 'content', 'text', 'page', 'body', 'main', 'article',
                            'chp', 'chap', 'prt', 'sec', 'glava', 'prologue', 'epilogue'
                        ]
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª —Å–ª—É–∂–µ–±–Ω—ã–º
                        is_skip_file = any(skip_word in filename_base for skip_word in skip_indicators)
                        is_content_file = any(content_word in filename_base for content_word in content_indicators)
                        
                        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º _translated
                        is_translated = filename_base.endswith('_translated')
                        
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –∏—Å–∫–ª—é—á–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ HTML —Ñ–∞–π–ª—ã (–º–µ–Ω–µ–µ 1KB)
                        try:
                            file_info = epub_zip.getinfo(file_path_in_epub)
                            file_size = file_info.file_size
                        except:
                            file_size = 0
                        
                        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å–ª—É–∂–µ–±–Ω—ã–π –∏ –Ω–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π, –∏ –∏–º–µ–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                        if not is_skip_file and not is_translated and file_size > 1000:
                            content_files.append(file_path_in_epub)
                            logger.debug(f"–ù–∞–π–¥–µ–Ω–∞ –≥–ª–∞–≤–∞: {file_path_in_epub} (—Ä–∞–∑–º–µ—Ä: {file_size} –±–∞–π—Ç)")
                        else:
                            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª: {file_path_in_epub} (—Å–ª—É–∂–µ–±–Ω—ã–π: {is_skip_file}, –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π: {is_translated}, —Ä–∞–∑–º–µ—Ä: {file_size})")
                    
                    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å –º–∞–ª–æ —Ñ–∞–π–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
                    if len(content_files) < 3:
                        logger.info("–ú–∞–ª–æ –≥–ª–∞–≤ –ø–æ—Å–ª–µ —Å—Ç—Ä–æ–≥–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –ø—Ä–∏–º–µ–Ω—è–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏")
                        content_files = []
                        for file_path_in_epub in html_files_in_epub:
                            filename_lower = Path(file_path_in_epub).name.lower()
                            filename_base = Path(file_path_in_epub).stem.split('.')[0].lower()
                            
                            # –ë–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                            skip_indicators_short = ['toc', 'nav', 'cover', 'title', 'copyright', 'meta', 'opf']
                            is_skip_file = any(skip_word in filename_base for skip_word in skip_indicators_short)
                            is_translated = filename_base.endswith('_translated')
                            
                            try:
                                file_info = epub_zip.getinfo(file_path_in_epub)
                                file_size = file_info.file_size
                            except:
                                file_size = 0
                            
                            if not is_skip_file and not is_translated and file_size > 500:
                                content_files.append(file_path_in_epub)
                    
                    chapter_count = len(content_files)
                    logger.info(f"EPUB –∞–Ω–∞–ª–∏–∑: –Ω–∞–π–¥–µ–Ω–æ {chapter_count} –≥–ª–∞–≤ –∏–∑ {len(html_files_in_epub)} HTML —Ñ–∞–π–ª–æ–≤")
                    
                    return max(1, chapter_count)
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ EPUB: {e}")
                # Fallback: –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ñ–∞–π–ª
                try:
                    # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ EPUB —á–∏—Ç–∞—é—Ç—Å—è –∫–∞–∫ —Ç–µ–∫—Å—Ç
                    encodings = ['utf-8', 'cp1251', 'latin-1']
                    for encoding in encodings:
                        try:
                            with open(file_path, 'r', encoding=encoding) as f:
                                content = f.read()
                                patterns = [
                                    r'(?:chapter|–≥–ª–∞–≤–∞|—á–∞—Å—Ç—å)\s*\d+',
                                    r'<h[1-6][^>]*>.*?</h[1-6]>',
                                ]
                                total_matches = 0
                                for pattern in patterns:
                                    matches = re.findall(pattern, content, re.IGNORECASE)
                                    total_matches = max(total_matches, len(matches))
                                if total_matches > 0:
                                    return total_matches
                            break
                        except UnicodeDecodeError:
                            continue
                except:
                    pass
                
                return 20  # –†–∞–∑—É–º–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –∫–Ω–∏–≥
        
        return 5  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ –≥–ª–∞–≤: {e}")
        return 5

async def show_chapter_selection(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–ø—Ü–∏–∏ –≤—ã–±–æ—Ä–∞ –≥–ª–∞–≤"""
    keyboard = [
        [InlineKeyboardButton("üìñ –í—Å–µ –≥–ª–∞–≤—ã", callback_data="chapters_all")],
        [InlineKeyboardButton("üî¢ –í—ã–±—Ä–∞—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω", callback_data="chapters_range")],
        [InlineKeyboardButton("üìã –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –≥–ª–∞–≤—ã", callback_data="show_all_chapters")],
        [InlineKeyboardButton("‚ñ∂Ô∏è –ü–µ—Ä–µ–π—Ç–∏ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º", callback_data="skip_chapters")]
    ]
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    chapter_info = ""
    if state.total_chapters > 1:
        chapter_info = f"üìä –í —Ñ–∞–π–ª–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–∏–º–µ—Ä–Ω–æ **{state.total_chapters} –≥–ª–∞–≤/—Ä–∞–∑–¥–µ–ª–æ–≤**\n\n"
    
    await update.message.reply_text(
        f"üìö **–í—ã–±–æ—Ä –≥–ª–∞–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
        f"{chapter_info}"
        f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
        f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é:",
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN
    )

async def show_all_chapters(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≥–ª–∞–≤—ã –≤ —Ñ–∞–π–ª–µ"""
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º –Ω–æ–≤—É—é
        chapters_info = getattr(state, 'chapters_info', None)
        if not chapters_info:
            chapters_info = await get_transgemini_chapters_info(state.file_path, state.file_format)
            state.chapters_info = chapters_info
        
        if chapters_info['total_all'] == 0:
            try:
                await update.edit_message_text(
                    "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–ª–∞–≤—ã –≤ —Ñ–∞–π–ª–µ.",
                    reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_chapter_selection")]])
                )
            except BadRequest as e:
                if "Message is not modified" not in str(e):
                    raise
            return
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å–æ —Å–ø–∏—Å–∫–æ–º –≥–ª–∞–≤
        message_text = f"üìã **–ê–Ω–∞–ª–∏–∑ –≥–ª–∞–≤ (TransGemini –ª–æ–≥–∏–∫–∞)**\n\n"
        message_text += f"üìÅ –§–∞–π–ª: `{state.file_name}`\n\n"
        message_text += f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**\n"
        message_text += f"‚Ä¢ –í—Å–µ–≥–æ HTML —Ñ–∞–π–ª–æ–≤: `{chapters_info['total_all']}`\n"
        message_text += f"‚Ä¢ –ì–ª–∞–≤—ã –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞: `{chapters_info['total_content']}`\n"
        message_text += f"‚Ä¢ –°–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã: `{len(chapters_info['skip_files'])}`\n"
        if chapters_info['nav_file']:
            message_text += f"‚Ä¢ NAV —Ñ–∞–π–ª (–æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ): `{Path(chapters_info['nav_file']).name}`\n"
        message_text += "\n"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥–ª–∞–≤—ã —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è (—Ç–µ, —á—Ç–æ –±—É–¥—É—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã)
        if chapters_info['content_files']:
            message_text += f"‚úÖ **–ì–ª–∞–≤—ã –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ ({len(chapters_info['content_files'])}):**\n"
            for i, file_data in enumerate(chapters_info['content_files'][:20], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 20
                size_kb = file_data['size'] // 1024 if file_data['size'] > 0 else 0
                category_emoji = {"content": "üìñ", "text": "üìÑ"}.get(file_data['category'], "üìÑ")
                message_text += f"{i}. {category_emoji} `{file_data['name']}` ({size_kb}KB)\n"
            
            if len(chapters_info['content_files']) > 20:
                message_text += f"... –∏ –µ—â–µ {len(chapters_info['content_files']) - 20} –≥–ª–∞–≤\n"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã (–ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ)
        if chapters_info['skip_files']:
            message_text += f"\nüö´ **–°–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã ({len(chapters_info['skip_files'])}):**\n"
            for file_data in chapters_info['skip_files'][:8]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 8
                size_kb = file_data['size'] // 1024 if file_data['size'] > 0 else 0
                category_emoji = {"nav": "üß≠", "skip": "‚è≠Ô∏è"}.get(file_data['category'], "‚ùì")
                reason = {"nav": "–Ω–∞–≤–∏–≥–∞—Ü–∏—è", "skip": "—Å–ª—É–∂–µ–±–Ω—ã–π"}.get(file_data['category'], "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                message_text += f"‚Ä¢ {category_emoji} `{file_data['name']}` ({size_kb}KB) - {reason}\n"
            
            if len(chapters_info['skip_files']) > 8:
                message_text += f"... –∏ –µ—â–µ {len(chapters_info['skip_files']) - 8} —Ñ–∞–π–ª–æ–≤\n"
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–ª–∞–≤ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è EPUB —Ñ–∞–π–ª–æ–≤
        # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        if state.file_format == 'epub' and chapters_info['total_content'] > 0:
            state.total_chapters = chapters_info['total_content']
        # –î–ª—è –Ω–µ-EPUB —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ EPUB –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        
        keyboard = [
            [InlineKeyboardButton(f"üìñ –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –≤—Å–µ {chapters_info['total_content']} –≥–ª–∞–≤", callback_data="chapters_all")],
            [InlineKeyboardButton("üî¢ –í—ã–±—Ä–∞—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω", callback_data="chapters_range")],
            [InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_chapter_selection")]
        ]
        
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        try:
            await update.edit_message_text(
                message_text,
                reply_markup=reply_markup,
                parse_mode=ParseMode.MARKDOWN
            )
        except BadRequest as e:
            if "Message is not modified" not in str(e):
                raise
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∫–∞–∑–∞ –≥–ª–∞–≤: {e}")
        try:
            await update.edit_message_text(
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≥–ª–∞–≤: {str(e)}",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_chapter_selection")]])
            )
        except BadRequest as e2:
            if "Message is not modified" not in str(e2):
                raise

async def handle_chapter_selection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –≥–ª–∞–≤"""
    query = update.callback_query
    user_id = query.from_user.id
    state = get_user_state(user_id)
    
    if state.step != "chapter_selection":
        await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–π —à–∞–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞")
        return
    
    callback_data = query.data
    
    if callback_data == "chapters_all":
        state.start_chapter = 1
        state.chapter_count = 0  # 0 = –≤—Å–µ –≥–ª–∞–≤—ã
        state.step = "translating"
        
        await query.answer("–í—ã–±—Ä–∞–Ω—ã –≤—Å–µ –≥–ª–∞–≤—ã")
        await show_translation_options(query, state)
        
    elif callback_data == "chapters_range":
        await query.answer()
        await show_chapter_range_input(query, state)
        
    elif callback_data == "show_all_chapters":
        await query.answer()
        await show_all_chapters(query, state)
        
    elif callback_data == "skip_chapters":
        state.step = "translating"
        await query.answer()
        await show_translation_options(query, state)
        
    elif callback_data == "back_to_chapter_selection":
        await query.answer()
        await show_chapter_selection(query, state)

async def show_chapter_range_input(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤–≤–æ–¥–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≥–ª–∞–≤"""
    keyboard = []
    
    # –ë—ã—Å—Ç—Ä—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–±–æ—Ä–∞
    if state.total_chapters >= 5:
        keyboard.extend([
            [
                InlineKeyboardButton("1-5 –≥–ª–∞–≤", callback_data="range_1_5"),
                InlineKeyboardButton("6-10 –≥–ª–∞–≤", callback_data="range_6_10")
            ],
            [
                InlineKeyboardButton("11-15 –≥–ª–∞–≤", callback_data="range_11_15"),
                InlineKeyboardButton("16-20 –≥–ª–∞–≤", callback_data="range_16_20")
            ]
        ])
    
    # –ö–Ω–æ–ø–∫–∏ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞
    keyboard.extend([
        [InlineKeyboardButton("‚úèÔ∏è –í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é", callback_data="range_manual")],
        [InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_chapters")]
    ])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.edit_message_text(
        f"üî¢ **–í—ã–±–æ—Ä –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≥–ª–∞–≤**\n\n"
        f"üìä –í—Å–µ–≥–æ –≥–ª–∞–≤ –≤ —Ñ–∞–π–ª–µ: `{state.total_chapters}`\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ –≤—Ä—É—á–Ω—É—é:",
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_chapter_range_selection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≥–ª–∞–≤"""
    query = update.callback_query
    user_id = query.from_user.id
    state = get_user_state(user_id)
    
    callback_data = query.data
    
    if callback_data.startswith("range_"):
        if callback_data == "range_manual":
            state.step = "chapter_input"
            await query.answer()
            await query.edit_message_text(
                f"‚úèÔ∏è **–†—É—á–Ω–æ–π –≤–≤–æ–¥ –¥–∏–∞–ø–∞–∑–æ–Ω–∞**\n\n"
                f"üìä –í—Å–µ–≥–æ –≥–ª–∞–≤: `{state.total_chapters}`\n\n"
                f"–í–≤–µ–¥–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –≤ –æ–¥–Ω–æ–º –∏–∑ —Ñ–æ—Ä–º–∞—Ç–æ–≤:\n"
                f"‚Ä¢ `5` - —Ç–æ–ª—å–∫–æ 5-—è –≥–ª–∞–≤–∞\n"
                f"‚Ä¢ `3-8` - –≥–ª–∞–≤—ã —Å 3 –ø–æ 8\n"
                f"‚Ä¢ `10+5` - –Ω–∞—á–∏–Ω–∞—è —Å 10-–π, –≤—Å–µ–≥–æ 5 –≥–ª–∞–≤\n\n"
                f"–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à –≤—ã–±–æ—Ä:",
                parse_mode=ParseMode.MARKDOWN
            )
            return
            
        elif callback_data == "back_to_chapters":
            await query.answer()
            await show_chapter_selection(query, state)
            return
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±—ã—Å—Ç—Ä—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        range_parts = callback_data.replace("range_", "").split("_")
        if len(range_parts) == 2:
            start_ch = int(range_parts[0])
            end_ch = int(range_parts[1])
            
            state.start_chapter = start_ch
            state.chapter_count = end_ch - start_ch + 1
            state.step = "translating"
            
            await query.answer(f"–í—ã–±—Ä–∞–Ω—ã –≥–ª–∞–≤—ã {start_ch}-{end_ch}")
            await show_translation_options(query, state)

async def handle_chapter_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≥–ª–∞–≤"""
    user_id = update.effective_user.id
    state = get_user_state(user_id)
    
    if state.step != "chapter_input":
        return
    
    input_text = update.message.text.strip()
    
    try:
        # –ü–∞—Ä—Å–∏–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤–≤–æ–¥–∞
        if "-" in input_text:
            # –§–æ—Ä–º–∞—Ç "3-8"
            parts = input_text.split("-")
            start_ch = int(parts[0])
            end_ch = int(parts[1])
            
            if start_ch < 1 or end_ch > state.total_chapters or start_ch > end_ch:
                raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω")
                
            state.start_chapter = start_ch
            state.chapter_count = end_ch - start_ch + 1
            
        elif "+" in input_text:
            # –§–æ—Ä–º–∞—Ç "10+5"
            parts = input_text.split("+")
            start_ch = int(parts[0])
            count = int(parts[1])
            
            if start_ch < 1 or start_ch > state.total_chapters or count < 1:
                raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω")
                
            state.start_chapter = start_ch
            state.chapter_count = min(count, state.total_chapters - start_ch + 1)
            
        else:
            # –§–æ—Ä–º–∞—Ç "5" - –æ–¥–Ω–∞ –≥–ª–∞–≤–∞
            chapter_num = int(input_text)
            
            if chapter_num < 1 or chapter_num > state.total_chapters:
                raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä –≥–ª–∞–≤—ã")
                
            state.start_chapter = chapter_num
            state.chapter_count = 1
        
        state.step = "translating"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        end_chapter = min(state.start_chapter + state.chapter_count - 1, state.total_chapters)
        range_text = f"–≥–ª–∞–≤–∞ {state.start_chapter}" if state.chapter_count == 1 else f"–≥–ª–∞–≤—ã {state.start_chapter}-{end_chapter}"
        
        await update.message.reply_text(
            f"‚úÖ –í—ã–±—Ä–∞–Ω –¥–∏–∞–ø–∞–∑–æ–Ω: **{range_text}**\n\n"
            f"–ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º –ø–µ—Ä–µ–≤–æ–¥–∞...",
            parse_mode=ParseMode.MARKDOWN
        )
        
        await show_translation_options(update, state)
        
    except (ValueError, IndexError):
        await update.message.reply_text(
            f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤–≤–æ–¥–∞!\n\n"
            f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–¥–∏–Ω –∏–∑ —Ñ–æ—Ä–º–∞—Ç–æ–≤:\n"
            f"‚Ä¢ `5` - —Ç–æ–ª—å–∫–æ 5-—è –≥–ª–∞–≤–∞\n"
            f"‚Ä¢ `3-8` - –≥–ª–∞–≤—ã —Å 3 –ø–æ 8\n"
            f"‚Ä¢ `10+5` - –Ω–∞—á–∏–Ω–∞—è —Å 10-–π, –≤—Å–µ–≥–æ 5 –≥–ª–∞–≤\n\n"
            f"–ú–∞–∫—Å–∏–º—É–º –≥–ª–∞–≤ –≤ —Ñ–∞–π–ª–µ: `{state.total_chapters}`\n"
            f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑:",
            parse_mode=ParseMode.MARKDOWN
        )

async def show_translation_options(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏ –ø–µ—Ä–µ–≤–æ–¥–∞"""
    keyboard = [
        [InlineKeyboardButton("üá∑üá∫ –†—É—Å—Å–∫–∏–π", callback_data="lang_—Ä—É—Å—Å–∫–∏–π")],
        [InlineKeyboardButton("üá∫üá∏ English", callback_data="lang_–∞–Ω–≥–ª–∏–π—Å–∫–∏–π")],
        [InlineKeyboardButton("üá©üá™ Deutsch", callback_data="lang_–Ω–µ–º–µ—Ü–∫–∏–π")],
        [InlineKeyboardButton("üá´üá∑ Fran√ßais", callback_data="lang_—Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π")],
        [InlineKeyboardButton("üá™üá∏ Espa√±ol", callback_data="lang_–∏—Å–ø–∞–Ω—Å–∫–∏–π")],
        [InlineKeyboardButton("ü§ñ –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å", callback_data="select_model")],
        [InlineKeyboardButton("‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥", callback_data="start_translation")]
    ]
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –≥–ª–∞–≤–∞—Ö
    chapter_info = ""
    if hasattr(state, 'total_chapters') and state.total_chapters > 0:
        if state.chapter_count == 0:  # –í—Å–µ –≥–ª–∞–≤—ã
            chapter_info = f"üìñ –ì–ª–∞–≤—ã: –≤—Å–µ ({state.total_chapters})\n"
        elif state.chapter_count == 1:
            chapter_info = f"üìñ –ì–ª–∞–≤–∞: {state.start_chapter}\n"
        else:
            end_chapter = min(state.start_chapter + state.chapter_count - 1, state.total_chapters)
            chapter_info = f"ÔøΩ –ì–ª–∞–≤—ã: {state.start_chapter}-{end_chapter}\n"
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –æ–±—ä–µ–∫—Ç–∞ update –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
        if hasattr(update, 'edit_message_text'):
            # –≠—Ç–æ CallbackQuery
            await update.edit_message_text(
                f"üîß **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
                f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
                f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n"
                f"{chapter_info}"
                f"üåç –Ø–∑—ã–∫: `{state.target_language}`\n"
                f"ü§ñ –ú–æ–¥–µ–ª—å: `{state.model}`\n\n"
                f"–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ –ø–µ—Ä–µ–≤–æ–¥:",
                reply_markup=reply_markup,
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            # –≠—Ç–æ Update, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            await update.message.reply_text(
                f"üîß **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
                f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
                f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n"
                f"{chapter_info}"
                f"üåç –Ø–∑—ã–∫: `{state.target_language}`\n"
                f"ü§ñ –ú–æ–¥–µ–ª—å: `{state.model}`\n\n"
                f"–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ –ø–µ—Ä–µ–≤–æ–¥:",
                reply_markup=reply_markup,
                parse_mode=ParseMode.MARKDOWN
            )
    except Exception as e:
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ
        if "Message is not modified" in str(e):
            logger.warning("–°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ")
        else:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–¥–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
            if hasattr(update, 'message') and update.message:
                await update.message.reply_text(
                    f"üîß **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
                    f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
                    f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n"
                    f"{chapter_info}"
                    f"üåç –Ø–∑—ã–∫: `{state.target_language}`\n"
                    f"ü§ñ –ú–æ–¥–µ–ª—å: `{state.model}`\n\n"
                    f"–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ –ø–µ—Ä–µ–≤–æ–¥:",
                    reply_markup=reply_markup,
                    parse_mode=ParseMode.MARKDOWN
                )
            elif hasattr(update, 'from_user'):
                # –î–ª—è CallbackQuery –∏—Å–ø–æ–ª—å–∑—É–µ–º bot.send_message
                await update.get_bot().send_message(
                    chat_id=update.message.chat_id,
                    text=f"üîß **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
                         f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
                         f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n"
                         f"{chapter_info}"
                         f"üåç –Ø–∑—ã–∫: `{state.target_language}`\n"
                         f"ü§ñ –ú–æ–¥–µ–ª—å: `{state.model}`\n\n"
                         f"–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ –ø–µ—Ä–µ–≤–æ–¥:",
                    reply_markup=reply_markup,
                    parse_mode=ParseMode.MARKDOWN
                )

async def show_model_selection(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ Gemini"""
    # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ TransGemini.py
    keyboard = []
    models_per_row = 1  # –ü–æ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ –≤ —Ä—è–¥—É –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    
    model_buttons = []
    for model_name in MODELS.keys():
        # –°–æ–∑–¥–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –∫–Ω–æ–ø–æ–∫
        short_name = model_name.replace("Gemini ", "").replace("gemma", "Gemma")
        if len(short_name) > 25:  # –û–±—Ä–µ–∑–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            short_name = short_name[:22] + "..."
        
        model_buttons.append(InlineKeyboardButton(
            f"ü§ñ {short_name}", 
            callback_data=f"model_{model_name}"
        ))
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫–∏ –ø–æ —Ä—è–¥–∞–º
    for i in range(0, len(model_buttons), models_per_row):
        keyboard.append(model_buttons[i:i + models_per_row])
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É "–ù–∞–∑–∞–¥"
    keyboard.append([InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º", callback_data="back_to_translation_options")])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.edit_message_text(
        f"ü§ñ **–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ Gemini**\n\n"
        f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
        f"üéØ –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: `{state.model}`\n\n"
        f"**–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:**\n"
        f"‚Ä¢ **Gemini 2.5** - –ù–æ–≤–µ–π—à–∏–µ –º–æ–¥–µ–ª–∏ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)\n"
        f"‚Ä¢ **Gemini 2.0** - –ë—ã—Å—Ç—Ä—ã–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ\n"
        f"‚Ä¢ **Gemini 1.5** - –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–µ–º\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞:",
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_translation_options(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ–ø—Ü–∏–π –ø–µ—Ä–µ–≤–æ–¥–∞"""
    query = update.callback_query
    user_id = query.from_user.id
    state = get_user_state(user_id)
    
    callback_data = query.data
    
    if callback_data.startswith("lang_"):
        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —è–∑—ã–∫–∞
        language = callback_data.replace("lang_", "")
        state.target_language = language
        
        await query.answer(f"–í—ã–±—Ä–∞–Ω —è–∑—ã–∫: {language}")
        await show_translation_options(query, state)
        
    elif callback_data == "select_model":
        # –ü–æ–∫–∞–∑–∞—Ç—å –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
        await query.answer()
        await show_model_selection(query, state)
        
    elif callback_data.startswith("model_"):
        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model_name = callback_data.replace("model_", "")
        if model_name in MODELS:
            state.model = model_name
            await query.answer(f"–í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
            await show_translation_options(query, state)
        else:
            await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å")
            
    elif callback_data == "back_to_translation_options":
        # –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º –ø–µ—Ä–µ–≤–æ–¥–∞
        await query.answer()
        await show_translation_options(query, state)
        
    elif callback_data == "start_translation":
        await query.answer()
        await start_translation(query, state)

async def start_translation(update: Update, state: UserState):
    import time
    start_time = time.time()
    logger.info(f"‚è≥ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–ø—É—â–µ–Ω –≤ {time.strftime('%H:%M:%S', time.localtime(start_time))}")
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –ø–µ—Ä–µ–≤–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É—è TransGemini.py"""
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞
    await update.edit_message_text(
        f"üîÑ **–ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–≤–æ–¥...**\n\n"
        f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
        f"üåç –Ø–∑—ã–∫: `{state.target_language}`\n"
        f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n\n"
        f"‚è≥ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...",
        parse_mode=ParseMode.MARKDOWN
    )
    
    try:
        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
        input_path = Path(state.file_path)
        output_dir = input_path.parent
        output_name = f"{input_path.stem}_translated.{state.output_format}"
        output_path = output_dir / output_name
        
        logger.info(f"–ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–≤–æ–¥ —Ñ–∞–π–ª–∞: {state.file_path}")
        logger.info(f"–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_path}")
        logger.info(f"–§–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω–æ–π: {state.file_format}, –≤—ã—Ö–æ–¥–Ω–æ–π: {state.output_format}")
        logger.info(f"–Ø–∑—ã–∫: {state.target_language}, –ú–æ–¥–µ–ª—å: {state.model}")
        logger.info(f"–ì–ª–∞–≤—ã: –Ω–∞—á–∏–Ω–∞—è —Å {getattr(state, 'start_chapter', 1)}, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {getattr(state, 'chapter_count', 0)}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TransGemini.py
        success, error_message = await translate_file_with_transgemini(
            input_file=state.file_path,
            output_file=str(output_path),
            input_format=state.file_format,
            output_format=state.output_format,
            target_language=state.target_language,
            api_key=state.api_key,
            model_name=state.model,
            progress_callback=None,  # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            start_chapter=getattr(state, 'start_chapter', 1),
            chapter_count=getattr(state, 'chapter_count', 0),
            chapters_info=getattr(state, 'chapters_info', None)  # –ü–µ—Ä–µ–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–ª–∞–≤–∞—Ö
        )
        
        end_time = time.time()
        duration = end_time - start_time
        if success and output_path.exists():
            logger.info(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω, —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {output_path}")
            logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –ø–µ—Ä–µ–≤–æ–¥–∞: {duration:.1f} —Å–µ–∫. (–∑–∞–≤–µ—Ä—à–µ–Ω–æ –≤ {time.strftime('%H:%M:%S', time.localtime(end_time))})")
            await send_translated_file(update, state, str(output_path))
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
            logger.error(f"‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –ø–µ—Ä–µ–≤–æ–¥–∞:")
            logger.error(f"   success: {success}")
            logger.error(f"   output_path: {output_path}")
            logger.error(f"   output_path.exists(): {output_path.exists() if output_path else 'N/A'}")
            logger.error(f"   output_path.parent: {output_path.parent if output_path else 'N/A'}")
            logger.error(f"   error_message: {error_message}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –ø–∞–ø–∫–µ
            if output_path and output_path.parent.exists():
                try:
                    files_in_output_dir = list(output_path.parent.iterdir())
                    logger.info(f"üìÅ –§–∞–π–ª—ã –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {output_path.parent}:")
                    for file in files_in_output_dir:
                        logger.info(f"   - {file.name} (—Ä–∞–∑–º–µ—Ä: {file.stat().st_size if file.is_file() else 'dir'})")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {e}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è —Ñ–∞–π–ª–∞
            if output_path:
                possible_locations = [
                    output_path.parent / f"{output_path.stem}_translated{output_path.suffix}",
                    output_path.parent / f"{output_path.stem}.txt",
                    output_path.parent / f"{Path(state.file_name).stem}_translated.txt",
                ]
                
                logger.info("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞:")
                for possible_path in possible_locations:
                    exists = possible_path.exists()
                    logger.info(f"   {possible_path}: {'‚úÖ –ù–ê–ô–î–ï–ù' if exists else '‚ùå –ù–ï–¢'}")
                    if exists and possible_path.is_file():
                        logger.info(f"      –†–∞–∑–º–µ—Ä: {possible_path.stat().st_size} –±–∞–π—Ç")
                        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ñ–∞–π–ª, –ø–æ–ø—Ä–æ–±—É–µ–º –µ–≥–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å
                        try:
                            await send_translated_file(update, state, str(possible_path))
                            return  # –£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ —Ñ–∞–π–ª
                        except Exception as send_error:
                            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ {possible_path}: {send_error}")
            
            error_text = "‚ùå **–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ**\n\n"
            if error_message and "—É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω" not in error_message.lower():
                error_text += f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: `{error_message}`\n\n"
            else:
                error_text += "–ü–µ—Ä–µ–≤–æ–¥ –±—ã–ª –∑–∞–≤–µ—Ä—à–µ–Ω, –Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.\n\n"
            
            error_text += "–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
            error_text += "‚Ä¢ Worker —Å–æ–∑–¥–∞–ª —Ñ–∞–π–ª –≤ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–º –º–µ—Å—Ç–µ\n"
            error_text += "‚Ä¢ –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø—Ä–∞–≤–∞–º–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É\n"
            error_text += "‚Ä¢ –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á Google Gemini\n"
            error_text += "‚Ä¢ –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ API\n"
            error_text += "‚Ä¢ –ü—Ä–æ–±–ª–µ–º—ã —Å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º\n"
            error_text += "‚Ä¢ –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n\n"
            error_text += "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."
            
            await update.edit_message_text(
                error_text,
                parse_mode=ParseMode.MARKDOWN
            )
            
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ: {e}", exc_info=True)
        await update.edit_message_text(
            f"‚ùå **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ**\n\n"
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: `{str(e)}`\n\n"
            f"–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –ø–æ–∑–∂–µ.",
            parse_mode=ParseMode.MARKDOWN
        )
    
    # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_id = update.from_user.id if hasattr(update, 'from_user') else update.effective_user.id
    reset_user_state(user_id)

async def translate_file_with_transgemini(input_file: str, output_file: str, 
                                        input_format: str, output_format: str,
                                        target_language: str, api_key: str, 
                                        model_name: str, progress_callback=None,
                                        start_chapter: int = 1, chapter_count: int = 0,
                                        chapters_info: dict = None) -> tuple[bool, str]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è TransGemini.py Worker –∫–ª–∞—Å—Å–∞
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—á–Ω–æ —Ç–∞–∫—É—é –∂–µ –ª–æ–≥–∏–∫—É –∫–∞–∫ TransGemini –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤
    """
    import datetime
    
    logger.info(f"üöÄ translate_file_with_transgemini: –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥")
    logger.info(f"üìÅ –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {input_file}")
    logger.info(f"üìÑ –§–æ—Ä–º–∞—Ç: {input_format} -> {output_format}")
    logger.info(f"ü§ñ –ú–æ–¥–µ–ª—å: {model_name}")
    
    start_time = datetime.datetime.now()
    
    def run_worker():
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç Worker –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ"""
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ TransGemini
            from TransGemini import Worker, MODELS
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏
            model_config = MODELS.get(model_name, MODELS.get("Gemini 2.0 Flash", MODELS[list(MODELS.keys())[0]]))
            logger.info(f"ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å: {model_name} —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π: {model_config}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º prompt –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–µ–ª–µ–≤–æ–≥–æ —è–∑—ã–∫–∞  
            if target_language.lower() in ['—Ä—É—Å—Å–∫–∏–π', 'russian', 'ru']:
                prompt_template = """–ü–µ—Ä–µ–≤–µ–¥–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –°–æ—Ö—Ä–∞–Ω–∏ –∏—Å—Ö–æ–¥–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏–∞–ª–æ–≥–æ–≤ –∏ —Ä–∞–∑–±–∏–≤–∫—É –Ω–∞ –∞–±–∑–∞—Ü—ã. –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π –∫ –ø–µ—Ä–µ–≤–æ–¥—É.

{text}"""
            else:
                prompt_template = f"""Translate the following text to {target_language}. Preserve the original formatting, dialogue structure, and paragraph breaks. Do not add any comments or explanations to the translation.

{{text}}"""
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            output_dir = os.path.dirname(output_file)
            if not output_dir:
                output_dir = os.path.dirname(input_file)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ñ–∞–π–ª–∞—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ TransGemini
            # TransGemini –æ–∂–∏–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π: (input_type, filepath, epub_html_path_or_none)
            input_type = input_format.lower()
            if input_type == 'epub' and output_format.lower() != 'epub':
                # EPUB -> –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç: TransGemini –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ HTML —Ñ–∞–π–ª—ã –≤–Ω—É—Ç—Ä–∏
                files_to_process_data = [(input_type, input_file, None)]
            else:
                # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏: –ø—Ä—è–º–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞
                files_to_process_data = [(input_type, input_file, None)]
            
            logger.info(f"üìù –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {files_to_process_data}")
            
            # –°–æ–∑–¥–∞–µ–º Worker —Å —Ç–µ–º–∏ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —á—Ç–æ –∏ –≤ TransGemini GUI
            worker = Worker(
                api_key=api_key,
                out_folder=output_dir,
                prompt_template=prompt_template,
                files_to_process_data=files_to_process_data,
                model_config=model_config,
                max_concurrent_requests=1,  # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ Telegram –±–æ—Ç–∞
                output_format=output_format,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º worker_output_format
                chunking_enabled_gui=True,
                chunk_limit=900000,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
                chunk_window=500,
                temperature=0.1,
                chunk_delay_seconds=0.5,  # –£–º–µ–Ω—å—à–µ–Ω–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
                proxy_string=None
            )
            
            logger.info("Worker —Å–æ–∑–¥–∞–Ω, –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –ª–æ–≥–æ–≤ Worker'–∞
            worker_logs = []
            worker_errors = []
            
            def capture_worker_log(message):
                worker_logs.append(message)
                logger.info(f"Worker Log: {message}")
                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ API –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
                if any(word in message for word in ['[API START]', '[API CALL]', '[API RESPONSE]', '–û–±—Ä–∞–±–æ—Ç–∫–∞', '–ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É', '–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç', '–û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å']):
                    logger.info(f"[PROGRESS] {message}")
                if any(keyword in message.lower() for keyword in ['error', 'failed', 'exception', '–æ—à–∏–±–∫–∞']):
                    worker_errors.append(message)
            
            def extract_progress_info(log_message: str) -> str:
                """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ –∏–∑ –ª–æ–≥-—Å–æ–æ–±—â–µ–Ω–∏—è Worker'–∞"""
                try:
                    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —ç—Ç–∞–ø–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    patterns = [
                        # API –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å - –Ω–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                        (r'\[API START\]\s*([^:]+):\s*–ù–∞—á–∏–Ω–∞–µ–º\s+API\s+–∑–∞–ø—Ä–æ—Å', 
                         lambda m: f"üîÑ **{m.group(1)}**\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º API –∑–∞–ø—Ä–æ—Å..."),
                        
                        (r'\[API CALL\]\s*([^:]+):\s*–û—Ç–ø—Ä–∞–≤–ª—è–µ–º\s+–∑–∞–ø—Ä–æ—Å\s+–∫\s+API', 
                         lambda m: f"üì° **{m.group(1)}**\nü§ñ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Gemini API..."),
                        
                        (r'\[API RESPONSE\]\s*([^:]+):\s*–ü–æ–ª—É—á–µ–Ω\s+–æ—Ç–≤–µ—Ç\s+–æ—Ç\s+API', 
                         lambda m: f"‚úÖ **{m.group(1)}**\nüìù –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç API!"),
                        
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ EPUB —Ñ–∞–π–ª–æ–≤
                        (r'\[INFO\]\s*([^:]+):\s*–û–±—Ä–∞–±–æ—Ç–∫–∞\s+(\d+)/(\d+)\s+—á–∞–Ω–∫–æ–≤', 
                         lambda m: f"üìÑ **{m.group(1)}**\n‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —á–∞–Ω–∫ {m.group(2)} –∏–∑ {m.group(3)}"),
                        
                        # –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
                        (r'\[INFO\]\s*([^:]+):\s*–ù–∞—á–∏–Ω–∞—é\s+–æ–±—Ä–∞–±–æ—Ç–∫—É', 
                         lambda m: f"üöÄ **–ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É**\nüìÑ {m.group(1)}"),
                        
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ HTML —Ñ–∞–π–ª–æ–≤ –∏–∑ EPUB
                        (r'\[INFO\]\s*([^:]+):\s*–ö–æ–Ω—Ç–µ–Ω—Ç\s+\(([^)]+)\).*—Ä–∞–∑–¥–µ–ª—è–µ–º', 
                         lambda m: f"üìñ **{m.group(1)}**\nüîÑ –†–∞–∑–¥–µ–ª—è—é –∫–æ–Ω—Ç–µ–Ω—Ç ({m.group(2)})"),
                        
                        # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ API (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
                        (r'\[INFO\]\s*([^:]+):\s*–û—Ç–ø—Ä–∞–≤–ª—è—é\s+–∑–∞–ø—Ä–æ—Å\s+–≤\s+API', 
                         lambda m: f"ü§ñ **{m.group(1)}**\nüì° –û—Ç–ø—Ä–∞–≤–ª—è—é –≤ Gemini API..."),
                        
                        # –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç API (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
                        (r'\[INFO\]\s*([^:]+):\s*–ü–æ–ª—É—á–µ–Ω\s+–æ—Ç–≤–µ—Ç.*—Å–∏–º–≤–æ–ª–æ–≤', 
                         lambda m: f"‚úÖ **{m.group(1)}**\nüìù –ü–æ–ª—É—á–µ–Ω –ø–µ—Ä–µ–≤–æ–¥ –æ—Ç Gemini"),
                        
                        # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                        (r'\[INFO\]\s*([^:]+):\s*–ü—Ä–∏–º–µ–Ω—è–µ–º\s+–∑–∞–¥–µ—Ä–∂–∫—É\s+([\d.]+)\s+—Å–µ–∫', 
                         lambda m: f"‚è∞ **{m.group(1)}**\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {m.group(2)} —Å–µ–∫..."),
                        
                        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
                        (r'\[INFO\]\s*([^:]+):\s*–û–±—Ä–∞–±–æ—Ç–∫–∞\s+–∑–∞–≤–µ—Ä—à–µ–Ω–∞', 
                         lambda m: f"‚úÖ **{m.group(1)}**\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"),
                        
                        # –ü—Ä–æ–≥—Ä–µ—Å—Å —á–∞–Ω–∫–æ–≤
                        (r'Chunk\s+(\d+)/(\d+)', 
                         lambda m: f"üìù **–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞**\nüî¢ {m.group(1)} –∏–∑ {m.group(2)}"),
                    ]
                    
                    for pattern, formatter in patterns:
                        match = re.search(pattern, log_message, re.IGNORECASE)
                        if match:
                            try:
                                return formatter(match)
                            except Exception as e:
                                logger.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")
                                return f"üìã {log_message}"
                    
                    return None
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")
                    return None
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –ª–æ–≥–æ–≤
            worker.log_message.connect(capture_worker_log)
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω
            if progress_callback:
                def on_log_message(message):
                    progress_info = extract_progress_info(message)
                    if progress_info:
                        try:
                            # –ó–∞–ø—É—Å–∫–∞–µ–º callback –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
                            asyncio.run_coroutine_threadsafe(
                                progress_callback(progress_info), 
                                asyncio.get_event_loop()
                            )
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ progress_callback: {e}")
                
                worker.log_message.connect(on_log_message)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
            logger.info("üèÉ –ó–∞–ø—É—Å–∫–∞–µ–º Worker.run()...")
            worker.run()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if worker_errors:
                error_msg = f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ—à–∏–±–∫–∏ –≤–æ –≤—Ä–µ–º—è –ø–µ—Ä–µ–≤–æ–¥–∞: {'; '.join(worker_errors[:3])}"
                logger.error(f"‚ùå {error_msg}")
                return False, error_msg
            
            # –ò—â–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            # Worker —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª—ã —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º _translated
            input_name = Path(input_file).stem
            expected_output_name = f"{input_name}_translated.{output_format}"
            expected_output_path = os.path.join(output_dir, expected_output_name)
            
            if os.path.exists(expected_output_path):
                # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å —Ñ–∞–π–ª
                if expected_output_path != output_file:
                    try:
                        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
                        os.makedirs(os.path.dirname(output_file), exist_ok=True)
                        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª
                        import shutil
                        shutil.move(expected_output_path, output_file)
                        logger.info(f"‚úÖ –§–∞–π–ª –ø–µ—Ä–µ–º–µ—â–µ–Ω —Å {expected_output_path} –Ω–∞ {output_file}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —Ñ–∞–π–ª: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—É—Ç—å")
                        output_file = expected_output_path
                
                file_size = os.path.getsize(output_file)
                end_time = datetime.datetime.now()
                duration = end_time - start_time
                
                logger.info(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                logger.info(f"üìÅ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_file}")
                logger.info(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
                logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration}")
                
                return True, f"–ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω. –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {os.path.basename(output_file)} ({file_size} –±–∞–π—Ç)"
            else:
                # –ò—â–µ–º –ª—é–±—ã–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å _translated
                created_files = []
                for file in os.listdir(output_dir):
                    if '_translated' in file and file.endswith(f'.{output_format}'):
                        created_files.append(os.path.join(output_dir, file))
                
                if created_files:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    actual_output = created_files[0]
                    logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω —Å–æ–∑–¥–∞–Ω–Ω—ã–π —Ñ–∞–π–ª: {actual_output}")
                    
                    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –∫ –Ω—É–∂–Ω–æ–º—É –∏–º–µ–Ω–∏
                    try:
                        import shutil
                        shutil.move(actual_output, output_file)
                        logger.info(f"‚úÖ –§–∞–π–ª –ø–µ—Ä–µ–º–µ—â–µ–Ω –Ω–∞ {output_file}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —Ñ–∞–π–ª: {e}")
                        output_file = actual_output
                    
                    file_size = os.path.getsize(output_file)
                    return True, f"–ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω. –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {os.path.basename(output_file)} ({file_size} –±–∞–π—Ç)"
                else:
                    error_msg = f"–§–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω. –û–∂–∏–¥–∞–ª—Å—è: {expected_output_path}"
                    logger.error(f"‚ùå {error_msg}")
                    return False, error_msg
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ Worker: {e}", exc_info=True)
            return False, f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º Worker –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    try:
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(None, run_worker)
        return result
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}", exc_info=True)
        return False, f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {str(e)}"


def main():
                                try:
                                    with epub_zip.open(html_file) as f:
                                        html_content = f.read().decode('utf-8', errors='ignore')
                                        
                                        # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏ –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
                                        # –£–±–∏—Ä–∞–µ–º CSS –∏ —Å–∫—Ä–∏–ø—Ç—ã
                                        html_content = re.sub(r'<style[^>]*>.*?</style>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
                                        html_content = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
                                        
                                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ HTML
                                        text_content = re.sub(r'<[^>]+>', '', html_content)
                                        text_content = re.sub(r'\s+', ' ', text_content).strip()
                                        
                                        if text_content and len(text_content) > 100:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ–∞–π–ª—ã
                                            chapters_content.append(text_content)
                                except:
                                    continue
                    
                    if chapters_content:
                        content = '\n\n--- –ì–õ–ê–í–ê ---\n\n'.join(chapters_content)
                        logger.info(f"EPUB –æ–±—Ä–∞–±–æ—Ç–∞–Ω: –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(chapters_content)} –≥–ª–∞–≤, –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    else:
                        # Fallback: —á–∏—Ç–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ñ–∞–π–ª
                        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≥–ª–∞–≤—ã –∏–∑ EPUB, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
                        with open(file_path, 'rb') as f:
                            raw_content = f.read()
                            content = raw_content.decode('utf-8', errors='ignore')
                            
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è EPUB: {e}")
                    # Fallback: —á–∏—Ç–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ñ–∞–π–ª
                    with open(file_path, 'rb') as f:
                        raw_content = f.read()
                        content = raw_content.decode('utf-8', errors='ignore')
                        
            elif file_format.lower() in ['html', 'xml']:
                encodings = ['utf-8', 'cp1251', 'latin-1']
                for encoding in encodings:
                    try:
                        with open(file_path, 'r', encoding=encoding) as f:
                            content = f.read()
                        break
                    except UnicodeDecodeError:
                        continue
                else:
                    with open(file_path, 'rb') as f:
                        raw_content = f.read()
                        content = raw_content.decode('utf-8', errors='ignore')
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —á–∏—Ç–∞–µ–º –∫–∞–∫ —Ç–µ–∫—Å—Ç —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
                encodings = ['utf-8', 'cp1251', 'latin-1']
                for encoding in encodings:
                    try:
                        with open(file_path, 'r', encoding=encoding) as f:
                            content = f.read()
                        break
                    except UnicodeDecodeError:
                        continue
                else:
                    with open(file_path, 'rb') as f:
                        raw_content = f.read()
                        content = raw_content.decode('utf-8', errors='ignore')
            
            # –ï—Å–ª–∏ –Ω—É–∂–Ω—ã –≤—Å–µ –≥–ª–∞–≤—ã (count = 0), –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç
            if count == 0:
                return content
            
            # –ò—â–µ–º –≥–ª–∞–≤—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞
            if file_format.lower() == 'txt':
                chapter_pattern = r'(?:^|\n)(?:–ì–õ–ê–í–ê|–ì–ª–∞–≤–∞|Chapter|CHAPTER)\s*(?:\d+|[IVXLCDM]+|[–ê-–Ø]{1,3})\b[^\n]*(?:\n|$)'
            elif file_format.lower() == 'docx':
                chapter_pattern = r'(?:^|\n)(?:–ì–õ–ê–í–ê|–ì–ª–∞–≤–∞|Chapter|CHAPTER)\s*(?:\d+|[IVXLCDM]+|[–ê-–Ø]{1,3})\b[^\n]*(?:\n|$)'
            elif file_format.lower() == 'epub':
                # –î–ª—è EPUB –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –¥–æ–±–∞–≤–∏–ª–∏ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏
                chapter_pattern = r'\n\n--- –ì–õ–ê–í–ê ---\n\n'
            elif file_format.lower() == 'html':
                chapter_pattern = r'<h[1-6][^>]*>(?:–ì–õ–ê–í–ê|–ì–ª–∞–≤–∞|Chapter|CHAPTER)\s*(?:\d+|[IVXLCDM]+|[–ê-–Ø]{1,3})\b[^<]*</h[1-6]>'
            else:
                chapter_pattern = r'(?:^|\n)(?:–ì–õ–ê–í–ê|–ì–ª–∞–≤–∞|Chapter|CHAPTER)\s*(?:\d+|[IVXLCDM]+|[–ê-–Ø]{1,3})\b[^\n]*(?:\n|$)'
            
            chapters = re.split(chapter_pattern, content, flags=re.MULTILINE | re.IGNORECASE)
            chapter_headers = re.findall(chapter_pattern, content, flags=re.MULTILINE | re.IGNORECASE)
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è EPUB
            if file_format.lower() == 'epub' and '--- –ì–õ–ê–í–ê ---' in content:
                chapters = content.split('\n\n--- –ì–õ–ê–í–ê ---\n\n')
                # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –≥–ª–∞–≤
                chapter_headers = [f"–ì–ª–∞–≤–∞ {i+1}" for i in range(len(chapters)-1)]
                
                # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ –≥–ª–∞–≤—ã
                filtered_chapters = []
                filtered_headers = []
                for i, chapter in enumerate(chapters):
                    if chapter.strip() and len(chapter.strip()) > 100:
                        filtered_chapters.append(chapter)
                        if i > 0:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—É—é "–≥–ª–∞–≤—É" (–¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è)
                            filtered_headers.append(f"–ì–ª–∞–≤–∞ {len(filtered_chapters)}")
                
                chapters = filtered_chapters
                chapter_headers = filtered_headers
            
            if len(chapters) <= 1:
                # –ì–ª–∞–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
                lines = content.split('\n')
async def update_progress_message(message, progress_text: str):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º"""
    try:
        await message.edit_text(
            f"üîÑ **–ü–µ—Ä–µ–≤–æ–¥ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ...**\n\n"
            f"{progress_text}",
            parse_mode=ParseMode.MARKDOWN
        )
    except Exception:
        pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–≤–∫–ª—é—á–∞—è timeout)

def update_progress_message_async(message, progress_text: str):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏–∑ Worker'–∞"""
    try:
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π event loop –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        import asyncio
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        if loop.is_running():
            # –ï—Å–ª–∏ loop —É–∂–µ –∑–∞–ø—É—â–µ–Ω, —Å–æ–∑–¥–∞–µ–º task
            asyncio.create_task(update_progress_message(message, progress_text))
        else:
            # –ï—Å–ª–∏ loop –Ω–µ –∑–∞–ø—É—â–µ–Ω, –∑–∞–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            loop.run_until_complete(update_progress_message(message, progress_text))
    except Exception as e:
        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        logger.debug(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")
        pass

async def send_translated_file(update: Update, state: UserState, output_path: str):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = os.path.getsize(output_path)
        if file_size > 50 * 1024 * 1024:  # 50MB –ª–∏–º–∏—Ç Telegram
            await update.edit_message_text(
                "‚ùå **–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π**\n\n"
                "–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–µ–≤—ã—à–∞–µ—Ç 50MB –∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —á–µ—Ä–µ–∑ Telegram.",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª
        with open(output_path, 'rb') as file:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º chat_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ update
            if hasattr(update, 'effective_chat'):
                chat_id = update.effective_chat.id
            elif hasattr(update, 'message') and update.message:
                chat_id = update.message.chat.id
            else:
                chat_id = update.from_user.id  # Fallback –¥–ª—è CallbackQuery
                
            await update.get_bot().send_document(
                chat_id=chat_id,
                document=file,
                filename=Path(output_path).name,
                caption=f"‚úÖ **–ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω!**\n\n"
                       f"üìÅ –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: `{state.file_name}`\n"
                       f"üåç –Ø–∑—ã–∫: `{state.target_language}`\n"
                       f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n"
                       f"üìä –†–∞–∑–º–µ—Ä: `{file_size / 1024:.1f} KB`",
                parse_mode=ParseMode.MARKDOWN
            )
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ
        try:
            if hasattr(update, 'delete_message'):
                await update.delete_message()
            elif hasattr(update, 'message') and update.message:
                await update.message.delete()
        except Exception:
            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ —É–¥–∞–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞: {e}")
        try:
            if hasattr(update, 'edit_message_text'):
                await update.edit_message_text(
                    f"‚ùå **–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞**\n\n"
                    f"–ü–µ—Ä–µ–≤–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω, –Ω–æ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ: `{str(e)}`",
                    parse_mode=ParseMode.MARKDOWN
                )
            elif hasattr(update, 'message') and update.message:
                await update.message.reply_text(
                    f"‚ùå **–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞**\n\n"
                    f"–ü–µ—Ä–µ–≤–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω, –Ω–æ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ: `{str(e)}`",
                    parse_mode=ParseMode.MARKDOWN
                )
        except Exception:
            pass
    
    finally:
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        try:
            if os.path.exists(state.file_path):
                os.remove(state.file_path)
            if os.path.exists(output_path):
                os.remove(output_path)
        except:
            pass

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /help"""
    help_text = """
ü§ñ **–ü–æ–º–æ—â—å –ø–æ –±–æ—Ç—É –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞**

**–ö–æ–º–∞–Ω–¥—ã:**
‚Ä¢ /start - –ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É
‚Ä¢ /help - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É
‚Ä¢ /cancel - –û—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–π –ø—Ä–æ—Ü–µ—Å—Å

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:**
‚Ä¢ TXT - —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
‚Ä¢ DOCX - –¥–æ–∫—É–º–µ–Ω—Ç—ã Word  
‚Ä¢ HTML - –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã
‚Ä¢ EPUB - —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏
‚Ä¢ XML - XML –¥–æ–∫—É–º–µ–Ω—Ç—ã

**–ü—Ä–æ—Ü–µ—Å—Å –ø–µ—Ä–µ–≤–æ–¥–∞:**
1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –±–æ—Ç—É
2. –í—ã–±–µ—Ä–∏—Ç–µ –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç
3. –í–≤–µ–¥–∏—Ç–µ API –∫–ª—é—á Google Gemini
4. –í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞
5. –ü–æ–ª—É—á–∏—Ç–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª

**–ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–∞:**
1. –û—Ç–∫—Ä–æ–π—Ç–µ https://aistudio.google.com/
2. –í–æ–π–¥–∏—Ç–µ –≤ Google –∞–∫–∫–∞—É–Ω—Ç
3. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π API –∫–ª—é—á
4. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ–≥–æ –±–æ—Ç—É

**–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:**
‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: 20MB
‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: 50MB
    """
    
    await update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)

async def cancel_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /cancel"""
    user_id = update.effective_user.id
    reset_user_state(user_id)
    
    await update.message.reply_text(
        "‚ùå **–ü—Ä–æ—Ü–µ—Å—Å –æ—Ç–º–µ–Ω–µ–Ω**\n\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ.",
        parse_mode=ParseMode.MARKDOWN
    )

def load_env_file():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞"""
    env_path = Path('.env')
    if env_path.exists():
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞"""
    print("ü§ñ –ó–∞–ø—É—Å–∫ Telegram –±–æ—Ç–∞ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞ —Ñ–∞–π–ª–æ–≤")
    print("üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç TransGemini.py –¥–ª—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º .env —Ñ–∞–π–ª –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    load_env_file()
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –±–æ—Ç–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
    
    if not bot_token:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω —Ç–æ–∫–µ–Ω –±–æ—Ç–∞!")
        print("–°–æ–∑–¥–∞–π—Ç–µ –±–æ—Ç–∞ —á–µ—Ä–µ–∑ @BotFather –≤ Telegram –∏ –ø–æ–ª—É—á–∏—Ç–µ —Ç–æ–∫–µ–Ω")
        print("=" * 40)
        
        # –ü–æ–ø—Ä–æ—Å–∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤–≤–µ—Å—Ç–∏ —Ç–æ–∫–µ–Ω
        bot_token = input("–í–≤–µ–¥–∏—Ç–µ —Ç–æ–∫–µ–Ω –±–æ—Ç–∞: ").strip()
        if not bot_token:
            print("–¢–æ–∫–µ–Ω –Ω–µ –≤–≤–µ–¥–µ–Ω. –í—ã—Ö–æ–¥.")
            sys.exit(1)
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    application = Application.builder().token(bot_token).build()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("cancel", cancel_command))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ–∞–π–ª–æ–≤
    application.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ API –∫–ª—é—á–∞ –∏ –≤–≤–æ–¥–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≥–ª–∞–≤ (—Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è)
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_input))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ callback –∫–Ω–æ–ø–æ–∫
    application.add_handler(CallbackQueryHandler(handle_format_selection, pattern=r"^format_"))
    application.add_handler(CallbackQueryHandler(handle_chapter_selection, pattern=r"^(chapters_|skip_chapters)"))
    application.add_handler(CallbackQueryHandler(handle_chapter_range_selection, pattern=r"^(range_|back_to_chapters)"))
    application.add_handler(CallbackQueryHandler(handle_translation_options, pattern=r"^(lang_|select_model$|model_|back_to_translation_options$|start_translation$)"))
    
    print(f"‚úÖ –ë–æ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω —Å —Ç–æ–∫–µ–Ω–æ–º: {bot_token[:10]}...")
    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.")
    print("üéØ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –±–æ—Ç—É —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ–≤–æ–¥–∞!")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()
