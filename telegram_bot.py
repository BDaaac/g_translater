#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Telegram –±–æ—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ñ–∞–π–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TransGemini.py
"""

import os
import sys
import re
import tempfile
import asyncio
import logging
import subprocess
import zipfile
import uuid
import shutil
import datetime
import json
import time
import threading
from pathlib import Path
from typing import Dict, Any, Optional, List, Union

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ Telegram
from telegram.error import BadRequest

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –µ—Å–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
def ensure_package(package_name, import_name=None):
    import_name = import_name or package_name
    try:
        __import__(import_name.split('.')[0])
    except ImportError:
        print(f"–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é {package_name}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package_name])

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã
ensure_package("python-telegram-bot==20.7")
ensure_package("google-generativeai", "google.generativeai")
ensure_package("python-docx", "docx")
ensure_package("beautifulsoup4", "bs4")
ensure_package("lxml")
ensure_package("PyQt6", "PyQt6")
ensure_package("ebooklib")

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Telegram
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, ContextTypes, filters
from telegram.constants import ParseMode

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ TransGemini.py
from TransGemini import (
    MODELS,
    OUTPUT_FORMATS,
    Worker,
    write_to_epub,
    ApiKeyManager,
    RateLimitTracker,
    InitialSetupDialog,
    TranslationSessionManager,
    EpubCreator,
    TranslatedChaptersManagerDialog,
    ContextManager,
    DynamicGlossaryFilter,
    run_translation_with_auto_restart
)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º Google API –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–ª—é—á–∞
try:
    import google.generativeai as genai
    from google.api_core import exceptions as google_exceptions
except ImportError:
    genai = None
    google_exceptions = None

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤ (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç TransGemini.py)
SUPPORTED_FORMATS = {
    'txt': ['.txt'],
    'docx': ['.docx'], 
    'html': ['.html', '.htm'],
    'epub': ['.epub'],
    'xml': ['.xml'],
    'fb2': ['.fb2']
}

def get_possible_output_formats(input_format: str) -> list:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º OUTPUT_FORMATS –∏–∑ TransGemini.py
    available_formats = []
    for display_name, format_code in OUTPUT_FORMATS.items():
        # –í–∫–ª—é—á–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∏–∑ TransGemini
        available_formats.append((display_name, format_code))
    return available_formats

def process_text_block_for_chapter_html(text_block: str) -> str:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è HTML, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞–∫ –≤ TransGemini"""
    from html import escape
    import re
    
    # –ó–∞—â–∏—â–∞–µ–º –∞–º–ø–µ—Ä—Å–∞–Ω–¥—ã
    text_block_escaped_amp = text_block.replace('&', '&amp;')
    
    # –ó–∞—â–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ <br/> —Ç–µ–≥–∏
    text_block_br_protected = re.sub(r'<br\s*/?>', '__TEMP_BR_TAG__', text_block_escaped_amp, flags=re.IGNORECASE)
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º < –∏ >
    text_block_lt_gt_escaped = text_block_br_protected.replace('<', '&lt;').replace('>', '&gt;')
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    temp_md_text = text_block_lt_gt_escaped
    temp_md_text = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', temp_md_text, flags=re.DOTALL)
    temp_md_text = re.sub(r'(?<!\*)\*(?!\*)(.*?)(?<!\*)\*(?!\*)', r'<em>\1</em>', temp_md_text, flags=re.DOTALL)
    temp_md_text = re.sub(r'`(.*?)`', r'<code>\1</code>', temp_md_text, flags=re.DOTALL)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ç–µ–≥–∏
    final_text = temp_md_text.replace('__TEMP_BR_TAG__', '<br/>')
    
    return final_text

def create_chapter_html(chapter_title: str, content: str, chapter_num: int) -> str:
    """–°–æ–∑–¥–∞–µ—Ç HTML –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –≥–ª–∞–≤—ã –≤ —Å—Ç–∏–ª–µ TransGemini —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
    from html import escape
    import re
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
    title_escaped = escape(chapter_title)
    
    # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç –º—É—Å–æ—Ä–Ω—ã—Ö —Ñ—Ä–∞–∑ AI
    content = clean_ai_response(content)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É)
    lines = content.splitlines()
    
    html_body_content = ""
    paragraph_buffer = []
    current_list_type = None
    in_code_block = False
    code_block_lines = []
    
    def flush_paragraph_buffer():
        """–û—á–∏—â–∞–µ—Ç –±—É—Ñ–µ—Ä –∞–±–∑–∞—Ü–∞ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –µ–≥–æ –≤ HTML"""
        nonlocal html_body_content, paragraph_buffer
        if paragraph_buffer:
            # –°–æ–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏ –∞–±–∑–∞—Ü–∞ —á–µ—Ä–µ–∑ <br/>
            para_content = process_text_block_for_chapter_html('<br/>'.join(paragraph_buffer))
            if para_content.strip():
                html_body_content += f"    <p>{para_content}</p>\n"
            paragraph_buffer = []
    
    def close_current_list():
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫"""
        nonlocal html_body_content, current_list_type
        if current_list_type:
            html_body_content += f"    </{current_list_type}>\n"
            current_list_type = None
    
    for line in lines:
        stripped_line = line.strip()
        is_code_fence = stripped_line == '```'
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
        if is_code_fence:
            if not in_code_block:
                flush_paragraph_buffer()
                close_current_list()
                in_code_block = True
                code_block_lines = []
            else:
                in_code_block = False
                escaped_code = escape("\n".join(code_block_lines))
                html_body_content += f"    <pre><code>{escaped_code}</code></pre>\n"
            continue
        
        if in_code_block:
            code_block_lines.append(line)
            continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        heading_match = re.match(r'^(#{1,6})\s+(.*)', stripped_line)
        hr_match = stripped_line == '---'
        ul_match = re.match(r'^[\*\-]\s+(.*)', stripped_line)
        ol_match = re.match(r'^\d+\.\s+(.*)', stripped_line)
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if current_list_type and not ((current_list_type == 'ul' and ul_match) or (current_list_type == 'ol' and ol_match)):
            close_current_list()
        
        # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –ø–µ—Ä–µ–¥ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏
        if paragraph_buffer and (heading_match or hr_match or ul_match or ol_match):
            flush_paragraph_buffer()
        
        if heading_match:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            level = len(heading_match.group(1))
            heading_text = process_text_block_for_chapter_html(heading_match.group(2).strip())
            if heading_text:
                html_body_content += f"    <h{level}>{heading_text}</h{level}>\n"
        elif hr_match:
            # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è
            html_body_content += "    <hr/>\n"
        elif ul_match:
            # –ù–µ—É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
            if current_list_type != 'ul':
                html_body_content += "    <ul>\n"
                current_list_type = 'ul'
            list_text = process_text_block_for_chapter_html(ul_match.group(1).strip())
            html_body_content += f"      <li>{list_text}</li>\n"
        elif ol_match:
            # –£–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
            if current_list_type != 'ol':
                html_body_content += "    <ol>\n"
                current_list_type = 'ol'
            list_text = process_text_block_for_chapter_html(ol_match.group(1).strip())
            html_body_content += f"      <li>{list_text}</li>\n"
        elif line.strip():
            # –û–±—ã—á–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ - –¥–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä –∞–±–∑–∞—Ü–∞
            paragraph_buffer.append(line)
        elif not stripped_line and paragraph_buffer:
            # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ - –∑–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â–∏–π –∞–±–∑–∞—Ü
            flush_paragraph_buffer()
    
    # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —ç–ª–µ–º–µ–Ω—Ç—ã
    close_current_list()
    flush_paragraph_buffer()
    
    if in_code_block:
        escaped_code = escape("\n".join(code_block_lines))
        html_body_content += f"    <pre><code>{escaped_code}</code></pre>\n"
    
    # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –ø—É—Å—Ç–æ–π, —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∞–±–∑–∞—Ü
    if not html_body_content.strip():
        processed_content = process_text_block_for_chapter_html(content.strip())
        html_body_content = f"    <p>{processed_content}</p>\n"
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π HTML –≤ —Å—Ç–∏–ª–µ TransGemini
    html_content = f'''<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title>{title_escaped}</title>
  <link rel="stylesheet" type="text/css" href="../style/default.css"/>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
</head>
<body>
  <h1>{title_escaped}</h1>
{html_body_content.rstrip()}
</body>
</html>'''
    
    return html_content

def clean_ai_response(content: str) -> str:
    """–û—á–∏—â–∞–µ—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ñ—Ä–∞–∑ AI"""
    try:
        # –°–ø–∏—Å–æ–∫ —Ñ—Ä–∞–∑, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –∏–∑ –Ω–∞—á–∞–ª–∞ —Ç–µ–∫—Å—Ç–∞
        ai_garbage_patterns = [
            r'^(?:–∫–æ–Ω–µ—á–Ω–æ[,!]?\s*)?–≤–æ—Ç\s+–ø–µ—Ä–µ–≤–æ–¥[:\s]*',
            r'^–≤–æ—Ç\s+–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π\s+—Ç–µ–∫—Å—Ç[:\s]*',
            r'^–ø–µ—Ä–µ–≤–æ–¥[:\s]*',
            r'^–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π\s+—Ç–µ–∫—Å—Ç[:\s]*',
            r'^–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ[:\s]*',
            r'^—Ä–µ–∑—É–ª—å—Ç–∞—Ç\s+–ø–µ—Ä–µ–≤–æ–¥–∞[:\s]*',
            r'^–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–∞—è\s+–≤–µ—Ä—Å–∏—è[:\s]*',
            r'^–≤–æ—Ç\s+—Ä–µ–∑—É–ª—å—Ç–∞—Ç[:\s]*',
            r'^–∫–æ–Ω–µ—á–Ω–æ[,!]?\s*',
            r'^–¥–∞[,!]?\s*–≤–æ—Ç\s*',
            r'^—Ö–æ—Ä–æ—à–æ[,!]?\s*',
            r'^–æ—Ç–ª–∏—á–Ω–æ[,!]?\s*',
            r'^–≥–æ—Ç–æ–≤–æ[,!]?\s*',
            r'^–≤–æ—Ç\s+–æ–Ω[:\s]*',
            r'^—Å–º–æ—Ç—Ä–∏[,!]?\s*',
            r'^–¥–µ—Ä–∂–∏[,!]?\s*',
            r'^–ø–æ–∂–∞–ª—É–π—Å—Ç–∞[,!]?\s*',
            r'^\*\*–ø–µ—Ä–µ–≤–æ–¥\*\*[:\s]*',
            r'^\*\*–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π\s+—Ç–µ–∫—Å—Ç\*\*[:\s]*',
            r'^here\s+is\s+the\s+translation[:\s]*',
            r'^translation[:\s]*',
            r'^translated\s+text[:\s]*',
            r'^of\s+course[,!]?\s*here\s*',
            r'^sure[,!]?\s*here\s*',
            r'^here\s+you\s+go[:\s]*',
            r'^–≤–æ—Ç\s+–∏\s+–≤—Å—ë[,!]?\s*',
            r'^–≥–æ—Ç–æ–≤–æ[,!]?\s*–≤–æ—Ç\s*'
        ]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –Ω–∞—á–∞–ª–∞
        cleaned_content = content.strip()
        for pattern in ai_garbage_patterns:
            cleaned_content = re.sub(pattern, '', cleaned_content, flags=re.IGNORECASE | re.MULTILINE)
            cleaned_content = cleaned_content.strip()
        
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –Ω–∞—á–∞–ª–µ
        while cleaned_content.startswith('\n'):
            cleaned_content = cleaned_content[1:]
        
        # –£–¥–∞–ª—è–µ–º markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
        cleaned_content = re.sub(r'^```[a-z]*\n?', '', cleaned_content, flags=re.MULTILINE)
        cleaned_content = re.sub(r'\n?```$', '', cleaned_content, flags=re.MULTILINE)
        
        # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        cleaned_content = re.sub(r'\n{3,}', '\n\n', cleaned_content)
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫
        cleaned_content = re.sub(r'^\s+', '', cleaned_content, flags=re.MULTILINE)
        
        if len(content) != len(cleaned_content):
            logger.info(f"üßπ –û—á–∏—â–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç: –±—ã–ª–æ {len(content)} —Å–∏–º–≤–æ–ª–æ–≤, —Å—Ç–∞–ª–æ {len(cleaned_content)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return cleaned_content.strip()
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ AI –æ—Ç–≤–µ—Ç–∞: {e}")
        return content

def smart_split_content(content: str, target_chapters: int) -> list:
    """–£–º–Ω–æ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –≥–ª–∞–≤—ã, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏–∞–ª–æ–≥–æ–≤ –∏ –∞–±–∑–∞—Ü–µ–≤"""
    try:
        logger.info(f"üìù –£–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤) –Ω–∞ {target_chapters} –≥–ª–∞–≤")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ —è–≤–Ω—ã–º –º–∞—Ä–∫–µ—Ä–∞–º –≥–ª–∞–≤
        chapter_patterns = [
            r'\n\s*(–ì–ª–∞–≤–∞|–ì–õ–ê–í–ê|Chapter|CHAPTER)\s+\d+',
            r'\n\s*(–ß–∞—Å—Ç—å|–ß–ê–°–¢–¨|Part|PART)\s+\d+',
            r'\n\s*\d+\.\s*[–ê-–ØA-Z]',
            r'\n\s*[IVX]+\.\s*[–ê-–ØA-Z]',
        ]
        
        for pattern in chapter_patterns:
            splits = re.split(pattern, content, flags=re.MULTILINE | re.IGNORECASE)
            if len(splits) > 1 and len(splits) <= target_chapters * 2:
                # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —á–∞—Å—Ç–∏ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
                chapters = []
                for i, part in enumerate(splits):
                    if part.strip():
                        chapters.append(part.strip())
                if len(chapters) >= 2:
                    logger.info(f"üìñ –†–∞–∑–¥–µ–ª–∏–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É –Ω–∞ {len(chapters)} —á–∞—Å—Ç–µ–π")
                    return chapters
        
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –Ω–∞–π—Ç–∏ —è–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã, —Ä–∞–∑–¥–µ–ª—è–µ–º –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–º –≥—Ä–∞–Ω–∏—Ü–∞–º
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫)
        
        # –ò—â–µ–º –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã (–¥–≤–æ–π–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫)
        sections = content.split('\n\n')
        
        if len(sections) <= target_chapters:
            # –°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Å–µ–∫—Ü–∏–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
            return [content]
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–µ–∫—Ü–∏–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É
        sections_per_chapter = max(1, len(sections) // target_chapters)
        chapters = []
        
        for i in range(0, len(sections), sections_per_chapter):
            chapter_sections = sections[i:i + sections_per_chapter]
            if chapter_sections:
                # –°–æ–µ–¥–∏–Ω—è–µ–º —Å–µ–∫—Ü–∏–∏ –æ–±—Ä–∞—Ç–Ω–æ –¥–≤–æ–π–Ω—ã–º–∏ –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                chapter_content = '\n\n'.join(sec.strip() for sec in chapter_sections if sec.strip())
                if chapter_content:
                    chapters.append(chapter_content)
        
        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è –≥–ª–∞–≤–∞ –ø–æ–ª—É—á–∏–ª–∞—Å—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–π, –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π
        if len(chapters) > 1 and len(chapters[-1]) < 200:  # –£–≤–µ–ª–∏—á–∏–ª–∏ –º–∏–Ω–∏–º—É–º
            chapters[-2] = chapters[-2] + '\n\n' + chapters[-1]
            chapters.pop()
        
        logger.info(f"üìù –†–∞–∑–¥–µ–ª–∏–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–º –≥—Ä–∞–Ω–∏—Ü–∞–º –Ω–∞ {len(chapters)} –≥–ª–∞–≤")
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞–∂–¥–æ–π –≥–ª–∞–≤—ã
        for i, chapter in enumerate(chapters[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            lines_count = len(chapter.split('\n'))
            paragraphs_count = len([p for p in chapter.split('\n\n') if p.strip()])
            logger.info(f"  –ì–ª–∞–≤–∞ {i+1}: {len(chapter)} —Å–∏–º–≤–æ–ª–æ–≤, {lines_count} —Å—Ç—Ä–æ–∫, {paragraphs_count} –∞–±–∑–∞—Ü–µ–≤")
        
        return chapters
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–º–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
        return [content]

def create_epub_from_original(original_epub_path: str, translated_content: str, output_path: str, title_override: str = None) -> bool:
    """
    –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è EPUB - —Ç–µ–ø–µ—Ä—å TransGemini.py –¥–µ–ª–∞–µ—Ç —ç—Ç–æ —Å–∞–º
    """
    logger.info("create_epub_from_original: TransGemini.py —Ç–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–µ—Ç EPUB —Ñ–∞–π–ª—ã –Ω–∞–ø—Ä—è–º—É—é")
    return False  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, —Ç–∞–∫ –∫–∞–∫ TransGemini —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª—ã —Å–∞–º


def create_epub_from_text(content: str, title: str, author: str, output_path: str, chapters_info: dict = None) -> bool:
    """
    –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è EPUB - —Ç–µ–ø–µ—Ä—å TransGemini.py –¥–µ–ª–∞–µ—Ç —ç—Ç–æ —Å–∞–º
    """
    logger.info("create_epub_from_text: TransGemini.py —Ç–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–µ—Ç EPUB —Ñ–∞–π–ª—ã –Ω–∞–ø—Ä—è–º—É—é")
    return False  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, —Ç–∞–∫ –∫–∞–∫ TransGemini —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª—ã —Å–∞–º

def extract_epub_metadata(epub_path: str) -> dict:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ EPUB –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ write_to_epub
    """
    try:
        with zipfile.ZipFile(epub_path, 'r') as epub_zip:
            # –ß–∏—Ç–∞–µ–º container.xml –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—É—Ç–∏ –∫ OPF
            try:
                container_data = epub_zip.read('META-INF/container.xml')
                from xml.etree import ElementTree as ET
                container_root = ET.fromstring(container_data)
                
                # –ù–∞—Ö–æ–¥–∏–º –ø—É—Ç—å –∫ OPF —Ñ–∞–π–ª—É
                opf_path = None
                for rootfile in container_root.iter():
                    if rootfile.tag.endswith('rootfile'):
                        opf_path = rootfile.get('full-path')
                        break
                
                if not opf_path:
                    # Fallback - –∏—â–µ–º .opf —Ñ–∞–π–ª—ã
                    opf_files = [name for name in epub_zip.namelist() if name.endswith('.opf')]
                    opf_path = opf_files[0] if opf_files else None
                
                if not opf_path:
                    logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω OPF —Ñ–∞–π–ª –≤ EPUB")
                    return {
                        'opf_dir': '',
                        'nav_path_in_zip': None,
                        'ncx_path_in_zip': None,
                        'nav_item_id': None,
                        'ncx_item_id': None,
                        'combined_image_map': {}
                    }
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é OPF
                opf_dir = os.path.dirname(opf_path).replace('\\', '/')
                if opf_dir == '.':
                    opf_dir = ''
                
                # –ß–∏—Ç–∞–µ–º OPF —Ñ–∞–π–ª –¥–ª—è –ø–æ–∏—Å–∫–∞ NAV –∏ NCX
                opf_data = epub_zip.read(opf_path)
                opf_root = ET.fromstring(opf_data)
                
                nav_path = None
                ncx_path = None
                nav_id = None
                ncx_id = None
                
                # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã manifest –¥–ª—è NAV –∏ NCX
                for item in opf_root.iter():
                    if item.tag.endswith('item'):
                        href = item.get('href', '')
                        media_type = item.get('media-type', '')
                        properties = item.get('properties', '')
                        item_id = item.get('id', '')
                        
                        # NAV —Ñ–∞–π–ª
                        if 'nav' in properties or 'nav' in href.lower():
                            nav_path = os.path.join(opf_dir, href).replace('\\', '/') if opf_dir else href
                            nav_id = item_id
                            
                        # NCX —Ñ–∞–π–ª
                        elif media_type == 'application/x-dtbncx+xml' or href.endswith('.ncx'):
                            ncx_path = os.path.join(opf_dir, href).replace('\\', '/') if opf_dir else href
                            ncx_id = item_id
                
                logger.info(f"üìã –ò–∑–≤–ª–µ—á–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ EPUB:")
                logger.info(f"   OPF dir: '{opf_dir}'")
                logger.info(f"   NAV path: '{nav_path}' (ID: {nav_id})")
                logger.info(f"   NCX path: '{ncx_path}' (ID: {ncx_id})")
                
                return {
                    'opf_dir': opf_dir,
                    'nav_path_in_zip': nav_path,
                    'ncx_path_in_zip': ncx_path,
                    'nav_item_id': nav_id,
                    'ncx_item_id': ncx_id,
                    'combined_image_map': {}
                }
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è container.xml: {e}")
                return {
                    'opf_dir': '',
                    'nav_path_in_zip': None,
                    'ncx_path_in_zip': None,
                    'nav_item_id': None,
                    'ncx_item_id': None,
                    'combined_image_map': {}
                }
                
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö EPUB: {e}")
        return {
            'opf_dir': '',
            'nav_path_in_zip': None,
            'ncx_path_in_zip': None,
            'nav_item_id': None,
            'ncx_item_id': None,
            'combined_image_map': {}
        }


class UserState:
    def __init__(self):
        self.step = "waiting_file"  # waiting_file -> format_selection -> api_key -> chapter_selection -> translating
        self.action_type: str = "translate"  # "translate" –∏–ª–∏ "glossary"
        self.file_path: Optional[str] = None
        self.file_name: Optional[str] = None
        self.file_format: Optional[str] = None
        self.output_format: Optional[str] = None
        self.api_key: Optional[str] = None
        self.api_keys: List[str] = []  # –°–ø–∏—Å–æ–∫ API –∫–ª—é—á–µ–π –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏
        self.use_key_rotation: bool = False  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–æ—Ç–∞—Ü–∏—é –∫–ª—é—á–µ–π
        self.target_language: str = "—Ä—É—Å—Å–∫–∏–π"
        self.model: str = list(MODELS.keys())[0] if MODELS else "Gemini 2.0 Flash"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
        self.start_chapter: int = 1
        self.chapter_count: int = 0  # 0 = –≤—Å–µ –≥–ª–∞–≤—ã
        self.total_chapters: int = 0  # –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞
        self.chapters_info: Optional[Dict[str, Any]] = None  # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥–ª–∞–≤–∞—Ö
        self.custom_prompt: Optional[str] = None  # –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
        self.temperature: float = 1.0  # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        self.glossary_path: Optional[str] = None  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≥–ª–æ—Å—Å–∞—Ä–∏—è
        self.glossary_data: Dict[str, Any] = {}  # –î–∞–Ω–Ω—ã–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è
        self.session_data: Dict[str, Any] = {}  # –î–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        self.proxy_string: Optional[str] = None  # –°—Ç—Ä–æ–∫–∞ –ø—Ä–æ–∫—Å–∏
        
    def get_settings_dict(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ run_translation_with_auto_restart"""
        return {
            'api_keys': self.api_keys if self.use_key_rotation else [self.api_key] if self.api_key else [],
            'output_folder': str(Path(self.file_path).parent) if self.file_path else "",
            'prompt_template': self.custom_prompt,
            'input_files': [self.file_path] if self.file_path else [],
            'model_name': self.model,
            'output_format': self.output_format,
            'temperature': self.temperature,
            'glossary_data': self.glossary_data,
            'auto_start': True,
            'proxy_string': self.proxy_string
        }

# –°–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
USER_STATES = {}

def get_user_state(user_id: int) -> UserState:
    if user_id not in USER_STATES:
        USER_STATES[user_id] = UserState()
    return USER_STATES[user_id]

def reset_user_state(user_id: int):
    if user_id in USER_STATES:
        del USER_STATES[user_id]

async def handle_apikeys_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /apikeys –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ API –∫–ª—é—á–∞–º–∏"""
    user_id = update.effective_user.id
    user_state = get_user_state(user_id)
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∫–ª—é—á–∏
    current_keys = user_state.api_keys
    
    # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    message = "üîë **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ API –∫–ª—é—á–∞–º–∏**\n\n"
    
    if current_keys:
        message += f"üìã –£ –≤–∞—Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ {len(current_keys)} –∫–ª—é—á–µ–π:\n"
        for i, key in enumerate(current_keys, 1):
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∫–ª—é—á–∞ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            masked_key = key[:5] + "..." + key[-3:] if len(key) > 10 else "***"
            message += f"{i}. `{masked_key}`\n"
    else:
        message += "‚ö†Ô∏è –£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö API –∫–ª—é—á–µ–π.\n"
    
    message += "\n–î–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–ª—é—á–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—ã:\n"
    message += "‚Ä¢ `/addkey –í–ê–®_–ö–õ–Æ–ß` - –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –∫–ª—é—á\n"
    message += "‚Ä¢ `/removekey –ù–û–ú–ï–†` - —É–¥–∞–ª–∏—Ç—å –∫–ª—é—á –ø–æ –Ω–æ–º–µ—Ä—É\n"
    message += "‚Ä¢ `/clearkeys` - —É–¥–∞–ª–∏—Ç—å –≤—Å–µ –∫–ª—é—á–∏\n"
    message += "‚Ä¢ `/rotation on/off` - –≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Ä–æ—Ç–∞—Ü–∏—é –∫–ª—é—á–µ–π\n\n"
    message += f"üîÑ –†–æ—Ç–∞—Ü–∏—è –∫–ª—é—á–µ–π: **{'–í–∫–ª—é—á–µ–Ω–∞' if user_state.use_key_rotation else '–í—ã–∫–ª—é—á–µ–Ω–∞'}**"
    
    await update.message.reply_text(message, parse_mode=ParseMode.MARKDOWN)

async def handle_addkey_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /addkey –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è API –∫–ª—é—á–∞"""
    user_id = update.effective_user.id
    user_state = get_user_state(user_id)
    
    # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–ª—é—á–æ–º –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    try:
        await update.message.delete()
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–ª—é—á–æ–º: {e}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥—ã
    if not context.args or not context.args[0].strip():
        await update.message.reply_text("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ API –∫–ª—é—á: `/addkey –í–ê–®_–ö–õ–Æ–ß`", parse_mode=ParseMode.MARKDOWN)
        return
    
    new_key = context.args[0].strip()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –∫–ª—é—á–∞
    if not re.match(r'^[A-Za-z0-9_-]+$', new_key):
        await update.message.reply_text("‚ö†Ô∏è API –∫–ª—é—á –∏–º–µ–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –ö–ª—é—á –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã, –¥–µ—Ñ–∏—Å—ã –∏ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è.")
        return
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á
    if new_key not in user_state.api_keys:
        user_state.api_keys.append(new_key)
        
        # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π –∫–ª—é—á, —Ç–∞–∫–∂–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –µ–≥–æ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π
        if not user_state.api_key:
            user_state.api_key = new_key
        
        await update.message.reply_text(f"‚úÖ API –∫–ª—é—á –¥–æ–±–∞–≤–ª–µ–Ω. –í—Å–µ–≥–æ –∫–ª—é—á–µ–π: {len(user_state.api_keys)}")
    else:
        await update.message.reply_text("‚ÑπÔ∏è –≠—Ç–æ—Ç –∫–ª—é—á —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Å–ø–∏—Å–æ–∫.")

async def handle_removekey_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /removekey –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è API –∫–ª—é—á–∞ –ø–æ –Ω–æ–º–µ—Ä—É"""
    user_id = update.effective_user.id
    user_state = get_user_state(user_id)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥—ã
    if not context.args or not context.args[0].strip():
        await update.message.reply_text("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä –∫–ª—é—á–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è: `/removekey –ù–û–ú–ï–†`", parse_mode=ParseMode.MARKDOWN)
        return
    
    try:
        key_index = int(context.args[0].strip()) - 1
        if key_index < 0 or key_index >= len(user_state.api_keys):
            await update.message.reply_text(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä –∫–ª—é—á–∞. –î–æ—Å—Ç—É–ø–Ω—ã –Ω–æ–º–µ—Ä–∞ –æ—Ç 1 –¥–æ {len(user_state.api_keys)}.")
            return
        
        removed_key = user_state.api_keys.pop(key_index)
        
        # –ï—Å–ª–∏ —É–¥–∞–ª—è–µ–º –∫–ª—é—á, –∫–æ—Ç–æ—Ä—ã–π –±—ã–ª —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π, –æ–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª—é—á
        if user_state.api_key == removed_key:
            user_state.api_key = user_state.api_keys[0] if user_state.api_keys else None
        
        await update.message.reply_text(f"‚úÖ API –∫–ª—é—á #{key_index+1} —É–¥–∞–ª–µ–Ω. –û—Å—Ç–∞–ª–æ—Å—å –∫–ª—é—á–µ–π: {len(user_state.api_keys)}")
        
    except ValueError:
        await update.message.reply_text("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä –∫–ª—é—á–∞.")

async def handle_clearkeys_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /clearkeys –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤—Å–µ—Ö API –∫–ª—é—á–µ–π"""
    user_id = update.effective_user.id
    user_state = get_user_state(user_id)
    
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
    keyboard = [
        [
            InlineKeyboardButton("–î–∞, —É–¥–∞–ª–∏—Ç—å –≤—Å–µ", callback_data="confirm_clear_keys"),
            InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data="cancel_clear_keys")
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(
        f"‚ö†Ô∏è –í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ —É–¥–∞–ª–∏—Ç—å –≤—Å–µ {len(user_state.api_keys)} API –∫–ª—é—á–µ–π?",
        reply_markup=reply_markup
    )

async def handle_rotation_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /rotation –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è/–≤—ã–∫–ª—é—á–µ–Ω–∏—è —Ä–æ—Ç–∞—Ü–∏–∏ –∫–ª—é—á–µ–π"""
    user_id = update.effective_user.id
    user_state = get_user_state(user_id)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥—ã
    if not context.args or context.args[0].strip().lower() not in ["on", "off"]:
        current_status = "–≤–∫–ª—é—á–µ–Ω–∞" if user_state.use_key_rotation else "–≤—ã–∫–ª—é—á–µ–Ω–∞"
        await update.message.reply_text(
            f"üîÑ –¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å —Ä–æ—Ç–∞—Ü–∏–∏ –∫–ª—é—á–µ–π: **{current_status}**\n\n"
            "–î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —É–∫–∞–∂–∏—Ç–µ:\n"
            "‚Ä¢ `/rotation on` - –≤–∫–ª—é—á–∏—Ç—å —Ä–æ—Ç–∞—Ü–∏—é\n"
            "‚Ä¢ `/rotation off` - –≤—ã–∫–ª—é—á–∏—Ç—å —Ä–æ—Ç–∞—Ü–∏—é",
            parse_mode=ParseMode.MARKDOWN
        )
        return
    
    # –ú–µ–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å —Ä–æ—Ç–∞—Ü–∏–∏
    new_status = context.args[0].strip().lower() == "on"
    user_state.use_key_rotation = new_status
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª—é—á–µ–π –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏
    if new_status and len(user_state.api_keys) < 2:
        await update.message.reply_text(
            "‚ö†Ô∏è –†–æ—Ç–∞—Ü–∏—è –∫–ª—é—á–µ–π –≤–∫–ª—é—á–µ–Ω–∞, –Ω–æ —É –≤–∞—Å –º–µ–Ω—å—à–µ 2 –∫–ª—é—á–µ–π.\n"
            "–î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –∫–ª—é—á–µ–π —Å –ø–æ–º–æ—â—å—é `/addkey` –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Ä–æ—Ç–∞—Ü–∏–∏.",
            parse_mode=ParseMode.MARKDOWN
        )
    else:
        status_text = "–≤–∫–ª—é—á–µ–Ω–∞" if new_status else "–≤—ã–∫–ª—é—á–µ–Ω–∞"
        await update.message.reply_text(f"‚úÖ –†–æ—Ç–∞—Ü–∏—è API –∫–ª—é—á–µ–π {status_text}.")

async def handle_keys_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–ª–±—ç–∫–æ–≤ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–ª—é—á–∞–º–∏"""
    query = update.callback_query
    user_id = query.from_user.id
    user_state = get_user_state(user_id)
    
    await query.answer()  # –û—Ç–≤–µ—á–∞–µ–º –Ω–∞ –∫–æ–ª–±—ç–∫
    
    if query.data == "confirm_clear_keys":
        # –û—á–∏—â–∞–µ–º –≤—Å–µ –∫–ª—é—á–∏
        keys_count = len(user_state.api_keys)
        user_state.api_keys = []
        user_state.api_key = None
        await query.message.edit_text(f"üóëÔ∏è –í—Å–µ {keys_count} API –∫–ª—é—á–µ–π —É–¥–∞–ª–µ–Ω—ã.")
    elif query.data == "cancel_clear_keys":
        # –û—Ç–º–µ–Ω—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ
        await query.message.edit_text("‚ùå –£–¥–∞–ª–µ–Ω–∏–µ API –∫–ª—é—á–µ–π –æ—Ç–º–µ–Ω–µ–Ω–æ.")

async def handle_settings_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /settings –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
    user_id = update.effective_user.id
    user_state = get_user_state(user_id)
    
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    keyboard = [
        [InlineKeyboardButton("üîë API –∫–ª—é—á–∏", callback_data="settings_apikeys")],
        [InlineKeyboardButton("üß† –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–æ–¥–∞", callback_data="settings_model")],
        [InlineKeyboardButton("üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", callback_data="settings_temperature")],
        [InlineKeyboardButton("üìù –ü—Ä–æ–º–ø—Ç", callback_data="settings_prompt")],
        [InlineKeyboardButton("üîÑ –†–æ—Ç–∞—Ü–∏—è –∫–ª—é—á–µ–π", callback_data="settings_rotation")],
        [InlineKeyboardButton("üîç –ì–ª–æ—Å—Å–∞—Ä–∏–π", callback_data="settings_glossary")],
        [InlineKeyboardButton("üåê –ü—Ä–æ–∫—Å–∏", callback_data="settings_proxy")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    model_name = user_state.model
    temperature = user_state.temperature
    rotation_status = "–í–∫–ª—é—á–µ–Ω–∞" if user_state.use_key_rotation else "–í—ã–∫–ª—é—á–µ–Ω–∞"
    api_keys_count = len(user_state.api_keys)
    has_custom_prompt = "–î–∞" if user_state.custom_prompt else "–ù–µ—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π)"
    has_glossary = "–î–∞" if user_state.glossary_data else "–ù–µ—Ç"
    has_proxy = "–ù–∞—Å—Ç—Ä–æ–µ–Ω" if user_state.proxy_string else "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è"
    
    message = (
        "‚öôÔ∏è **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
        f"üîë API –∫–ª—é—á–∏: {api_keys_count} —à—Ç.\n"
        f"üß† –ú–æ–¥–µ–ª—å: {model_name}\n"
        f"üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {temperature}\n"
        f"üîÑ –†–æ—Ç–∞—Ü–∏—è –∫–ª—é—á–µ–π: {rotation_status}\n"
        f"üìù –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {has_custom_prompt}\n"
        f"üîç –ì–ª–æ—Å—Å–∞—Ä–∏–π: {has_glossary}\n"
        f"üåê –ü—Ä–æ–∫—Å–∏: {has_proxy}\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫—É –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:"
    )
    
    await update.message.reply_text(message, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)

async def handle_settings_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–ª–±—ç–∫–æ–≤ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
    query = update.callback_query
    user_id = query.from_user.id
    user_state = get_user_state(user_id)
    
    await query.answer()  # –û—Ç–≤–µ—á–∞–µ–º –Ω–∞ –∫–æ–ª–±—ç–∫
    
    if query.data == "settings_apikeys":
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ API –∫–ª—é—á–∞–º–∏
        await handle_settings_apikeys(query, user_state)
    elif query.data == "settings_model":
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
        await handle_settings_model(query, user_state)
    elif query.data == "settings_temperature":
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
        await handle_settings_temperature(query, user_state)
    elif query.data == "settings_prompt":
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É –ø—Ä–æ–º–ø—Ç–∞
        await handle_settings_prompt(query, user_state)
    elif query.data == "settings_rotation":
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É —Ä–æ—Ç–∞—Ü–∏–∏ –∫–ª—é—á–µ–π
        await handle_settings_rotation(query, user_state)
    elif query.data == "settings_glossary":
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏–µ–º
        await handle_settings_glossary(query, user_state)
    elif query.data == "settings_proxy":
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É –ø—Ä–æ–∫—Å–∏
        await handle_settings_proxy(query, user_state)
    elif query.data.startswith("set_model_"):
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
        model_key = query.data[10:]
        if model_key in MODELS:
            user_state.model = model_key
            await query.message.edit_text(f"‚úÖ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_key}", reply_markup=None)
        else:
            await query.message.edit_text(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {model_key}", reply_markup=None)
    elif query.data.startswith("set_temp_"):
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—ã–±–æ—Ä —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
        try:
            temp_value = float(query.data[9:])
            user_state.temperature = temp_value
            await query.message.edit_text(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {temp_value}", reply_markup=None)
        except ValueError:
            await query.message.edit_text("‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã", reply_markup=None)
    elif query.data == "toggle_rotation":
        # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º —Ä–æ—Ç–∞—Ü–∏—é –∫–ª—é—á–µ–π
        user_state.use_key_rotation = not user_state.use_key_rotation
        status = "–≤–∫–ª—é—á–µ–Ω–∞" if user_state.use_key_rotation else "–≤—ã–∫–ª—é—á–µ–Ω–∞"
        
        if user_state.use_key_rotation and len(user_state.api_keys) < 2:
            await query.message.edit_text(
                f"‚ö†Ô∏è –†–æ—Ç–∞—Ü–∏—è –∫–ª—é—á–µ–π {status}, –Ω–æ —É –≤–∞—Å –º–µ–Ω—å—à–µ 2 –∫–ª—é—á–µ–π.\n"
                "–î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –∫–ª—é—á–µ–π —Å –ø–æ–º–æ—â—å—é `/addkey` –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Ä–æ—Ç–∞—Ü–∏–∏.",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            await query.message.edit_text(f"‚úÖ –†–æ—Ç–∞—Ü–∏—è API –∫–ª—é—á–µ–π {status}.", reply_markup=None)
    elif query.data == "set_custom_prompt":
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
        await query.message.edit_text(
            "üìù –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç-—à–∞–±–ª–æ–Ω –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞.\n\n"
            "–í–∞—à –ø—Ä–æ–º–ø—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å `{text}` –¥–ª—è —É–∫–∞–∑–∞–Ω–∏—è –º–µ—Å—Ç–∞ –≤—Å—Ç–∞–≤–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.\n\n"
            "–î–ª—è –æ—Ç–º–µ–Ω—ã –æ—Ç–ø—Ä–∞–≤—å—Ç–µ /cancel.",
            parse_mode=ParseMode.MARKDOWN
        )
        user_state.step = "waiting_custom_prompt"
    elif query.data == "reset_prompt":
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É
        user_state.custom_prompt = None
        await query.message.edit_text("‚úÖ –ü—Ä–æ–º–ø—Ç —Å–±—Ä–æ—à–µ–Ω –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É.", reply_markup=None)
    elif query.data == "set_proxy":
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ–∫—Å–∏
        await query.message.edit_text(
            "üåê –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ URL –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–∞.\n\n"
            "–§–æ—Ä–º–∞—Ç: `http(s)://user:pass@host:port` –∏–ª–∏ `socks5(h)://host:port`\n\n"
            "–î–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ–∫—Å–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ `none`.\n"
            "–î–ª—è –æ—Ç–º–µ–Ω—ã –æ—Ç–ø—Ä–∞–≤—å—Ç–µ /cancel.",
            parse_mode=ParseMode.MARKDOWN
        )
        user_state.step = "waiting_proxy"
    elif query.data == "reset_proxy":
        # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–∫—Å–∏
        user_state.proxy_string = None
        await query.message.edit_text("‚úÖ –ü—Ä–æ–∫—Å–∏ –æ—Ç–∫–ª—é—á–µ–Ω.", reply_markup=None)
    elif query.data == "upload_glossary":
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ñ–∞–π–ª –≥–ª–æ—Å—Å–∞—Ä–∏—è
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —à–∞–≥, —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å—Å—è –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
        if user_state.step != "waiting_glossary":
            user_state.session_data["previous_step"] = user_state.step
        
        user_state.step = "waiting_glossary"
        
        await query.message.edit_text(
            "üìö –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –≥–ª–æ—Å—Å–∞—Ä–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.\n\n"
            "–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
            "```\n{\n  \"term1\": \"–ø–µ—Ä–µ–≤–æ–¥1\",\n  \"term2\": \"–ø–µ—Ä–µ–≤–æ–¥2\"\n}\n```\n\n"
            "–î–ª—è –æ—Ç–º–µ–Ω—ã –æ—Ç–ø—Ä–∞–≤—å—Ç–µ /cancel.",
            parse_mode=ParseMode.MARKDOWN
        )
    elif query.data == "remove_glossary":
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è
        terms_count = len(user_state.glossary_data) if user_state.glossary_data else 0
        user_state.glossary_data = {}
        
        success_message = f"‚úÖ –ì–ª–æ—Å—Å–∞—Ä–∏–π —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω ({terms_count} —Ç–µ—Ä–º–∏–Ω–æ–≤)."
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —à–∞–≥ –≤—ã–±–æ—Ä–æ–º –≥–ª–∞–≤
        if user_state.session_data.get("previous_step") == "chapter_selection":
            # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫—É –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ –≤—ã–±–æ—Ä—É –≥–ª–∞–≤
            keyboard = [
                [InlineKeyboardButton("‚¨ÖÔ∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –≤—ã–±–æ—Ä—É –≥–ª–∞–≤", callback_data="back_to_chapter_selection")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.message.edit_text(success_message, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ
            await query.message.edit_text(success_message, parse_mode=ParseMode.MARKDOWN)
        
async def handle_settings_apikeys(query, user_state):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ API –∫–ª—é—á–µ–π"""
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∫–ª—é—á–∏
    current_keys = user_state.api_keys
    
    # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    message = "üîë **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ API –∫–ª—é—á–∞–º–∏**\n\n"
    
    if current_keys:
        message += f"üìã –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ {len(current_keys)} –∫–ª—é—á–µ–π:\n"
        for i, key in enumerate(current_keys, 1):
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∫–ª—é—á–∞ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            masked_key = key[:5] + "..." + key[-3:] if len(key) > 10 else "***"
            message += f"{i}. `{masked_key}`\n"
    else:
        message += "‚ö†Ô∏è –ù–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö API –∫–ª—é—á–µ–π.\n"
    
    message += "\n–î–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–ª—é—á–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—ã:\n"
    message += "‚Ä¢ `/addkey –í–ê–®_–ö–õ–Æ–ß` - –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –∫–ª—é—á\n"
    message += "‚Ä¢ `/removekey –ù–û–ú–ï–†` - —É–¥–∞–ª–∏—Ç—å –∫–ª—é—á –ø–æ –Ω–æ–º–µ—Ä—É\n"
    message += "‚Ä¢ `/clearkeys` - —É–¥–∞–ª–∏—Ç—å –≤—Å–µ –∫–ª—é—á–∏\n"
    message += "‚Ä¢ `/rotation on/off` - –≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å —Ä–æ—Ç–∞—Ü–∏—é"
    
    await query.message.edit_text(message, parse_mode=ParseMode.MARKDOWN)

async def handle_settings_model(query, user_state):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–∞"""
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
    keyboard = []
    for model_name in MODELS:
        keyboard.append([InlineKeyboardButton(model_name, callback_data=f"set_model_{model_name}")])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await query.message.edit_text(
        f"üß† **–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
        f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: **{user_state.model}**\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å:",
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_settings_temperature(query, user_state):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã"""
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
    keyboard = [
        [
            InlineKeyboardButton("0.0 (–¥–µ—Ç–µ—Ä–º–∏–Ω.)", callback_data="set_temp_0.0"),
            InlineKeyboardButton("0.5 (–Ω–∏–∑–∫–∞—è)", callback_data="set_temp_0.5")
        ],
        [
            InlineKeyboardButton("0.7 (—Å—Ä–µ–¥–Ω—è—è)", callback_data="set_temp_0.7"),
            InlineKeyboardButton("1.0 (—Å—Ç–∞–Ω–¥–∞—Ä—Ç)", callback_data="set_temp_1.0")
        ],
        [
            InlineKeyboardButton("1.5 (—Ç–≤–æ—Ä—á–µ—Å–∫–∞—è)", callback_data="set_temp_1.5"),
            InlineKeyboardButton("2.0 (–º–∞–∫—Å–∏–º.)", callback_data="set_temp_2.0")
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await query.message.edit_text(
        f"üå°Ô∏è **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏**\n\n"
        f"–¢–µ–∫—É—â–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: **{user_state.temperature}**\n\n"
        f"–ß–µ–º –≤—ã—à–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, —Ç–µ–º –±–æ–ª–µ–µ —Ç–≤–æ—Ä—á–µ—Å–∫–∏–º –±—É–¥–µ—Ç –ø–µ—Ä–µ–≤–æ–¥:\n"
        f"‚Ä¢ 0.0 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π\n"
        f"‚Ä¢ 1.0 - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)\n"
        f"‚Ä¢ 2.0 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–≤–æ—Ä—á–µ—Å–∫–∏–π\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:",
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_settings_prompt(query, user_state):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–æ–º–ø—Ç–∞"""
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É
    keyboard = [
        [InlineKeyboardButton("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç", callback_data="set_custom_prompt")],
        [InlineKeyboardButton("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç", callback_data="reset_prompt")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    prompt_status = "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç" if user_state.custom_prompt else "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç"
    prompt_preview = ""
    if user_state.custom_prompt:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –ø—Ä–æ–º–ø—Ç–∞
        prompt_preview = "\n\n**–¢–µ–∫—É—â–∏–π –ø—Ä–æ–º–ø—Ç:**\n" + user_state.custom_prompt[:200]
        if len(user_state.custom_prompt) > 200:
            prompt_preview += "..."
    
    await query.message.edit_text(
        f"üìù **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
        f"–°—Ç–∞—Ç—É—Å: **{prompt_status}**{prompt_preview}\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_settings_rotation(query, user_state):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Ä–æ—Ç–∞—Ü–∏–∏ –∫–ª—é—á–µ–π"""
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É
    keyboard = [
        [InlineKeyboardButton(
            "–í—ã–∫–ª—é—á–∏—Ç—å —Ä–æ—Ç–∞—Ü–∏—é" if user_state.use_key_rotation else "–í–∫–ª—é—á–∏—Ç—å —Ä–æ—Ç–∞—Ü–∏—é", 
            callback_data="toggle_rotation"
        )]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    status = "–≤–∫–ª—é—á–µ–Ω–∞" if user_state.use_key_rotation else "–≤—ã–∫–ª—é—á–µ–Ω–∞"
    keys_info = f"–ù–∞—Å—Ç—Ä–æ–µ–Ω–æ –∫–ª—é—á–µ–π: {len(user_state.api_keys)}"
    recommendation = ""
    
    if user_state.use_key_rotation and len(user_state.api_keys) < 2:
        recommendation = "\n\n‚ö†Ô∏è –î–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Ä–æ—Ç–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ API –∫–ª—é—á–µ–π."
    
    await query.message.edit_text(
        f"üîÑ **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ API –∫–ª—é—á–µ–π**\n\n"
        f"–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å: **–†–æ—Ç–∞—Ü–∏—è {status}**\n"
        f"{keys_info}{recommendation}\n\n"
        f"–ü—Ä–∏ –≤–∫–ª—é—á–µ–Ω–Ω–æ–π —Ä–æ—Ç–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º–∞ –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –º–µ–∂–¥—É –∫–ª—é—á–∞–º–∏ "
        f"–ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–æ–≤ API –∏–ª–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –æ—à–∏–±–æ–∫.\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_settings_glossary(query, user_state):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≥–ª–æ—Å—Å–∞—Ä–∏—è"""
    try:
        logger.info("–ü–æ–∫–∞–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≥–ª–æ—Å—Å–∞—Ä–∏—è")
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É
        keyboard = [
            [InlineKeyboardButton("–ó–∞–≥—Ä—É–∑–∏—Ç—å –≥–ª–æ—Å—Å–∞—Ä–∏–π (JSON)", callback_data="upload_glossary")]
        ]
        
        if user_state.glossary_data:
            keyboard.append([InlineKeyboardButton("–£–¥–∞–ª–∏—Ç—å —Ç–µ–∫—É—â–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π", callback_data="remove_glossary")])
        
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        glossary_status = "–ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω" if not user_state.glossary_data else f"–ó–∞–≥—Ä—É–∂–µ–Ω ({len(user_state.glossary_data)} —Ç–µ—Ä–º–∏–Ω–æ–≤)"
        
        await query.message.edit_text(
            f"üîç **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏–µ–º**\n\n"
            f"–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å: **{glossary_status}**\n\n"
            f"–ì–ª–æ—Å—Å–∞—Ä–∏–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–¥–∞—Ç—å –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ.\n"
            f"–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª JSON —Å —Ç–µ—Ä–º–∏–Ω–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
            f"```\n{{\n  \"term1\": \"–ø–µ—Ä–µ–≤–æ–¥1\",\n  \"term2\": \"–ø–µ—Ä–µ–≤–æ–¥2\"\n}}\n```\n\n"
            f"–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
            reply_markup=reply_markup,
            parse_mode=ParseMode.MARKDOWN
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∫–∞–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≥–ª–æ—Å—Å–∞—Ä–∏—è: {e}", exc_info=True)
        try:
            await query.message.edit_text(
                "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≥–ª–æ—Å—Å–∞—Ä–∏—è",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_chapter_selection")]])
            )
        except Exception as e2:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ: {e2}")

async def handle_settings_proxy(query, user_state):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–æ–∫—Å–∏"""
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É
    keyboard = [
        [InlineKeyboardButton("–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–∫—Å–∏", callback_data="set_proxy")]
    ]
    
    if user_state.proxy_string:
        keyboard.append([InlineKeyboardButton("–û—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–∫—Å–∏", callback_data="reset_proxy")])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    proxy_status = f"–ù–∞—Å—Ç—Ä–æ–µ–Ω: `{user_state.proxy_string}`" if user_state.proxy_string else "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è"
    
    await query.message.edit_text(
        f"üåê **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∫—Å–∏**\n\n"
        f"–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å: **{proxy_status}**\n\n"
        f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è HTTP(S) –∏ SOCKS5 –ø—Ä–æ–∫—Å–∏.\n"
        f"–§–æ—Ä–º–∞—Ç: `http(s)://user:pass@host:port` –∏–ª–∏ `socks5(h)://host:port`\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_glossary_upload(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞ –≥–ª–æ—Å—Å–∞—Ä–∏—è"""
    user_id = update.effective_user.id
    user_state = get_user_state(user_id)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏
    if user_state.step != "waiting_glossary":
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª
    if not update.message.document:
        await update.message.reply_text("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –≥–ª–æ—Å—Å–∞—Ä–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.")
        return
    
    document = update.message.document
    file_name = document.file_name
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    if not file_name.lower().endswith('.json'):
        await update.message.reply_text("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .json")
        return
    
    # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
    file = await context.bot.get_file(document.file_id)
    file_path = f"temp_glossary_{user_id}.json"
    await file.download_to_drive(file_path)
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º JSON
        with open(file_path, 'r', encoding='utf-8') as f:
            glossary_data = json.load(f)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç
        if not isinstance(glossary_data, dict):
            await update.message.reply_text("‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≥–ª–æ—Å—Å–∞—Ä–∏—è. –î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—å.")
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π
        user_state.glossary_data = glossary_data
        user_state.step = "waiting_file"  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫ –Ω–∞—á–∞–ª—å–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é
        
        await update.message.reply_text(
            f"‚úÖ –ì–ª–æ—Å—Å–∞—Ä–∏–π —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!\n"
            f"üìã –î–æ–±–∞–≤–ª–µ–Ω–æ {len(glossary_data)} —Ç–µ—Ä–º–∏–Ω–æ–≤."
        )
        
    except json.JSONDecodeError:
        await update.message.reply_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å JSON —Ñ–∞–π–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç.")
    except Exception as e:
        await update.message.reply_text(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è: {e}")
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        if os.path.exists(file_path):
            os.remove(file_path)

def get_possible_output_formats_old(input_format: str) -> list:
    """–°—Ç–∞—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –∑–∞–º–µ–Ω–µ–Ω–∞ –Ω–∞ –≤–µ—Ä—Å–∏—é —Å OUTPUT_FORMATS"""
    if input_format in ['txt', 'docx', 'html', 'xml']:
        return ['txt', 'docx', 'html']
    elif input_format == 'epub':
        return ['txt', 'docx', 'html', 'epub']
    else:
        return ['txt']

def determine_input_format(file_extension: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é"""
    for fmt, extensions in SUPPORTED_FORMATS.items():
        if file_extension in extensions:
            return fmt
    return 'txt'  # fallback

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user_id = update.effective_user.id
    reset_user_state(user_id)
    
    welcome_message = """
ü§ñ **–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –±–æ—Ç –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞ —Ñ–∞–π–ª–æ–≤!**

–Ø –º–æ–≥—É –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É—è Google Gemini AI.

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:**
‚Ä¢ TXT - —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
‚Ä¢ DOCX - –¥–æ–∫—É–º–µ–Ω—Ç—ã Word
‚Ä¢ HTML - –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã
‚Ä¢ EPUB - —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏
‚Ä¢ XML - XML –¥–æ–∫—É–º–µ–Ω—Ç—ã

**–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
2. –í—ã–±–µ—Ä–∏—Ç–µ –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç
3. –í–≤–µ–¥–∏—Ç–µ API –∫–ª—é—á Google Gemini
4. –ü–æ–ª—É—á–∏—Ç–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª

–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å! üìÅ
    """
    
    await update.message.reply_text(
        welcome_message,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    user_id = update.effective_user.id
    state = get_user_state(user_id)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≤ —Ä–µ–∂–∏–º–µ –ª–∏ –æ–∂–∏–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
    if state.step == "waiting_glossary":
        document = update.message.document
        file_name = document.file_name
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not file_name.lower().endswith('.json'):
            await update.message.reply_text("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .json")
            return
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        file = await context.bot.get_file(document.file_id)
        file_path = f"temp_glossary_{user_id}.json"
        await file.download_to_drive(file_path)
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º JSON
            with open(file_path, 'r', encoding='utf-8') as f:
                glossary_data = json.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç
            if not isinstance(glossary_data, dict):
                await update.message.reply_text("‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≥–ª–æ—Å—Å–∞—Ä–∏—è. –î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—å.")
                return
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π
            state.glossary_data = glossary_data
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —à–∞–≥ –≤—ã–±–æ—Ä–æ–º –≥–ª–∞–≤
            previous_step = state.session_data.get("previous_step")
            
            if previous_step == "chapter_selection":
                # –ï—Å–ª–∏ –º—ã –ø—Ä–∏—à–ª–∏ –∏–∑ –≤—ã–±–æ—Ä–∞ –≥–ª–∞–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è —Ç—É–¥–∞
                state.step = "chapter_selection"
                
                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∫–Ω–æ–ø–∫—É –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ –≤—ã–±–æ—Ä—É –≥–ª–∞–≤
                keyboard = [
                    [InlineKeyboardButton("‚¨ÖÔ∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –≤—ã–±–æ—Ä—É –≥–ª–∞–≤", callback_data="back_to_chapter_selection")]
                ]
            else:
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫ –Ω–∞—á–∞–ª—å–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é
                state.step = "waiting_file"
                
                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
                keyboard = [
                    [InlineKeyboardButton("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏", callback_data="settings_main")]
                ]
            
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await update.message.reply_text(
                f"‚úÖ –ì–ª–æ—Å—Å–∞—Ä–∏–π —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!\n"
                f"üìã –î–æ–±–∞–≤–ª–µ–Ω–æ {len(glossary_data)} —Ç–µ—Ä–º–∏–Ω–æ–≤.",
                reply_markup=reply_markup
            )
            
        except json.JSONDecodeError:
            await update.message.reply_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å JSON —Ñ–∞–π–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç.")
        except Exception as e:
            await update.message.reply_text(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è: {e}")
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if os.path.exists(file_path):
                os.remove(file_path)
        
        return  # –ü—Ä–µ–∫—Ä–∞—â–∞–µ–º –¥–∞–ª—å–Ω–µ–π—à—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
    if state.step != "waiting_file":
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≤–µ—Ä—à–∏—Ç–µ —Ç–µ–∫—É—â–∏–π –ø—Ä–æ—Ü–µ—Å—Å –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –Ω–∞—á–∞–ª–∞ –∑–∞–Ω–æ–≤–æ.")
        return
    
    document = update.message.document
    if not document:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª.")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–º–∞–∫—Å–∏–º—É–º 20MB –¥–ª—è Telegram)
    if document.file_size > 20 * 1024 * 1024:
        await update.message.reply_text("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 20MB")
        return
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
    file_name = document.file_name
    file_extension = Path(file_name).suffix.lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
    supported_extensions = {'.txt', '.docx', '.html', '.htm', '.epub', '.xml'}
    if file_extension not in supported_extensions:
        await update.message.reply_text(
            f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_extension}\n"
            f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(supported_extensions)}"
        )
        return
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        file = await context.bot.get_file(document.file_id)
        
        # –°–æ–∑–¥–∞–µ–º temporary —Ñ–∞–π–ª
        temp_dir = tempfile.mkdtemp()
        file_path = os.path.join(temp_dir, file_name)
        
        await file.download_to_drive(file_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–∫–∞—á–∞–ª—Å—è
        if not os.path.exists(file_path):
            await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª")
            return
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
        state.file_format = determine_input_format(file_extension)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
        state.file_path = file_path
        state.file_name = file_name
        state.step = "format_selection"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        await show_format_selection(update, state)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")

async def show_format_selection(update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã–±–æ—Ä –º–µ–∂–¥—É —Å–æ–∑–¥–∞–Ω–∏–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏—è –∏ –ø–µ—Ä–µ–≤–æ–¥–æ–º"""
    keyboard = [
        [InlineKeyboardButton("üìñ –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ñ–∞–π–ª", callback_data="action_translate")],
        [InlineKeyboardButton("üìö –°–æ–∑–¥–∞—Ç—å –≥–ª–æ—Å—Å–∞—Ä–∏–π", callback_data="action_glossary")]
    ]
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    message_text = (
        f"üìÅ –§–∞–π–ª –ø–æ–ª—É—á–µ–Ω: `{state.file_name}`\n"
        f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.file_format.upper()}`\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:"
    )
    
    try:
        if hasattr(update, 'edit_message_text'):
            # –≠—Ç–æ CallbackQuery
            await update.edit_message_text(
                message_text,
                reply_markup=reply_markup,
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            # –≠—Ç–æ Update, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            await update.message.reply_text(
                message_text,
                reply_markup=reply_markup,
                parse_mode=ParseMode.MARKDOWN
            )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

async def handle_format_selection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏—è (–ø–µ—Ä–µ–≤–æ–¥ –∏–ª–∏ –≥–ª–æ—Å—Å–∞—Ä–∏–π)"""
    query = update.callback_query
    user_id = query.from_user.id
    state = get_user_state(user_id)
    
    if state.step != "format_selection":
        await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–π —à–∞–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞")
        return
    
    callback_data = query.data
    
    if callback_data == "action_translate":
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –≤—ã–±–æ—Ä—É –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
        await query.answer("–í—ã–±—Ä–∞–Ω –ø–µ—Ä–µ–≤–æ–¥ —Ñ–∞–π–ª–∞")
        await show_output_format_selection(query, state)
        
    elif callback_data == "action_glossary":
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–æ–∑–¥–∞–Ω–∏—é –≥–ª–æ—Å—Å–∞—Ä–∏—è
        await query.answer("–í—ã–±—Ä–∞–Ω–æ —Å–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è")
        state.action_type = "glossary"
        state.step = "api_key"
        await show_api_key_request(query, state)
    else:
        await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")

async def show_api_key_request(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å API –∫–ª—é—á–∞"""
    action_text = "—Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è" if getattr(state, 'action_type', '') == "glossary" else "–ø–µ—Ä–µ–≤–æ–¥–∞"
    
    try:
        if hasattr(update, 'edit_message_text'):
            # –≠—Ç–æ CallbackQuery
            await update.edit_message_text(
                f"üîë **API –∫–ª—é—á Google Gemini**\n\n"
                f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
                f"üéØ –î–µ–π—Å—Ç–≤–∏–µ: {action_text}\n\n"
                f"–î–ª—è —Ä–∞–±–æ—Ç—ã —Å Google Gemini API –Ω–µ–æ–±—Ö–æ–¥–∏–º API –∫–ª—é—á.\n\n"
                f"**–ü–æ–ª—É—á–∏—Ç—å –∫–ª—é—á:**\n"
                f"1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ [Google AI Studio](https://aistudio.google.com/app/apikey)\n"
                f"2. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π API –∫–ª—é—á\n"
                f"3. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –µ–≥–æ –±–æ—Ç—É\n\n"
                f"üîí –í–∞—à –∫–ª—é—á –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞",
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            # –≠—Ç–æ Update, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            await update.message.reply_text(
                f"üîë **API –∫–ª—é—á Google Gemini**\n\n"
                f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
                f"üéØ –î–µ–π—Å—Ç–≤–∏–µ: {action_text}\n\n"
                f"–î–ª—è —Ä–∞–±–æ—Ç—ã —Å Google Gemini API –Ω–µ–æ–±—Ö–æ–¥–∏–º API –∫–ª—é—á.\n\n"
                f"**–ü–æ–ª—É—á–∏—Ç—å –∫–ª—é—á:**\n"
                f"1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ [Google AI Studio](https://aistudio.google.com/app/apikey)\n"
                f"2. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π API –∫–ª—é—á\n"
                f"3. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –µ–≥–æ –±–æ—Ç—É\n\n"
                f"üîí –í–∞—à –∫–ª—é—á –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞",
                parse_mode=ParseMode.MARKDOWN
            )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ API –∫–ª—é—á–∞: {e}")

async def show_output_format_selection(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã–±–æ—Ä –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
    # –ü–æ–ª—É—á–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
    possible_formats = get_possible_output_formats(state.file_format)
    
    keyboard = []
    for display_name, format_code in possible_formats:
        keyboard.append([InlineKeyboardButton(display_name, callback_data=f"format_{format_code}")])
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É "–ù–∞–∑–∞–¥"
    keyboard.append([InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_action_selection")])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    try:
        await update.edit_message_text(
            f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
            f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.file_format.upper()}`\n\n"
            f"–í—ã–±–µ—Ä–∏—Ç–µ –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞:",
            reply_markup=reply_markup,
            parse_mode=ParseMode.MARKDOWN
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

async def handle_output_format_selection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞"""
    query = update.callback_query
    user_id = query.from_user.id
    state = get_user_state(user_id)
    
    callback_data = query.data
    
    if callback_data == "back_to_action_selection":
        await query.answer()
        state.step = "format_selection"
        await show_format_selection(query, state)
        return
    
    if not callback_data.startswith("format_"):
        await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        return
    
    selected_format = callback_data.replace("format_", "")
    state.output_format = selected_format
    state.action_type = "translate"
    state.step = "api_key"
    
    await query.answer()
    await show_api_key_request(query, state)

async def handle_text_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user_id = update.effective_user.id
    state = get_user_state(user_id)
    
    if state.step == "api_key":
        await handle_api_key(update, context)
    elif state.step == "chapter_input":
        await handle_chapter_input(update, context)
    elif state.step == "waiting_custom_prompt":
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        prompt_text = update.message.text.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∞ {text}
        if "{text}" not in prompt_text:
            await update.message.reply_text(
                "‚ö†Ô∏è –í –ø—Ä–æ–º–ø—Ç–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä `{text}` –¥–ª—è —É–∫–∞–∑–∞–Ω–∏—è –º–µ—Å—Ç–∞ –≤—Å—Ç–∞–≤–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –ø—Ä–æ–º–ø—Ç —Å–Ω–æ–≤–∞ –∏–ª–∏ /cancel –¥–ª—è –æ—Ç–º–µ–Ω—ã.",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç
        state.custom_prompt = prompt_text
        state.step = "waiting_file"  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫ –Ω–∞—á–∞–ª—å–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é
        
        # –î–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—ã—Ç–∞–µ–º—Å—è —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–æ–º–ø—Ç–æ–º
        try:
            await update.message.delete()
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–æ–º–ø—Ç–æ–º: {e}")
        
        await update.message.reply_text("‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
    
    elif state.step == "waiting_proxy":
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–∫—Å–∏
        proxy_text = update.message.text.strip().lower()
        
        if proxy_text == "none":
            state.proxy_string = None
            state.step = "waiting_file"
            await update.message.reply_text("‚úÖ –ü—Ä–æ–∫—Å–∏ –æ—Ç–∫–ª—é—á–µ–Ω!")
            return
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–∫—Å–∏
        if (not proxy_text.startswith(("http://", "https://", "socks4://", "socks5://", "socks5h://")) or 
            "://" not in proxy_text):
            await update.message.reply_text(
                "‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç URL –ø—Ä–æ–∫—Å–∏.\n"
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç: `http(s)://user:pass@host:port` –∏–ª–∏ `socks5(h)://host:port`\n"
                "–î–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤—å—Ç–µ `none` –∏–ª–∏ /cancel –¥–ª—è –æ—Ç–º–µ–Ω—ã.",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–∫—Å–∏
        state.proxy_string = proxy_text
        state.step = "waiting_file"
        
        # –î–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —É–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–æ–∫—Å–∏
        try:
            await update.message.delete()
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–æ–∫—Å–∏: {e}")
        
        await update.message.reply_text(f"‚úÖ –ü—Ä–æ–∫—Å–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {proxy_text.split('@')[-1]}")
    
    elif state.step == "waiting_glossary":
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª —Ç–µ–∫—Å—Ç –≤–º–µ—Å—Ç–æ —Ñ–∞–π–ª–∞ –≥–ª–æ—Å—Å–∞—Ä–∏—è
        await update.message.reply_text(
            "‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –≥–ª–æ—Å—Å–∞—Ä–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.\n"
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /cancel –¥–ª—è –æ—Ç–º–µ–Ω—ã."
        )
    
    else:
        # –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        await update.message.reply_text(
            "ü§î –Ø –Ω–µ –ø–æ–Ω–∏–º–∞—é, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å.\n"
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã –∏–ª–∏ /help –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏."
        )

async def validate_api_key(api_key: str) -> tuple[bool, str]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞ —á–µ—Ä–µ–∑ Google Gemini API"""
    try:
        if not genai or not google_exceptions:
            return False, "Google API –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã"
            
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º API
        genai.configure(api_key=api_key)
        
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–ª—é—á–∞
        models = genai.list_models()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Gemini
        gemini_models = [m for m in models if m.name.startswith("models/")]
        
        if gemini_models:
            return True, "API –∫–ª—é—á –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω."
        else:
            return False, "–ö–ª—é—á –ø—Ä–∏–Ω—è—Ç API, –Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Gemini."
            
    except google_exceptions.Unauthenticated as e:
        return False, f"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–Ω–µ–≤–µ—Ä–Ω—ã–π –∫–ª—é—á): {str(e)}"
    except Exception as e:
        return False, f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ API –∫–ª—é—á–∞: {str(e)}"

async def handle_api_key(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ API –∫–ª—é—á–∞"""
    user_id = update.effective_user.id
    state = get_user_state(user_id)
    
    if state.step != "api_key":
        return
    
    api_key = update.message.text.strip()
    
    # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞
    if len(api_key) < 30 or not api_key.startswith('AI'):
        await update.message.reply_text(
            "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç API –∫–ª—é—á–∞.\n"
            "API –∫–ª—é—á –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å 'AI' –∏ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–º.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
        )
        return
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–ª—é—á–∞
    checking_message = await update.message.reply_text(
        "üîç **–ü—Ä–æ–≤–µ—Ä—è—é API –∫–ª—é—á...**\n\n"
        "‚è≥ –í—ã–ø–æ–ª–Ω—è—é —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ Google Gemini API...",
        parse_mode=ParseMode.MARKDOWN
    )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞
    is_valid, validation_message = await validate_api_key(api_key)
    
    if is_valid:
        # –ö–ª—é—á –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω
        state.api_key = api_key
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞ –¥–µ–π—Å—Ç–≤–∏–µ –≤—ã–±—Ä–∞–Ω–æ
        if getattr(state, 'action_type', '') == "glossary":
            # –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–∏
            state.step = "glossary_model_selection"
            
            await checking_message.edit_text(
                "‚úÖ **API –∫–ª—é—á –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω!**\n\n"
                "üîë –ö–ª—é—á —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω\n"
                "ü§ñ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è...",
                parse_mode=ParseMode.MARKDOWN
            )
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–ª–æ—Å—Å–∞—Ä–∏—è
            await show_glossary_model_selection(update, state)
        else:
            # –û–±—ã—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥
            state.step = "chapter_selection"
            
            await checking_message.edit_text(
                "‚úÖ **API –∫–ª—é—á –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω!**\n\n"
                "üîë –ö–ª—é—á —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω\n"
                "üìù –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ñ–∞–π–ª –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≥–ª–∞–≤...",
                parse_mode=ParseMode.MARKDOWN
            )
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–ª–∞–≤
            await analyze_file_chapters(update, state)
        
    else:
        # –ö–ª—é—á –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω
        await checking_message.edit_text(
            "‚ùå **API –∫–ª—é—á –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω**\n\n"
            f"üö´ {validation_message}\n\n"
            "**–ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á:**\n"
            "1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ https://aistudio.google.com/\n"
            "2. –í–æ–π–¥–∏—Ç–µ –≤ –∞–∫–∫–∞—É–Ω—Ç Google\n"
            "3. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π API –∫–ª—é—á\n"
            "4. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ–≥–æ –º–Ω–µ\n\n"
            "üîê –û—Ç–ø—Ä–∞–≤—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π API –∫–ª—é—á:",
            parse_mode=ParseMode.MARKDOWN
        )

async def show_glossary_model_selection(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è"""
    keyboard = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–ª–æ—Å—Å–∞—Ä–∏—è
    for model_name in MODELS.keys():
        # –°–æ–∑–¥–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –∫–Ω–æ–ø–æ–∫
        short_name = model_name.replace("Gemini ", "").replace("gemma", "Gemma")
        if len(short_name) > 25:  # –û–±—Ä–µ–∑–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            short_name = short_name[:22] + "..."
        
        keyboard.append([InlineKeyboardButton(
            f"ü§ñ {short_name}", 
            callback_data=f"glossary_model_{model_name}"
        )])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    try:
        await update.message.reply_text(
            f"ü§ñ **–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–ª–æ—Å—Å–∞—Ä–∏—è**\n\n"
            f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
            f"üìö –î–µ–π—Å—Ç–≤–∏–µ: –°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è\n\n"
            f"**–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:**\n"
            f"‚Ä¢ **Gemini 2.5** - –ù–æ–≤–µ–π—à–∏–µ –º–æ–¥–µ–ª–∏ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)\n"
            f"‚Ä¢ **Gemini 2.0** - –ë—ã—Å—Ç—Ä—ã–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ\n"
            f"‚Ä¢ **Gemini 1.5** - –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–µ–º\n\n"
            f"–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è:",
            reply_markup=reply_markup,
            parse_mode=ParseMode.MARKDOWN
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∫–∞–∑–∞ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–ª–æ—Å—Å–∞—Ä–∏—è: {e}")

async def start_glossary_creation(update: Update, state: UserState):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è –ø–æ –ª–æ–≥–∏–∫–µ Worker.py"""
    try:
        # –ü—Ä–æ–º–ø—Ç –∏–∑ Launcher.py (—Ç–æ—á–Ω–∞—è –∫–æ–ø–∏—è)
        glossary_prompt = """–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ª–∏–Ω–≥–≤–∏—Å—Ç-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Å–æ–∑–¥–∞—Ç—å –≥–ª–æ—Å—Å–∞—Ä–∏–π —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –∫–Ω–∏–≥–∏.

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –ù–∞–π–¥–∏ –≤ —Ç–µ–∫—Å—Ç–µ –í–°–ï:
   - –ò–º–µ–Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π (–≤–∫–ª—é—á–∞—è –ø—Ä–æ–∑–≤–∏—â–∞, —Ç–∏—Ç—É–ª—ã)
   - –ù–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—Ç, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π, —Ç–µ—Ö–Ω–∏–∫, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
   - –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –ø–æ–Ω—è—Ç–∏—è –º–∏—Ä–∞ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
   - –£—Å—Ç–æ–π—á–∏–≤—ã–µ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏—è –∏ —Ç–∏—Ç—É–ª—ã

2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–∏ –û–î–ò–ù –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫.

3. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∂–∞–Ω—Ä –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ.

4. –ù–ï –≤–∫–ª—é—á–∞–π –≤ –≥–ª–æ—Å—Å–∞—Ä–∏–π:
   - –û–±—ã—á–Ω—ã–µ —Å–ª–æ–≤–∞ –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
   - –¢–µ—Ä–º–∏–Ω—ã, –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Ç–æ–ª—å–∫–æ 1 —Ä–∞–∑ (–µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –∫–ª—é—á–µ–≤–æ–µ –∏–º—è/–Ω–∞–∑–≤–∞–Ω–∏–µ)

–§–û–†–ú–ê–¢ –í–´–í–û–î–ê (—Å—Ç—Ä–æ–≥–æ JSON):
{{
  "—Ç–µ—Ä–º–∏–Ω_–Ω–∞_–æ—Ä–∏–≥–∏–Ω–∞–ª–µ": "–ø–µ—Ä–µ–≤–æ–¥_–Ω–∞_—Ä—É—Å—Å–∫–∏–π",
  "Son Goku": "–°–æ–Ω –ì–æ–∫—É",
  "Kamehameha": "–ö–∞–º–µ—Ö–∞–º–µ—Ö–∞"
}}

–í–ê–ñ–ù–û: 
- –í—ã–≤–æ–¥–∏ –¢–û–õ–¨–ö–û JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
- –°–æ—Ö—Ä–∞–Ω—è–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ (—Ä–µ–≥–∏—Å—Ç—Ä –±—É–∫–≤)
- –î–ª—è –∏–º—ë–Ω –∏—Å–ø–æ–ª—å–∑—É–π –±–ª–∞–≥–æ–∑–≤—É—á–Ω—É—é —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é
- –î–ª—è —Ç–µ—Ä–º–∏–Ω–æ–≤ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–π –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏

–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
{text}"""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–ª–∞–≤—ã –∏–∑ —Ñ–∞–π–ª–∞ (–∫–∞–∫ –≤ Worker.py)
        chapters = await extract_chapters_from_file(state.file_path, state.file_format)
        
        if not chapters:
            await update.message.reply_text(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≥–ª–∞–≤—ã –∏–∑ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è.",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è
        progress_message = await update.message.reply_text(
            f"üìö –°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è\n\n"
            f"üìÅ –§–∞–π–ª: {state.file_name}\n"
            f"üìÑ –§–æ—Ä–º–∞—Ç: {state.file_format.upper()}\n"
            f"üìä –ù–∞–π–¥–µ–Ω–æ –≥–ª–∞–≤: {len(chapters)}\n\n"
            "üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≥–ª–∞–≤—ã –∏ —Å–æ–∑–¥–∞—é –≥–ª–æ—Å—Å–∞—Ä–∏–π —Ç–µ—Ä–º–∏–Ω–æ–≤...\n"
            "‚è≥ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç..."
        )
        
        # –°–æ–∑–¥–∞–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π —á–µ—Ä–µ–∑ API
        import google.generativeai as genai
        genai.configure(api_key=state.api_key)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        model_name = getattr(state, 'glossary_model', "models/gemini-2.5-flash")
        model = genai.GenerativeModel(model_name)
        
        # –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–π –≥–ª–æ—Å—Å–∞—Ä–∏–π (–∫–∞–∫ –≤ Worker.py)
        current_glossary = {}
        processed_chapters = 0
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –≥–ª–∞–≤—É –æ—Ç–¥–µ–ª—å–Ω–æ (–ª–æ–≥–∏–∫–∞ Worker.py)
        for i, (chapter_name, chapter_text) in enumerate(chapters, 1):
            try:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                await progress_message.edit_text(
                    f"üìö –°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è\n\n"
                    f"üìÅ –§–∞–π–ª: {state.file_name}\n"
                    f"üìÑ –§–æ—Ä–º–∞—Ç: {state.file_format.upper()}\n"
                    f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≥–ª–∞–≤: {i-1}/{len(chapters)}\n"
                    f"üìñ –¢–µ–∫—É—â–∞—è –≥–ª–∞–≤–∞: {chapter_name}\n"
                    f"üîÑ –ù–∞–π–¥–µ–Ω–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(current_glossary)}\n\n"
                    "‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≥–ª–∞–≤—É..."
                )
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã (–∫–∞–∫ –≤ Worker.py)
                limited_text = chapter_text[:30000]
                prompt = glossary_prompt.format(text=limited_text)
                
                # –î–µ–ª–∞–µ–º API –∑–∞–ø—Ä–æ—Å (—Å retry –ª–æ–≥–∏–∫–æ–π –∫–∞–∫ –≤ Worker.py)
                response = await asyncio.get_event_loop().run_in_executor(
                    None, 
                    lambda: generate_content_with_retry(model, prompt, chapter_name)
                )
                
                if response and response.text:
                    # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–≥–∏–∫—É Worker.py)
                    chapter_terms = parse_glossary_response(response)
                    
                    if chapter_terms:
                        # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º —Ç–µ—Ä–º–∏–Ω—ã (–ª–æ–≥–∏–∫–∞ Worker.py: if term not in current_glossary)
                        for term, definition in chapter_terms.items():
                            if term not in current_glossary:
                                current_glossary[term] = definition
                        
                        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –≥–ª–∞–≤–∞ {chapter_name}, –¥–æ–±–∞–≤–ª–µ–Ω–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(chapter_terms)}, –≤—Å–µ–≥–æ: {len(current_glossary)}")
                
                processed_chapters += 1
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                await asyncio.sleep(1)
                        
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–ª–∞–≤—ã {chapter_name}: {e}")
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if current_glossary:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            state.glossary_data = current_glossary
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –≥–ª–æ—Å—Å–∞—Ä–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            import json
            glossary_json = json.dumps(current_glossary, ensure_ascii=False, indent=2)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π –∫–∞–∫ —Ñ–∞–π–ª
            import io
            glossary_file = io.BytesIO(glossary_json.encode('utf-8'))
            glossary_file.name = f"glossary_{state.file_name.split('.')[0]}.json"
            
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –¥–ª—è Markdown
            safe_filename = state.file_name.replace('_', '\\_').replace('*', '\\*').replace('[', '\\[').replace(']', '\\]').replace('(', '\\(').replace(')', '\\)').replace('~', '\\~').replace('`', '\\`').replace('>', '\\>').replace('#', '\\#').replace('+', '\\+').replace('-', '\\-').replace('=', '\\=').replace('|', '\\|').replace('{', '\\{').replace('}', '\\}').replace('.', '\\.')
            
            await progress_message.edit_text(
                "‚úÖ –ì–ª–æ—Å—Å–∞—Ä–∏–π —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!\n\n"
                f"üìÅ –§–∞–π–ª: {state.file_name}\n"
                f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≥–ª–∞–≤: {processed_chapters}/{len(chapters)}\n"
                f"üìö –ù–∞–π–¥–µ–Ω–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(current_glossary)}\n\n"
                "üì• –§–∞–π–ª –≥–ª–æ—Å—Å–∞—Ä–∏—è –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.\n"
                "üíæ –ì–ª–æ—Å—Å–∞—Ä–∏–π —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ø–∞–º—è—Ç–∏ –±–æ—Ç–∞ –¥–ª—è –±—É–¥—É—â–∏—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤."
            )
            
            await update.message.reply_document(
                document=glossary_file,
                caption=f"üìö –ì–ª–æ—Å—Å–∞—Ä–∏–π –¥–ª—è —Ñ–∞–π–ª–∞: {state.file_name}\nüìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(current_glossary)}"
            )
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            state.step = "waiting_file"
        else:
            await progress_message.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è\n\n"
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ {processed_chapters} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≥–ª–∞–≤.\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —Å –¥—Ä—É–≥–∏–º —Ñ–∞–π–ª–æ–º."
            )
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è: {e}", exc_info=True)
        await update.message.reply_text(
            f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è\n\n"
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"
        )

def generate_content_with_retry(model, prompt, chapter_name):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç —Å retry –ª–æ–≥–∏–∫–æ–π –∫–∞–∫ –≤ Worker.py"""
    import time
    import random
    from google.api_core.exceptions import ResourceExhausted, DeadlineExceeded
    
    max_retries = 5
    base_delay = 5
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt, request_options={"timeout": 120})
            return response
        except ResourceExhausted as e:
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                logger.warning(f"Rate limit hit for chapter {chapter_name}. Retrying in {delay:.2f} seconds... (Attempt {attempt + 1}/{max_retries})")
                time.sleep(delay)
            else:
                logger.error(f"API limit reached for chapter {chapter_name} after {max_retries} attempts.")
                raise e
        except DeadlineExceeded as e:
            logger.error(f"API timeout for chapter {chapter_name}: {str(e)}")
            return None

    return None

def parse_glossary_response(response) -> dict:
    """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç AI –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≥–ª–æ—Å—Å–∞—Ä–∏–π (–ø–æ –ª–æ–≥–∏–∫–µ Worker.py)"""
    import json
    
    try:
        if not response or not hasattr(response, 'text') or not response.text:
            return {}
            
        cleaned_text = response.text.strip()
        if not cleaned_text:
            logger.warning("Received empty response from API.")
            return {}

        if cleaned_text.startswith("```json"):
            cleaned_text = cleaned_text[7:]
        if cleaned_text.endswith("```"):
            cleaned_text = cleaned_text[:-3]
        
        return json.loads(cleaned_text)

    except json.JSONDecodeError:
        logger.error(f"Failed to decode JSON from API response: {response.text[:200]}")
        return {}
    except Exception as e:
        logger.error(f"An unexpected error occurred in parse_glossary_response: {str(e)}")
        return {}

async def handle_glossary_model_selection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–ª–æ—Å—Å–∞—Ä–∏—è"""
    query = update.callback_query
    user_id = query.from_user.id
    state = get_user_state(user_id)
    
    if state.step != "glossary_model_selection":
        await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–π —à–∞–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞")
        return
    
    callback_data = query.data
    
    if not callback_data.startswith("glossary_model_"):
        await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
    selected_model = callback_data.replace("glossary_model_", "")
    if selected_model not in MODELS:
        await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å")
        return
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º ID –º–æ–¥–µ–ª–∏ –¥–ª—è API (–∫–∞–∫ –≤ Worker.py)
    state.glossary_model = MODELS[selected_model]["id"]
    state.step = "glossary_ready"
    
    await query.answer(f"–í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {selected_model}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É "–ù–∞—á–∞—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è"
    await show_glossary_start_options(query, state)

async def show_glossary_start_options(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–ø—Ü–∏–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è"""
    keyboard = [
        [InlineKeyboardButton("üìö –ù–∞—á–∞—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è", callback_data="start_glossary_creation")],
        [InlineKeyboardButton("ü§ñ –ò–∑–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å", callback_data="change_glossary_model")],
        [InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –∫ –≤—ã–±–æ—Ä—É –¥–µ–π—Å—Ç–≤–∏—è", callback_data="back_to_action_selection")]
    ]
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    try:
        await update.edit_message_text(
            f"üîß **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–ª–æ—Å—Å–∞—Ä–∏—è**\n\n"
            f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
            f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.file_format.upper()}`\n"
            f"ü§ñ –ú–æ–¥–µ–ª—å: `{state.model}`\n\n"
            f"–ì–æ—Ç–æ–≤ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –≥–ª–æ—Å—Å–∞—Ä–∏—è.\n"
            f"–ì–ª–æ—Å—Å–∞—Ä–∏–π –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å:\n"
            f"‚Ä¢ –ò–º–µ–Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π\n"
            f"‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—Ç –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π\n"
            f"‚Ä¢ –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã\n"
            f"‚Ä¢ –¢–µ—Ö–Ω–∏–∫–∏ –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã\n\n"
            f"–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
            reply_markup=reply_markup,
            parse_mode=ParseMode.MARKDOWN
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∫–∞–∑–∞ –æ–ø—Ü–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏—è: {e}")

async def handle_glossary_options(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ–ø—Ü–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏—è"""
    query = update.callback_query
    user_id = query.from_user.id
    state = get_user_state(user_id)
    
    callback_data = query.data
    
    if callback_data == "start_glossary_creation":
        await query.answer("–ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è")
        state.step = "creating_glossary"
        await start_glossary_creation(query, state)
        
    elif callback_data == "change_glossary_model":
        await query.answer()
        state.step = "glossary_model_selection"
        await show_glossary_model_selection(query, state)
        
    elif callback_data == "back_to_action_selection":
        await query.answer()
        state.step = "format_selection"
        await show_format_selection(query, state)

async def extract_chapters_from_file(file_path: str, file_format: str) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–ª–∞–≤—ã –∏–∑ —Ñ–∞–π–ª–∞ (–ª–æ–≥–∏–∫–∞ Worker.py)"""
    try:
        chapters = []
        
        if file_format == 'epub':
            # –î–ª—è EPUB —Ñ–∞–π–ª–æ–≤ - –∏–∑–≤–ª–µ–∫–∞–µ–º –≥–ª–∞–≤—ã –∫–∞–∫ –≤ Worker.py
            import zipfile
            from bs4 import BeautifulSoup
            import ebooklib
            from ebooklib import epub
            
            try:
                # –ß–∏—Ç–∞–µ–º EPUB –∫–∞–∫ –≤ Worker.py
                book = epub.read_epub(file_path)
                epub_chapters = [item for item in book.get_items_of_type(ebooklib.ITEM_DOCUMENT)]
                
                for chapter in epub_chapters:
                    chapter_name = chapter.get_name()
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã (–∫–∞–∫ –≤ Worker.py)
                    soup = BeautifulSoup(chapter.get_content(), "lxml")
                    chapter_text = soup.get_text(separator=" ", strip=True)
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –≥–ª–∞–≤—ã
                    if chapter_text and len(chapter_text) > 100:
                        chapters.append((chapter_name, chapter_text))
                        
                logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(chapters)} –≥–ª–∞–≤ –∏–∑ EPUB —Ñ–∞–π–ª–∞")
                return chapters
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è EPUB —á–µ—Ä–µ–∑ ebooklib: {e}")
                # Fallback - –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ zipfile (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥)
                with zipfile.ZipFile(file_path, 'r') as epub_zip:
                    html_files = [
                        name for name in epub_zip.namelist()
                        if name.lower().endswith(('.html', '.xhtml', '.htm'))
                        and not name.startswith(('__MACOSX', 'META-INF/'))
                    ]
                    
                    for html_file in html_files:
                        try:
                            content = epub_zip.read(html_file).decode('utf-8', errors='ignore')
                            soup = BeautifulSoup(content, 'lxml')
                            text = soup.get_text(separator=' ', strip=True)
                            if text and len(text) > 100:
                                chapters.append((html_file, text))
                        except Exception as e:
                            logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {html_file}: {e}")
                            continue
                
                return chapters
                
        elif file_format == 'txt':
            # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ - —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Å–µ–≤–¥–æ-–≥–ª–∞–≤—ã
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                full_text = f.read()
            
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –≥–ª–∞–≤
            chapter_patterns = [
                r'\n\s*Chapter\s+\d+',
                r'\n\s*CHAPTER\s+\d+', 
                r'\n\s*–ì–ª–∞–≤–∞\s+\d+',
                r'\n\s*–ì–õ–ê–í–ê\s+\d+',
                r'\n\s*\d+\.\s*',
                r'\n\s*\*\*\*\s*\n',
                r'\n\s*---\s*\n'
            ]
            
            import re
            for pattern in chapter_patterns:
                splits = re.split(pattern, full_text)
                if len(splits) > 3:  # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –≥–ª–∞–≤—ã
                    for i, chapter_text in enumerate(splits[1:], 1):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å –¥–æ –ø–µ—Ä–≤–æ–π –≥–ª–∞–≤—ã
                        if len(chapter_text.strip()) > 500:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –≥–ª–∞–≤—ã
                            chapters.append((f"Chapter_{i}", chapter_text.strip()))
                    if chapters:
                        logger.info(f"–†–∞–∑–±–∏—Ç –Ω–∞ {len(chapters)} –≥–ª–∞–≤ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É: {pattern}")
                        return chapters
            
            # –ï—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏ - —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∫—É—Å–∫–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É
            chunk_size = 10000  # 10K —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ –≥–ª–∞–≤—É
            for i in range(0, len(full_text), chunk_size):
                chunk = full_text[i:i + chunk_size]
                if len(chunk.strip()) > 500:
                    chapters.append((f"Part_{i//chunk_size + 1}", chunk.strip()))
            
            return chapters
                
        elif file_format == 'docx':
            # –î–ª—è DOCX —Ñ–∞–π–ª–æ–≤ - –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–±–∏—Ç—å –Ω–∞ –≥–ª–∞–≤—ã –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º
            import docx
            doc = docx.Document(file_path)
            
            current_chapter = ""
            chapter_num = 1
            
            for paragraph in doc.paragraphs:
                text = paragraph.text.strip()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ –Ω–æ–≤–∞—è –≥–ª–∞–≤–∞
                if any(keyword in text.lower() for keyword in ['chapter', '–≥–ª–∞–≤–∞']) and len(text) < 100:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –≥–ª–∞–≤—É
                    if current_chapter and len(current_chapter) > 500:
                        chapters.append((f"Chapter_{chapter_num}", current_chapter.strip()))
                        chapter_num += 1
                    current_chapter = ""
                else:
                    current_chapter += text + "\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥–ª–∞–≤—É
            if current_chapter and len(current_chapter) > 500:
                chapters.append((f"Chapter_{chapter_num}", current_chapter.strip()))
            
            # –ï—Å–ª–∏ –≥–ª–∞–≤ –º–∞–ª–æ - —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∫—É—Å–∫–∏
            if len(chapters) < 3:
                full_text = ' '.join([paragraph.text for paragraph in doc.paragraphs])
                chunk_size = 8000
                chapters = []
                for i in range(0, len(full_text), chunk_size):
                    chunk = full_text[i:i + chunk_size]
                    if len(chunk.strip()) > 500:
                        chapters.append((f"Part_{i//chunk_size + 1}", chunk.strip()))
            
            return chapters
            
        return []
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≥–ª–∞–≤ –∏–∑ —Ñ–∞–π–ª–∞: {e}")
        return []

async def extract_chapters_for_glossary(file_path: str, file_format: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è"""
    try:
        if file_format == 'epub':
            import zipfile
            from bs4 import BeautifulSoup
            
            with zipfile.ZipFile(file_path, 'r') as epub_zip:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ HTML —Ñ–∞–π–ª—ã
                html_files = [
                    name for name in epub_zip.namelist()
                    if name.lower().endswith(('.html', '.xhtml', '.htm'))
                    and not name.startswith(('__MACOSX', 'META-INF/'))
                ]
                
                all_text = []
                for html_file in html_files[:20]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 20 —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–±—ã–ª–æ 10)
                    try:
                        content = epub_zip.read(html_file).decode('utf-8', errors='ignore')
                        soup = BeautifulSoup(content, 'lxml')
                        text = soup.get_text(separator=' ', strip=True)
                        if text and len(text) > 100:  # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ–∞–π–ª—ã
                            all_text.append(text)
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {html_file}: {e}")
                        continue
                
                return ' '.join(all_text)
                
        elif file_format == 'txt':
            # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                return f.read()
                
        elif file_format == 'docx':
            # –î–ª—è DOCX —Ñ–∞–π–ª–æ–≤
            import docx
            doc = docx.Document(file_path)
            return ' '.join([paragraph.text for paragraph in doc.paragraphs])
            
        return ""
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞: {e}")
        return ""

async def analyze_file_chapters(update: Update, state: UserState):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–ª–∞–≤"""
    try:
        chapters_found = 0
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É TransGemini
        if state.file_format == 'epub':
            transgemini_info = await get_transgemini_chapters_info(state.file_path, state.file_format)
            if transgemini_info['total_content'] > 0:
                chapters_found = transgemini_info['total_content']
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                state.chapters_info = transgemini_info
                logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Ç–æ—á–Ω–∞—è –ª–æ–≥–∏–∫–∞ TransGemini: –Ω–∞–π–¥–µ–Ω–æ {chapters_found} –≥–ª–∞–≤")
            else:
                # Fallback –∫ —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–µ
                chapters_found = await count_chapters_in_file(state.file_path, state.file_format)
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –ª–æ–≥–∏–∫—É
            chapters_found = await count_chapters_in_file(state.file_path, state.file_format)
        
        state.total_chapters = max(1, chapters_found)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–ø—Ü–∏–∏ –≤—ã–±–æ—Ä–∞ –≥–ª–∞–≤
        await show_chapter_selection(update, state)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≥–ª–∞–≤: {e}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ - —Å—Ä–∞–∑—É –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º –ø–µ—Ä–µ–≤–æ–¥–∞
        state.step = "translating"
        await show_translation_options(update, state)

async def get_transgemini_chapters_info(file_path: str, file_format: str) -> dict:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–ª–∞–≤–∞—Ö –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É TransGemini"""
    try:
        logger.info(f"–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {file_path}, —Ñ–æ—Ä–º–∞—Ç: {file_format}")
        
        if file_format == 'epub':
            with zipfile.ZipFile(file_path, 'r') as epub_zip:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ HTML —Ñ–∞–π–ª—ã (–∫–∞–∫ –≤ TransGemini)
                html_files = sorted([
                    name for name in epub_zip.namelist()
                    if name.lower().endswith(('.html', '.xhtml', '.htm'))
                    and not name.startswith(('__MACOSX', 'META-INF/'))
                ])
                
                logger.info(f"–ù–∞–π–¥–µ–Ω–æ HTML —Ñ–∞–π–ª–æ–≤: {len(html_files)}")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ NAV —Ñ–∞–π–ª (–∫–∞–∫ –≤ TransGemini)
                nav_path = None
                for html_file in html_files:
                    if 'nav' in Path(html_file).name.lower():
                        nav_path = html_file
                        break
                
                chapters_info = {
                    'all_files': [],
                    'content_files': [],
                    'skip_files': [],
                    'nav_file': nav_path,
                    'total_all': len(html_files),
                    'total_content': 0,
                    'original_path': file_path  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É EPUB
                }
                
                TRANSLATED_SUFFIX = '_translated'  # –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –∏–∑ TransGemini
                
                for file_path_in_epub in html_files:
                    try:
                        file_info = epub_zip.getinfo(file_path_in_epub)
                        file_size = file_info.file_size
                    except:
                        file_size = 0
                    
                    is_nav = (nav_path and file_path_in_epub == nav_path)
                    is_translated = Path(file_path_in_epub).stem.endswith(TRANSLATED_SUFFIX)
                    
                    file_data = {
                        'path': file_path_in_epub,
                        'name': Path(file_path_in_epub).name,
                        'size': file_size,
                        'is_nav': is_nav,
                        'is_translated': is_translated,
                        'is_selected': False,
                        'category': 'unknown'
                    }
                    
                    if is_nav:
                        file_data['category'] = 'nav'
                        file_data['is_selected'] = False
                        chapters_info['skip_files'].append(file_data)
                    else:
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É TransGemini –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
                        item_text_lower = file_path_in_epub.lower()
                        path = Path(item_text_lower)
                        filename_lower = path.name
                        filename_base = path.stem.split('.')[0]  # Get stem before first dot
                        
                        skip_indicators = ['toc', 'nav', 'ncx', 'cover', 'title', 'index', 'copyright', 'about', 'meta', 'opf',
                                          'masthead', 'colophon', 'imprint', 'acknowledgments', 'dedication',
                                          'glossary', 'bibliography', 'notes', 'annotations', 'epigraph', 'halftitle',
                                          'frontmatter', 'backmatter', 'preface', 'introduction', 'appendix', 'biography',
                                          'isbn', 'legal', 'notice', 'otherbooks', 'prelims', 'team', 'promo', 'bonus']
                        content_indicators = ['chapter', 'part', 'section', 'content', 'text', 'page', 'body', 'main', 'article',
                                            'chp', 'chap', 'prt', 'sec', 'glava', 'prologue', 'epilogue']
                        
                        is_likely_skip = any(skip in filename_base for skip in skip_indicators)
                        parent_dir_lower = str(path.parent).lower()
                        is_likely_skip = is_likely_skip or any(skip in parent_dir_lower for skip in ['toc', 'nav', 'meta', 'frontmatter', 'backmatter', 'index', 'notes'])
                        is_likely_content = any(indicator in filename_base for indicator in content_indicators)
                        is_chapter_like = (re.fullmatch(r'(ch|gl|chap|chapter|part|section|sec|glava)[\d_-]+.*', filename_base) or 
                                          re.fullmatch(r'[\d]+', filename_base) or 
                                          re.match(r'^[ivxlcdm]+$', filename_base))
                        
                        if not is_likely_skip and (is_likely_content or is_chapter_like):
                            file_data['category'] = 'content'
                            file_data['is_selected'] = True
                            chapters_info['content_files'].append(file_data)
                        else:
                            if not is_likely_skip and 'text' in filename_base:
                                file_data['category'] = 'text'
                                file_data['is_selected'] = True
                                chapters_info['content_files'].append(file_data)
                            else:
                                file_data['category'] = 'skip'
                                file_data['is_selected'] = False
                                chapters_info['skip_files'].append(file_data)
                    
                    chapters_info['all_files'].append(file_data)
                
                chapters_info['total_content'] = len(chapters_info['content_files'])
                logger.info(f"TransGemini –∞–Ω–∞–ª–∏–∑ EPUB: {chapters_info['total_content']} –≥–ª–∞–≤ –∏–∑ {chapters_info['total_all']} —Ñ–∞–π–ª–æ–≤")
                return chapters_info
                
        return {'total_all': 0, 'total_content': 0, 'all_files': [], 'content_files': [], 'skip_files': [], 'nav_file': None}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ TransGemini –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return {'total_all': 0, 'total_content': 0, 'all_files': [], 'content_files': [], 'skip_files': [], 'nav_file': None}

async def get_chapters_info(file_path: str, file_format: str) -> dict:
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–ª–∞–≤–∞—Ö –≤ —Ñ–∞–π–ª–µ"""
    try:
        if file_format == 'epub':
            with zipfile.ZipFile(file_path, 'r') as epub_zip:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ HTML —Ñ–∞–π–ª—ã
                all_html_files = sorted([
                    name for name in epub_zip.namelist()
                    if name.lower().endswith(('.html', '.xhtml', '.htm'))
                    and not name.startswith(('__MACOSX', 'META-INF/'))
                ])
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
                chapters_info = {
                    'all_files': [],
                    'content_files': [],
                    'skip_files': [],
                    'total_all': len(all_html_files),
                    'total_content': 0,
                    'original_path': file_path  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É EPUB
                }
                
                skip_indicators = [
                    'toc', 'nav', 'ncx', 'cover', 'title', 'index', 'copyright', 'about', 'meta', 'opf',
                    'masthead', 'colophon', 'imprint', 'acknowledgments', 'dedication',
                    'glossary', 'bibliography', 'notes', 'annotations', 'epigraph', 'halftitle',
                    'frontmatter', 'backmatter', 'preface', 'introduction', 'appendix', 'biography',
                    'isbn', 'legal', 'notice', 'otherbooks', 'prelims', 'team', 'promo', 'bonus'
                ]
                
                for html_file in all_html_files:
                    filename_base = Path(html_file).stem.split('.')[0].lower()
                    
                    try:
                        file_info = epub_zip.getinfo(html_file)
                        file_size = file_info.file_size
                    except:
                        file_size = 0
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª —Å–ª—É–∂–µ–±–Ω—ã–º
                    is_skip_file = any(skip_word in filename_base for skip_word in skip_indicators)
                    is_translated = filename_base.endswith('_translated')
                    
                    file_data = {
                        'path': html_file,
                        'name': Path(html_file).name,
                        'size': file_size,
                        'is_skip': is_skip_file,
                        'is_translated': is_translated
                    }
                    
                    chapters_info['all_files'].append(file_data)
                    
                    if not is_skip_file and not is_translated and file_size > 500:
                        chapters_info['content_files'].append(file_data)
                    else:
                        chapters_info['skip_files'].append(file_data)
                
                chapters_info['total_content'] = len(chapters_info['content_files'])
                logger.info(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {chapters_info['total_content']} –≥–ª–∞–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–∑ {chapters_info['total_all']} —Ñ–∞–π–ª–æ–≤")
                return chapters_info
                
        logger.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_format}")
        return {'total_all': 0, 'total_content': 0, 'all_files': [], 'content_files': [], 'skip_files': []}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≥–ª–∞–≤: {e}", exc_info=True)
        return {'total_all': 0, 'total_content': 0, 'all_files': [], 'content_files': [], 'skip_files': []}

async def count_chapters_in_file(file_path: str, file_format: str) -> int:
    """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–ª–∞–≤ –≤ —Ñ–∞–π–ª–µ"""
    try:
        if file_format == 'txt':
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
            content = ""
            encodings = ['utf-8', 'cp1251', 'latin-1', 'cp866']
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    break
                except UnicodeDecodeError:
                    continue
            else:
                # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–æ–≥–ª–æ, —á–∏—Ç–∞–µ–º –≤ –±–∏–Ω–∞—Ä–Ω–æ–º —Ä–µ–∂–∏–º–µ
                with open(file_path, 'rb') as f:
                    raw_content = f.read()
                    content = raw_content.decode('utf-8', errors='ignore')
            
            # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≥–ª–∞–≤
            import re
            patterns = [
                r'^\s*(–ì–ª–∞–≤–∞|Chapter|–ì–õ–ê–í–ê|CHAPTER)\s+\d+',
                r'^\s*(–ß–∞—Å—Ç—å|Part|–ß–ê–°–¢–¨|PART)\s+\d+',
                r'^\s*\d+\.\s*[–ê-–ØA-Z]',
                r'^#{1,3}\s+',  # Markdown –∑–∞–≥–æ–ª–æ–≤–∫–∏
            ]
            
            total_matches = 0
            for pattern in patterns:
                matches = re.findall(pattern, content, re.MULTILINE | re.IGNORECASE)
                total_matches = max(total_matches, len(matches))
            
            return max(1, total_matches)
                
        elif file_format == 'docx':
            # –î–ª—è DOCX –∏—Å–ø–æ–ª—å–∑—É–µ–º python-docx
            try:
                from docx import Document
                doc = Document(file_path)
                chapter_count = 0
                
                for para in doc.paragraphs:
                    text = para.text.strip()
                    if text and (
                        text.lower().startswith(('–≥–ª–∞–≤–∞', 'chapter', '—á–∞—Å—Ç—å', 'part')) or
                        para.style.name.startswith('Heading')
                    ):
                        chapter_count += 1
                
                return max(1, chapter_count)
            except ImportError:
                return 5  # Fallback –µ—Å–ª–∏ docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
                
        elif file_format == 'html':
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è HTML
            content = ""
            encodings = ['utf-8', 'cp1251', 'latin-1']
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    break
                except UnicodeDecodeError:
                    continue
            else:
                with open(file_path, 'rb') as f:
                    raw_content = f.read()
                    content = raw_content.decode('utf-8', errors='ignore')
            
            import re
            # –ò—â–µ–º HTML –∑–∞–≥–æ–ª–æ–≤–∫–∏
            headers = re.findall(r'<h[1-6][^>]*>(.*?)</h[1-6]>', content, re.IGNORECASE | re.DOTALL)
            return max(1, len(headers))
        
        elif file_format == 'epub':
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É TransGemini.py –¥–ª—è EPUB —Ñ–∞–π–ª–æ–≤
            try:
                chapter_count = 0
                with zipfile.ZipFile(file_path, 'r') as epub_zip:
                    # –ü–æ–ª—É—á–∞–µ–º HTML —Ñ–∞–π–ª—ã —Ç–∞–∫ –∂–µ, –∫–∞–∫ –≤ TransGemini
                    html_files_in_epub = sorted([
                        name for name in epub_zip.namelist()
                        if name.lower().endswith(('.html', '.xhtml', '.htm'))
                        and not name.startswith(('__MACOSX', 'META-INF/'))  # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–∞–ø–∫–∏
                    ])
                    
                    if not html_files_in_epub:
                        logger.warning(f"–í EPUB —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ HTML/XHTML —Ñ–∞–π–ª–æ–≤")
                        return 5
                    
                    logger.info(f"–í—Å–µ–≥–æ HTML —Ñ–∞–π–ª–æ–≤ –≤ EPUB: {len(html_files_in_epub)}")
                    for html_file in html_files_in_epub:
                        logger.debug(f"HTML —Ñ–∞–π–ª: {html_file}")
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –≥–ª–∞–≤—ã, –∏—Å–∫–ª—é—á–∞—è —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã (–∫–∞–∫ –≤ TransGemini)
                    content_files = []
                    for file_path_in_epub in html_files_in_epub:
                        filename_lower = Path(file_path_in_epub).name.lower()
                        filename_base = Path(file_path_in_epub).stem.split('.')[0].lower()
                        
                        # –°–ø–∏—Å–æ–∫ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–∫–∞–∫ –≤ TransGemini)
                        skip_indicators = [
                            'toc', 'nav', 'ncx', 'cover', 'title', 'index', 'copyright', 'about', 'meta', 'opf',
                            'masthead', 'colophon', 'imprint', 'acknowledgments', 'dedication',
                            'glossary', 'bibliography', 'notes', 'annotations', 'epigraph', 'halftitle',
                            'frontmatter', 'backmatter', 'preface', 'introduction', 'appendix', 'biography',
                            'isbn', 'legal', 'notice', 'otherbooks', 'prelims', 'team', 'promo', 'bonus'
                        ]
                        
                        # –°–ø–∏—Å–æ–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–≥–ª–∞–≤—ã)
                        content_indicators = [
                            'chapter', 'part', 'section', 'content', 'text', 'page', 'body', 'main', 'article',
                            'chp', 'chap', 'prt', 'sec', 'glava', 'prologue', 'epilogue'
                        ]
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª —Å–ª—É–∂–µ–±–Ω—ã–º
                        is_skip_file = any(skip_word in filename_base for skip_word in skip_indicators)
                        is_content_file = any(content_word in filename_base for content_word in content_indicators)
                        
                        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º _translated
                        is_translated = filename_base.endswith('_translated')
                        
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –∏—Å–∫–ª—é—á–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ HTML —Ñ–∞–π–ª—ã (–º–µ–Ω–µ–µ 1KB)
                        try:
                            file_info = epub_zip.getinfo(file_path_in_epub)
                            file_size = file_info.file_size
                        except:
                            file_size = 0
                        
                        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å–ª—É–∂–µ–±–Ω—ã–π –∏ –Ω–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π, –∏ –∏–º–µ–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                        if not is_skip_file and not is_translated and file_size > 1000:
                            content_files.append(file_path_in_epub)
                            logger.debug(f"–ù–∞–π–¥–µ–Ω–∞ –≥–ª–∞–≤–∞: {file_path_in_epub} (—Ä–∞–∑–º–µ—Ä: {file_size} –±–∞–π—Ç)")
                        else:
                            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª: {file_path_in_epub} (—Å–ª—É–∂–µ–±–Ω—ã–π: {is_skip_file}, –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π: {is_translated}, —Ä–∞–∑–º–µ—Ä: {file_size})")
                    
                    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å –º–∞–ª–æ —Ñ–∞–π–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
                    if len(content_files) < 3:
                        logger.info("–ú–∞–ª–æ –≥–ª–∞–≤ –ø–æ—Å–ª–µ —Å—Ç—Ä–æ–≥–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –ø—Ä–∏–º–µ–Ω—è–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏")
                        content_files = []
                        for file_path_in_epub in html_files_in_epub:
                            filename_lower = Path(file_path_in_epub).name.lower()
                            filename_base = Path(file_path_in_epub).stem.split('.')[0].lower()
                            
                            # –ë–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                            skip_indicators_short = ['toc', 'nav', 'cover', 'title', 'copyright', 'meta', 'opf']
                            is_skip_file = any(skip_word in filename_base for skip_word in skip_indicators_short)
                            is_translated = filename_base.endswith('_translated')
                            
                            try:
                                file_info = epub_zip.getinfo(file_path_in_epub)
                                file_size = file_info.file_size
                            except:
                                file_size = 0
                            
                            if not is_skip_file and not is_translated and file_size > 500:
                                content_files.append(file_path_in_epub)
                    
                    chapter_count = len(content_files)
                    logger.info(f"EPUB –∞–Ω–∞–ª–∏–∑: –Ω–∞–π–¥–µ–Ω–æ {chapter_count} –≥–ª–∞–≤ –∏–∑ {len(html_files_in_epub)} HTML —Ñ–∞–π–ª–æ–≤")
                    
                    return max(1, chapter_count)
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ EPUB: {e}")
                # Fallback: –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ñ–∞–π–ª
                try:
                    # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ EPUB —á–∏—Ç–∞—é—Ç—Å—è –∫–∞–∫ —Ç–µ–∫—Å—Ç
                    encodings = ['utf-8', 'cp1251', 'latin-1']
                    for encoding in encodings:
                        try:
                            with open(file_path, 'r', encoding=encoding) as f:
                                content = f.read()
                                patterns = [
                                    r'(?:chapter|–≥–ª–∞–≤–∞|—á–∞—Å—Ç—å)\s*\d+',
                                    r'<h[1-6][^>]*>.*?</h[1-6]>',
                                ]
                                total_matches = 0
                                for pattern in patterns:
                                    matches = re.findall(pattern, content, re.IGNORECASE)
                                    total_matches = max(total_matches, len(matches))
                                if total_matches > 0:
                                    return total_matches
                            break
                        except UnicodeDecodeError:
                            continue
                except:
                    pass
                
                return 20  # –†–∞–∑—É–º–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –∫–Ω–∏–≥
        
        return 5  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ –≥–ª–∞–≤: {e}")
        return 5

async def show_chapter_selection(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–ø—Ü–∏–∏ –≤—ã–±–æ—Ä–∞ –≥–ª–∞–≤"""
    keyboard = [
        [InlineKeyboardButton("üìñ –í—Å–µ –≥–ª–∞–≤—ã", callback_data="chapters_all")],
        [InlineKeyboardButton("üî¢ –í—ã–±—Ä–∞—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω", callback_data="chapters_range")],
        [InlineKeyboardButton("üìã –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –≥–ª–∞–≤—ã", callback_data="show_all_chapters")],
        [InlineKeyboardButton("üîç –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –≥–ª–æ—Å—Å–∞—Ä–∏–π", callback_data="setup_glossary_from_chapter_selection")],
        [InlineKeyboardButton("‚ñ∂Ô∏è –ü–µ—Ä–µ–π—Ç–∏ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º", callback_data="skip_chapters")]
    ]
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    chapter_info = ""
    if state.total_chapters > 1:
        chapter_info = f"üìä –í —Ñ–∞–π–ª–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–∏–º–µ—Ä–Ω–æ **{state.total_chapters} –≥–ª–∞–≤/—Ä–∞–∑–¥–µ–ª–æ–≤**\n\n"
    
    message_text = (
        f"‚öôÔ∏è **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
        f"{chapter_info}"
        f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
        f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é:"
    )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –æ–±—ä–µ–∫—Ç–∞ update –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
    try:
        if hasattr(update, 'edit_message_text'):
            # –≠—Ç–æ CallbackQuery
            await update.edit_message_text(
                message_text,
                reply_markup=reply_markup,
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            # –≠—Ç–æ Update, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            await update.message.reply_text(
                message_text,
                reply_markup=reply_markup,
                parse_mode=ParseMode.MARKDOWN
            )
    except BadRequest as e:
        if "Message is not modified" not in str(e):
            raise

async def show_all_chapters(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≥–ª–∞–≤—ã –≤ —Ñ–∞–π–ª–µ"""
    try:
        logger.info(f"–ü–æ–∫–∞–∑ –≤—Å–µ—Ö –≥–ª–∞–≤ –¥–ª—è —Ñ–∞–π–ª–∞: {state.file_name}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º –Ω–æ–≤—É—é
        chapters_info = getattr(state, 'chapters_info', None)
        if not chapters_info:
            logger.info("–ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–ª–∞–≤–∞—Ö —á–µ—Ä–µ–∑ TransGemini")
            chapters_info = await get_transgemini_chapters_info(state.file_path, state.file_format)
            state.chapters_info = chapters_info
        
        logger.info(f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥–ª–∞–≤–∞—Ö: {chapters_info}")
        
        if chapters_info['total_all'] == 0:
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –≥–ª–∞–≤—ã")
            try:
                await update.edit_message_text(
                    "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–ª–∞–≤—ã –≤ —Ñ–∞–π–ª–µ.",
                    reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_chapter_selection")]])
                )
            except BadRequest as e:
                if "Message is not modified" not in str(e):
                    raise
            return
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å–æ —Å–ø–∏—Å–∫–æ–º –≥–ª–∞–≤
        message_text = f"üìã **–ê–Ω–∞–ª–∏–∑ –≥–ª–∞–≤ (TransGemini –ª–æ–≥–∏–∫–∞)**\n\n"
        message_text += f"üìÅ –§–∞–π–ª: `{state.file_name}`\n\n"
        message_text += f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**\n"
        message_text += f"‚Ä¢ –í—Å–µ–≥–æ HTML —Ñ–∞–π–ª–æ–≤: `{chapters_info['total_all']}`\n"
        message_text += f"‚Ä¢ –ì–ª–∞–≤—ã –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞: `{chapters_info['total_content']}`\n"
        message_text += f"‚Ä¢ –°–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã: `{len(chapters_info['skip_files'])}`\n"
        if chapters_info['nav_file']:
            message_text += f"‚Ä¢ NAV —Ñ–∞–π–ª (–æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ): `{Path(chapters_info['nav_file']).name}`\n"
        message_text += "\n"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥–ª–∞–≤—ã —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è (—Ç–µ, —á—Ç–æ –±—É–¥—É—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã)
        if chapters_info['content_files']:
            message_text += f"‚úÖ **–ì–ª–∞–≤—ã –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ ({len(chapters_info['content_files'])}):**\n"
            for i, file_data in enumerate(chapters_info['content_files'][:20], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 20
                size_kb = file_data['size'] // 1024 if file_data['size'] > 0 else 0
                category_emoji = {"content": "üìñ", "text": "üìÑ"}.get(file_data['category'], "üìÑ")
                message_text += f"{i}. {category_emoji} `{file_data['name']}` ({size_kb}KB)\n"
            
            if len(chapters_info['content_files']) > 20:
                message_text += f"... –∏ –µ—â–µ {len(chapters_info['content_files']) - 20} –≥–ª–∞–≤\n"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã (–ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ)
        if chapters_info['skip_files']:
            message_text += f"\nüö´ **–°–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã ({len(chapters_info['skip_files'])}):**\n"
            for file_data in chapters_info['skip_files'][:8]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 8
                size_kb = file_data['size'] // 1024 if file_data['size'] > 0 else 0
                category_emoji = {"nav": "üß≠", "skip": "‚è≠Ô∏è"}.get(file_data['category'], "‚ùì")
                reason = {"nav": "–Ω–∞–≤–∏–≥–∞—Ü–∏—è", "skip": "—Å–ª—É–∂–µ–±–Ω—ã–π"}.get(file_data['category'], "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                message_text += f"‚Ä¢ {category_emoji} `{file_data['name']}` ({size_kb}KB) - {reason}\n"
            
            if len(chapters_info['skip_files']) > 8:
                message_text += f"... –∏ –µ—â–µ {len(chapters_info['skip_files']) - 8} —Ñ–∞–π–ª–æ–≤\n"
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–ª–∞–≤ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è EPUB —Ñ–∞–π–ª–æ–≤
        # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        if state.file_format == 'epub' and chapters_info['total_content'] > 0:
            state.total_chapters = chapters_info['total_content']
        # –î–ª—è –Ω–µ-EPUB —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ EPUB –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        
        keyboard = [
            [InlineKeyboardButton(f"üìñ –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –≤—Å–µ {chapters_info['total_content']} –≥–ª–∞–≤", callback_data="chapters_all")],
            [InlineKeyboardButton("üî¢ –í—ã–±—Ä–∞—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω", callback_data="chapters_range")],
            [InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_chapter_selection")]
        ]
        
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        try:
            await update.edit_message_text(
                message_text,
                reply_markup=reply_markup,
                parse_mode=ParseMode.MARKDOWN
            )
        except BadRequest as e:
            if "Message is not modified" not in str(e):
                raise
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∫–∞–∑–∞ –≥–ª–∞–≤: {e}")
        try:
            await update.edit_message_text(
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≥–ª–∞–≤: {str(e)}",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_chapter_selection")]])
            )
        except BadRequest as e2:
            if "Message is not modified" not in str(e2):
                raise

async def handle_chapter_selection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –≥–ª–∞–≤"""
    query = update.callback_query
    user_id = query.from_user.id
    state = get_user_state(user_id)
    
    logger.info(f"–ü–æ–ª—É—á–µ–Ω callback_data: {query.data}, —à–∞–≥: {state.step}")
    
    if state.step != "chapter_selection":
        logger.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π —à–∞–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞. –¢–µ–∫—É—â–∏–π: {state.step}, –æ–∂–∏–¥–∞–µ—Ç—Å—è: chapter_selection")
        await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–π —à–∞–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞")
        return
    
    callback_data = query.data
    logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º callback_data: {callback_data}")
    
    if callback_data == "chapters_all":
        logger.info("–í—ã–±—Ä–∞–Ω—ã –≤—Å–µ –≥–ª–∞–≤—ã")
        state.start_chapter = 1
        state.chapter_count = 0  # 0 = –≤—Å–µ –≥–ª–∞–≤—ã
        state.step = "translating"
        
        await query.answer("–í—ã–±—Ä–∞–Ω—ã –≤—Å–µ –≥–ª–∞–≤—ã")
        await show_translation_options(query, state)
        
    elif callback_data == "chapters_range":
        logger.info("–ü–µ—Ä–µ—Ö–æ–¥ –∫ –≤—ã–±–æ—Ä—É –¥–∏–∞–ø–∞–∑–æ–Ω–∞")
        await query.answer()
        await show_chapter_range_input(query, state)
        
    elif callback_data == "show_all_chapters":
        logger.info("–ü–æ–∫–∞–∑ –≤—Å–µ—Ö –≥–ª–∞–≤")
        await query.answer()
        await show_all_chapters(query, state)
        
    elif callback_data == "setup_glossary_from_chapter_selection":
        logger.info("–ü–µ—Ä–µ—Ö–æ–¥ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è")
        # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º, —á—Ç–æ –º—ã –±—ã–ª–∏ –≤ –≤—ã–±–æ—Ä–µ –≥–ª–∞–≤
        state.session_data["previous_step"] = state.step
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é –≥–ª–æ—Å—Å–∞—Ä–∏—è
        await query.answer("–ü–µ—Ä–µ—Ö–æ–¥ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è")
        await handle_settings_glossary(query, state)
        
    elif callback_data == "skip_chapters":
        logger.info("–ü—Ä–æ–ø—É—Å–∫ –≤—ã–±–æ—Ä–∞ –≥–ª–∞–≤")
        state.step = "translating"
        await query.answer()
        await show_translation_options(query, state)
        
    elif callback_data == "back_to_chapter_selection":
        logger.info("–í–æ–∑–≤—Ä–∞—Ç –∫ –≤—ã–±–æ—Ä—É –≥–ª–∞–≤")
        await query.answer()
        await show_chapter_selection(query, state)
    else:
        logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π callback_data: {callback_data}")

async def show_chapter_range_input(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤–≤–æ–¥–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≥–ª–∞–≤"""
    keyboard = []
    
    # –ë—ã—Å—Ç—Ä—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–±–æ—Ä–∞
    if state.total_chapters >= 5:
        keyboard.extend([
            [
                InlineKeyboardButton("1-5 –≥–ª–∞–≤", callback_data="range_1_5"),
                InlineKeyboardButton("6-10 –≥–ª–∞–≤", callback_data="range_6_10")
            ],
            [
                InlineKeyboardButton("11-15 –≥–ª–∞–≤", callback_data="range_11_15"),
                InlineKeyboardButton("16-20 –≥–ª–∞–≤", callback_data="range_16_20")
            ]
        ])
    
    # –ö–Ω–æ–ø–∫–∏ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞
    keyboard.extend([
        [InlineKeyboardButton("‚úèÔ∏è –í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é", callback_data="range_manual")],
        [InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_chapters")]
    ])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.edit_message_text(
        f"üî¢ **–í—ã–±–æ—Ä –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≥–ª–∞–≤**\n\n"
        f"üìä –í—Å–µ–≥–æ –≥–ª–∞–≤ –≤ —Ñ–∞–π–ª–µ: `{state.total_chapters}`\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ –≤—Ä—É—á–Ω—É—é:",
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_chapter_range_selection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≥–ª–∞–≤"""
    query = update.callback_query
    user_id = query.from_user.id
    state = get_user_state(user_id)
    
    callback_data = query.data
    
    if callback_data == "back_to_chapters":
        await query.answer()
        await show_chapter_selection(query, state)
        return
    elif callback_data.startswith("range_"):
        if callback_data == "range_manual":
            state.step = "chapter_input"
            await query.answer()
            await query.edit_message_text(
                f"‚úèÔ∏è **–†—É—á–Ω–æ–π –≤–≤–æ–¥ –¥–∏–∞–ø–∞–∑–æ–Ω–∞**\n\n"
                f"üìä –í—Å–µ–≥–æ –≥–ª–∞–≤: `{state.total_chapters}`\n\n"
                f"–í–≤–µ–¥–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –≤ –æ–¥–Ω–æ–º –∏–∑ —Ñ–æ—Ä–º–∞—Ç–æ–≤:\n"
                f"‚Ä¢ `5` - —Ç–æ–ª—å–∫–æ 5-—è –≥–ª–∞–≤–∞\n"
                f"‚Ä¢ `3-8` - –≥–ª–∞–≤—ã —Å 3 –ø–æ 8\n"
                f"‚Ä¢ `10+5` - –Ω–∞—á–∏–Ω–∞—è —Å 10-–π, –≤—Å–µ–≥–æ 5 –≥–ª–∞–≤\n\n"
                f"–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à –≤—ã–±–æ—Ä:",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±—ã—Å—Ç—Ä—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        range_parts = callback_data.replace("range_", "").split("_")
        if len(range_parts) == 2:
            start_ch = int(range_parts[0])
            end_ch = int(range_parts[1])
            
            state.start_chapter = start_ch
            state.chapter_count = end_ch - start_ch + 1
            state.step = "translating"
            
            await query.answer(f"–í—ã–±—Ä–∞–Ω—ã –≥–ª–∞–≤—ã {start_ch}-{end_ch}")
            await show_translation_options(query, state)

async def handle_chapter_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≥–ª–∞–≤"""
    user_id = update.effective_user.id
    state = get_user_state(user_id)
    
    if state.step != "chapter_input":
        return
    
    input_text = update.message.text.strip()
    
    try:
        # –ü–∞—Ä—Å–∏–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤–≤–æ–¥–∞
        if "-" in input_text:
            # –§–æ—Ä–º–∞—Ç "3-8"
            parts = input_text.split("-")
            start_ch = int(parts[0])
            end_ch = int(parts[1])
            
            if start_ch < 1 or end_ch > state.total_chapters or start_ch > end_ch:
                raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω")
                
            state.start_chapter = start_ch
            state.chapter_count = end_ch - start_ch + 1
            
        elif "+" in input_text:
            # –§–æ—Ä–º–∞—Ç "10+5"
            parts = input_text.split("+")
            start_ch = int(parts[0])
            count = int(parts[1])
            
            if start_ch < 1 or start_ch > state.total_chapters or count < 1:
                raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω")
                
            state.start_chapter = start_ch
            state.chapter_count = min(count, state.total_chapters - start_ch + 1)
            
        else:
            # –§–æ—Ä–º–∞—Ç "5" - –æ–¥–Ω–∞ –≥–ª–∞–≤–∞
            chapter_num = int(input_text)
            
            if chapter_num < 1 or chapter_num > state.total_chapters:
                raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä –≥–ª–∞–≤—ã")
                
            state.start_chapter = chapter_num
            state.chapter_count = 1
        
        state.step = "translating"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        end_chapter = min(state.start_chapter + state.chapter_count - 1, state.total_chapters)
        range_text = f"–≥–ª–∞–≤–∞ {state.start_chapter}" if state.chapter_count == 1 else f"–≥–ª–∞–≤—ã {state.start_chapter}-{end_chapter}"
        
        await update.message.reply_text(
            f"‚úÖ –í—ã–±—Ä–∞–Ω –¥–∏–∞–ø–∞–∑–æ–Ω: **{range_text}**\n\n"
            f"–ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º –ø–µ—Ä–µ–≤–æ–¥–∞...",
            parse_mode=ParseMode.MARKDOWN
        )
        
        await show_translation_options(update, state)
        
    except (ValueError, IndexError):
        await update.message.reply_text(
            f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤–≤–æ–¥–∞!\n\n"
            f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–¥–∏–Ω –∏–∑ —Ñ–æ—Ä–º–∞—Ç–æ–≤:\n"
            f"‚Ä¢ `5` - —Ç–æ–ª—å–∫–æ 5-—è –≥–ª–∞–≤–∞\n"
            f"‚Ä¢ `3-8` - –≥–ª–∞–≤—ã —Å 3 –ø–æ 8\n"
            f"‚Ä¢ `10+5` - –Ω–∞—á–∏–Ω–∞—è —Å 10-–π, –≤—Å–µ–≥–æ 5 –≥–ª–∞–≤\n\n"
            f"–ú–∞–∫—Å–∏–º—É–º –≥–ª–∞–≤ –≤ —Ñ–∞–π–ª–µ: `{state.total_chapters}`\n"
            f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑:",
            parse_mode=ParseMode.MARKDOWN
        )

async def show_translation_options(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏ –ø–µ—Ä–µ–≤–æ–¥–∞"""
    keyboard = [
        [InlineKeyboardButton("üá∑üá∫ –†—É—Å—Å–∫–∏–π", callback_data="lang_—Ä—É—Å—Å–∫–∏–π")],
        [InlineKeyboardButton("üá∫üá∏ English", callback_data="lang_–∞–Ω–≥–ª–∏–π—Å–∫–∏–π")],
        [InlineKeyboardButton("üá©üá™ Deutsch", callback_data="lang_–Ω–µ–º–µ—Ü–∫–∏–π")],
        [InlineKeyboardButton("üá´üá∑ Fran√ßais", callback_data="lang_—Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π")],
        [InlineKeyboardButton("üá™üá∏ Espa√±ol", callback_data="lang_–∏—Å–ø–∞–Ω—Å–∫–∏–π")],
        [InlineKeyboardButton("ü§ñ –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å", callback_data="select_model")],
        [InlineKeyboardButton("‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥", callback_data="start_translation")],
        [InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –∫ –≤—ã–±–æ—Ä—É –≥–ª–∞–≤", callback_data="back_to_translation_options")]
    ]
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –≥–ª–∞–≤–∞—Ö
    chapter_info = ""
    if hasattr(state, 'total_chapters') and state.total_chapters > 0:
        if state.chapter_count == 0:  # –í—Å–µ –≥–ª–∞–≤—ã
            chapter_info = f"üìñ –ì–ª–∞–≤—ã: –≤—Å–µ ({state.total_chapters})\n"
        elif state.chapter_count == 1:
            chapter_info = f"üìñ –ì–ª–∞–≤–∞: {state.start_chapter}\n"
        else:
            end_chapter = min(state.start_chapter + state.chapter_count - 1, state.total_chapters)
            chapter_info = f"ÔøΩ –ì–ª–∞–≤—ã: {state.start_chapter}-{end_chapter}\n"
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –æ–±—ä–µ–∫—Ç–∞ update –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
        if hasattr(update, 'edit_message_text'):
            # –≠—Ç–æ CallbackQuery
            await update.edit_message_text(
                f"üîß **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
                f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
                f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n"
                f"{chapter_info}"
                f"üåç –Ø–∑—ã–∫: `{state.target_language}`\n"
                f"ü§ñ –ú–æ–¥–µ–ª—å: `{state.model}`\n\n"
                f"–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ –ø–µ—Ä–µ–≤–æ–¥:",
                reply_markup=reply_markup,
                parse_mode=ParseMode.MARKDOWN
            )
        else:
            # –≠—Ç–æ Update, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            await update.message.reply_text(
                f"üîß **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
                f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
                f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n"
                f"{chapter_info}"
                f"üåç –Ø–∑—ã–∫: `{state.target_language}`\n"
                f"ü§ñ –ú–æ–¥–µ–ª—å: `{state.model}`\n\n"
                f"–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ –ø–µ—Ä–µ–≤–æ–¥:",
                reply_markup=reply_markup,
                parse_mode=ParseMode.MARKDOWN
            )
    except Exception as e:
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ
        if "Message is not modified" in str(e):
            logger.warning("–°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ")
        else:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–¥–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
            if hasattr(update, 'message') and update.message:
                await update.message.reply_text(
                    f"üîß **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
                    f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
                    f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n"
                    f"{chapter_info}"
                    f"üåç –Ø–∑—ã–∫: `{state.target_language}`\n"
                    f"ü§ñ –ú–æ–¥–µ–ª—å: `{state.model}`\n\n"
                    f"–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ –ø–µ—Ä–µ–≤–æ–¥:",
                    reply_markup=reply_markup,
                    parse_mode=ParseMode.MARKDOWN
                )
            elif hasattr(update, 'from_user'):
                # –î–ª—è CallbackQuery –∏—Å–ø–æ–ª—å–∑—É–µ–º bot.send_message
                await update.get_bot().send_message(
                    chat_id=update.message.chat_id,
                    text=f"üîß **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞**\n\n"
                         f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
                         f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n"
                         f"{chapter_info}"
                         f"üåç –Ø–∑—ã–∫: `{state.target_language}`\n"
                         f"ü§ñ –ú–æ–¥–µ–ª—å: `{state.model}`\n\n"
                         f"–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ –ø–µ—Ä–µ–≤–æ–¥:",
                    reply_markup=reply_markup,
                    parse_mode=ParseMode.MARKDOWN
                )

async def show_model_selection(update: Update, state: UserState):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ Gemini"""
    # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ TransGemini.py
    keyboard = []
    models_per_row = 1  # –ü–æ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ –≤ —Ä—è–¥—É –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    
    model_buttons = []
    for model_name in MODELS.keys():
        # –°–æ–∑–¥–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –∫–Ω–æ–ø–æ–∫
        short_name = model_name.replace("Gemini ", "").replace("gemma", "Gemma")
        if len(short_name) > 25:  # –û–±—Ä–µ–∑–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            short_name = short_name[:22] + "..."
        
        model_buttons.append(InlineKeyboardButton(
            f"ü§ñ {short_name}", 
            callback_data=f"model_{model_name}"
        ))
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫–∏ –ø–æ —Ä—è–¥–∞–º
    for i in range(0, len(model_buttons), models_per_row):
        keyboard.append(model_buttons[i:i + models_per_row])
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É "–ù–∞–∑–∞–¥"
    keyboard.append([InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º", callback_data="back_to_translation_options")])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.edit_message_text(
        f"ü§ñ **–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ Gemini**\n\n"
        f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
        f"üéØ –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: `{state.model}`\n\n"
        f"**–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:**\n"
        f"‚Ä¢ **Gemini 2.5** - –ù–æ–≤–µ–π—à–∏–µ –º–æ–¥–µ–ª–∏ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)\n"
        f"‚Ä¢ **Gemini 2.0** - –ë—ã—Å—Ç—Ä—ã–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ\n"
        f"‚Ä¢ **Gemini 1.5** - –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–µ–º\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞:",
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_translation_options(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ–ø—Ü–∏–π –ø–µ—Ä–µ–≤–æ–¥–∞"""
    query = update.callback_query
    user_id = query.from_user.id
    state = get_user_state(user_id)
    
    callback_data = query.data
    
    if callback_data.startswith("lang_"):
        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —è–∑—ã–∫–∞
        language = callback_data.replace("lang_", "")
        state.target_language = language
        
        await query.answer(f"–í—ã–±—Ä–∞–Ω —è–∑—ã–∫: {language}")
        await show_translation_options(query, state)
        
    elif callback_data == "select_model":
        # –ü–æ–∫–∞–∑–∞—Ç—å –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
        await query.answer()
        await show_model_selection(query, state)
        
    elif callback_data.startswith("model_"):
        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model_name = callback_data.replace("model_", "")
        if model_name in MODELS:
            state.model = model_name
            await query.answer(f"–í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
            await show_translation_options(query, state)
        else:
            await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å")
            
    elif callback_data == "back_to_translation_options":
        # –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –≤—ã–±–æ—Ä—É –≥–ª–∞–≤
        await query.answer()
        state.step = "chapter_selection"  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —à–∞–≥
        await show_chapter_selection(query, state)
        
    elif callback_data == "start_translation":
        await query.answer()
        await start_translation(query, state)

async def start_translation(update: Update, state: UserState):
    import time
    start_time = time.time()
    logger.info(f"‚è≥ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–ø—É—â–µ–Ω –≤ {time.strftime('%H:%M:%S', time.localtime(start_time))}")
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –ø–µ—Ä–µ–≤–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É—è TransGemini.py"""
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞
    await update.edit_message_text(
        f"üîÑ **–ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–≤–æ–¥...**\n\n"
        f"üìÅ –§–∞–π–ª: `{state.file_name}`\n"
        f"üåç –Ø–∑—ã–∫: `{state.target_language}`\n"
        f"üìÑ –§–æ—Ä–º–∞—Ç: `{state.output_format.upper()}`\n\n"
        f"‚è≥ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...",
        parse_mode=ParseMode.MARKDOWN
    )
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ file_path –Ω–µ None
        if not state.file_path:
            await update.callback_query.edit_message_text(
                "‚ùå –û—à–∏–±–∫–∞: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –∑–∞–Ω–æ–≤–æ."
            )
            return
            
        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
        input_path = Path(state.file_path)
        output_dir = input_path.parent
        output_name = f"{input_path.stem}_translated.{state.output_format}"
        output_path = output_dir / output_name
        
        logger.info(f"–ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–≤–æ–¥ —Ñ–∞–π–ª–∞: {state.file_path}")
        logger.info(f"–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_path}")
        logger.info(f"–§–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω–æ–π: {state.file_format}, –≤—ã—Ö–æ–¥–Ω–æ–π: {state.output_format}")
        logger.info(f"–Ø–∑—ã–∫: {state.target_language}, –ú–æ–¥–µ–ª—å: {state.model}")
        logger.info(f"–ì–ª–∞–≤—ã: –Ω–∞—á–∏–Ω–∞—è —Å {getattr(state, 'start_chapter', 1)}, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {getattr(state, 'chapter_count', 0)}")
        logger.info(f"–†–æ—Ç–∞—Ü–∏—è API –∫–ª—é—á–µ–π: {'–í–∫–ª—é—á–µ–Ω–∞' if state.use_key_rotation and len(state.api_keys) > 1 else '–í—ã–∫–ª—é—á–µ–Ω–∞'}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–æ—Ç–∞—Ü–∏—é –∫–ª—é—á–µ–π
        if state.use_key_rotation and len(state.api_keys) > 1:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º run_translation_with_auto_restart –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–æ—Ç–∞—Ü–∏–∏ –∫–ª—é—á–µ–π
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–æ—Ç–∞—Ü–∏—é —Å {len(state.api_keys)} API –∫–ª—é—á–∞–º–∏")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏
            settings = state.get_settings_dict()
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–∞–ø–∫—É –≤—ã–≤–æ–¥–∞ –∏ –∏–º—è —Ñ–∞–π–ª–∞
            settings['output_folder'] = str(output_dir)
            settings['output_format'] = state.output_format
            
            # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–æ—Ç–∞—Ü–∏–µ–π
            # –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, —Ç–∞–∫ –∫–∞–∫ run_translation_with_auto_restart - —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
            def run_translation_thread():
                try:
                    run_translation_with_auto_restart(settings)
                    logger.info("–ü–µ—Ä–µ–≤–æ–¥ —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –∫–ª—é—á–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –∫–ª—é—á–µ–π: {e}")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            translation_thread = threading.Thread(target=run_translation_thread)
            translation_thread.start()
            
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ (—Å —Ç–∞–π–º–∞—É—Ç–æ–º –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)
            max_wait_time = 3600  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (1 —á–∞—Å)
            translation_thread.join(timeout=max_wait_time)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É—Å–ø–µ—à–Ω–æ –ª–∏ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –ø–µ—Ä–µ–≤–æ–¥
            if translation_thread.is_alive():
                logger.warning("–ü–µ—Ä–µ–≤–æ–¥ —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –ø—Ä–µ–≤—ã—Å–∏–ª –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è")
                success = False
                error_message = "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞"
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                if output_path.exists():
                    success = True
                    error_message = None
                else:
                    success = False
                    error_message = "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –ø–æ—Å–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –∫–ª—é—á–µ–π"
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –ø–µ—Ä–µ–≤–æ–¥–∞
            success, error_message = await translate_file_with_transgemini(
                input_file=state.file_path,
                output_file=str(output_path),
                input_format=state.file_format,
                output_format=state.output_format,
                target_language=state.target_language,
                api_key=state.api_key,
                model_name=state.model,
                progress_callback=None,  # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                start_chapter=getattr(state, 'start_chapter', 1),
                chapter_count=getattr(state, 'chapter_count', 0),
                chapters_info=getattr(state, 'chapters_info', None),  # –ü–µ—Ä–µ–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–ª–∞–≤–∞—Ö
                glossary_data=getattr(state, 'glossary_data', None)  # –ü–µ—Ä–µ–¥–∞–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π
            )
        
        end_time = time.time()
        duration = end_time - start_time
        if success and output_path.exists():
            logger.info(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω, —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {output_path}")
            logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –ø–µ—Ä–µ–≤–æ–¥–∞: {duration:.1f} —Å–µ–∫. (–∑–∞–≤–µ—Ä—à–µ–Ω–æ –≤ {time.strftime('%H:%M:%S', time.localtime(end_time))})")
            await send_translated_file(update, state, str(output_path))
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
            logger.error(f"‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –ø–µ—Ä–µ–≤–æ–¥–∞:")
            logger.error(f"   success: {success}")
            logger.error(f"   output_path: {output_path}")
            logger.error(f"   output_path.exists(): {output_path.exists() if output_path else 'N/A'}")
            logger.error(f"   output_path.parent: {output_path.parent if output_path else 'N/A'}")
            logger.error(f"   error_message: {error_message}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –ø–∞–ø–∫–µ
            if output_path and output_path.parent.exists():
                try:
                    files_in_output_dir = list(output_path.parent.iterdir())
                    logger.info(f"üìÅ –§–∞–π–ª—ã –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {output_path.parent}:")
                    for file in files_in_output_dir:
                        logger.info(f"   - {file.name} (—Ä–∞–∑–º–µ—Ä: {file.stat().st_size if file.is_file() else 'dir'})")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {e}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è —Ñ–∞–π–ª–∞
            if output_path:
                possible_locations = [
                    output_path.parent / f"{output_path.stem}_translated{output_path.suffix}",
                    output_path.parent / f"{output_path.stem}.txt",
                    output_path.parent / f"{Path(state.file_name).stem}_translated.txt",
                ]
                
                logger.info("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞:")
                for possible_path in possible_locations:
                    exists = possible_path.exists()
                    logger.info(f"   {possible_path}: {'‚úÖ –ù–ê–ô–î–ï–ù' if exists else '‚ùå –ù–ï–¢'}")
                    if exists and possible_path.is_file():
                        logger.info(f"      –†–∞–∑–º–µ—Ä: {possible_path.stat().st_size} –±–∞–π—Ç")
                        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ñ–∞–π–ª, –ø–æ–ø—Ä–æ–±—É–µ–º –µ–≥–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å
                        try:
                            await send_translated_file(update, state, str(possible_path))
                            return  # –£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ —Ñ–∞–π–ª
                        except Exception as send_error:
                            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ {possible_path}: {send_error}")
            
            error_text = "‚ùå **–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ**\n\n"
            if error_message and "—É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω" not in error_message.lower():
                error_text += f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: `{error_message}`\n\n"
            else:
                error_text += "–ü–µ—Ä–µ–≤–æ–¥ –±—ã–ª –∑–∞–≤–µ—Ä—à–µ–Ω, –Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.\n\n"
            
            error_text += "–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
            error_text += "‚Ä¢ Worker —Å–æ–∑–¥–∞–ª —Ñ–∞–π–ª –≤ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–º –º–µ—Å—Ç–µ\n"
            error_text += "‚Ä¢ –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø—Ä–∞–≤–∞–º–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É\n"
            error_text += "‚Ä¢ –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á Google Gemini\n"
            error_text += "‚Ä¢ –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ API\n"
            error_text += "‚Ä¢ –ü—Ä–æ–±–ª–µ–º—ã —Å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º\n"
            error_text += "‚Ä¢ –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n\n"
            error_text += "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."
            
            await update.edit_message_text(
                error_text,
                parse_mode=ParseMode.MARKDOWN
            )
            
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ: {e}", exc_info=True)
        await update.edit_message_text(
            f"‚ùå **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ**\n\n"
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: `{str(e)}`\n\n"
            f"–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –ø–æ–∑–∂–µ.",
            parse_mode=ParseMode.MARKDOWN
        )
    
    # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_id = update.from_user.id if hasattr(update, 'from_user') else update.effective_user.id
    reset_user_state(user_id)

def extract_body_content_from_html(html_content: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ <body> –∏–∑ HTML, —É–¥–∞–ª—è—è CSS —Å—Ç–∏–ª–∏ –∏ –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–Ω—Ç
    –†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –ø–æ–ø–∞–¥–∞–Ω–∏—è CSS —Å—Ç–∏–ª–µ–π –≤ —Ç–µ–ª–æ EPUB —Ñ–∞–π–ª–∞
    """
    if not html_content or not html_content.strip():
        return ""
    
    try:
        from bs4 import BeautifulSoup
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å–ª—É—á–∞–µ–≤, –≥–¥–µ CSS —Å—Ç–∏–ª–∏ –ø–æ–ø–∞–¥–∞—é—Ç –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
        # –∫–∞–∫ —Ç–µ–∫—Å—Ç —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –≥–ª–∞–≤—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: "0002_Chapter_2_Bom__Spring_1 <br />body { font-family...")
        if '<br />body {' in html_content and 'font-family' in html_content:
            logger.info("üßπ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã CSS —Å—Ç–∏–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ, –≤—ã–ø–æ–ª–Ω—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –æ—á–∏—Å—Ç–∫—É...")
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ <br /> –∏ –∏—â–µ–º CSS –±–ª–æ–∫
            parts = html_content.split('<br />')
            
            # –ò—â–µ–º —á–∞—Å—Ç—å —Å CSS —Å—Ç–∏–ª—è–º–∏ –∏ —É–¥–∞–ª—è–µ–º –µ—ë
            clean_parts = []
            css_block_started = False
            
            for part in parts:
                part_stripped = part.strip()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–∞ —á–∞—Å—Ç—å CSS —Å—Ç–∏–ª–µ–º
                if ('body {' in part_stripped or 
                    'font-family' in part_stripped or
                    'line-height' in part_stripped or
                    'margin:' in part_stripped or
                    'padding:' in part_stripped or
                    'color:' in part_stripped or
                    part_stripped.endswith('}') and any(css_prop in part_stripped for css_prop in ['font-size', 'border', 'background'])):
                    logger.info(f"   –£–¥–∞–ª—è–µ–º CSS —Ñ—Ä–∞–≥–º–µ–Ω—Ç: {part_stripped[:100]}...")
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —á–∞—Å—Ç–∏
                if not part_stripped:
                    continue
                    
                clean_parts.append(part)
            
            # –°–æ–µ–¥–∏–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–µ —á–∞—Å—Ç–∏
            html_content = '<br />'.join(clean_parts)
            logger.info(f"‚úÖ –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –æ—Å—Ç–∞–ª–æ—Å—å {len(clean_parts)} —á–∞—Å—Ç–µ–π")
        
        # –ü–∞—Ä—Å–∏–º HTML
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –ù–∞—Ö–æ–¥–∏–º —Ç–µ–≥ <body>
        body_tag = soup.find('body')
        if body_tag:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ body, —É–±–∏—Ä–∞—è —Å–∞–º —Ç–µ–≥ <body>
            body_content = ""
            for element in body_tag.contents:
                body_content += str(element)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º HTML –≤ Markdown-like —Ñ–æ—Ä–º–∞—Ç –¥–ª—è TransGemini
            from bs4 import BeautifulSoup
            clean_soup = BeautifulSoup(body_content, 'html.parser')
            
            # –ó–∞–º–µ–Ω—è–µ–º HTML —Ç–µ–≥–∏ –Ω–∞ Markdown/—Ç–µ–∫—Å—Ç
            markdown_content = ""
            
            for element in clean_soup.find_all():
                if element.name == 'p':
                    # –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã —Ä–∞–∑–¥–µ–ª—è–µ–º –¥–≤—É–º—è –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫
                    text = element.get_text().strip()
                    if text:
                        markdown_content += text + "\n\n"
                elif element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ Markdown
                    level = int(element.name[1])
                    text = element.get_text().strip()
                    if text:
                        markdown_content += '#' * level + ' ' + text + "\n\n"
                elif element.name == 'br':
                    markdown_content += "\n"
                elif element.name in ['strong', 'b']:
                    text = element.get_text().strip()
                    if text:
                        markdown_content += f"**{text}**"
                elif element.name in ['em', 'i']:
                    text = element.get_text().strip()
                    if text:
                        markdown_content += f"*{text}*"
            
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –ø—Ä–æ—Å—Ç–æ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
            if not markdown_content.strip():
                markdown_content = clean_soup.get_text()
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –∏ –ø—Ä–æ–±–µ–ª—ã
            markdown_content = re.sub(r'\n\s*\n\s*\n+', '\n\n', markdown_content)
            markdown_content = re.sub(r'[ \t]+', ' ', markdown_content)
            
            logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ body –≤ Markdown ({len(markdown_content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            return markdown_content.strip()
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ–≥–∞ body, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç, –Ω–æ —É–±–∏—Ä–∞–µ–º —Å—Ç–∏–ª–∏ –∏ HTML —Ç–µ–≥–∏
            logger.warning("‚ö†Ô∏è –¢–µ–≥ <body> –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç")
            
            # –£–±–∏—Ä–∞–µ–º —Ç–µ–≥–∏ <head>, <style>, <html>, –∏ DOCTYPE
            content = re.sub(r'<!DOCTYPE[^>]*>', '', html_content, flags=re.IGNORECASE)
            content = re.sub(r'<html[^>]*>', '', content, flags=re.IGNORECASE)
            content = re.sub(r'</html>', '', content, flags=re.IGNORECASE)
            content = re.sub(r'<head[^>]*>.*?</head>', '', content, flags=re.DOTALL | re.IGNORECASE)
            content = re.sub(r'<style[^>]*>.*?</style>', '', content, flags=re.DOTALL | re.IGNORECASE)
            content = re.sub(r'<\?xml[^>]*\?>', '', content, flags=re.IGNORECASE)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –æ—Ç CSS —Å—Ç–∏–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –ø–æ–ø–∞—Å—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç
            content = re.sub(r'body\s*\{[^}]*\}', '', content, flags=re.DOTALL | re.IGNORECASE)
            content = re.sub(r'[a-zA-Z\-]+\s*\{[^}]*\}', '', content, flags=re.DOTALL)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ HTML —Ç–µ–≥–∏ –≤ —Ç–µ–∫—Å—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            content = re.sub(r'<p[^>]*>', '\n', content, flags=re.IGNORECASE)
            content = re.sub(r'</p>', '\n\n', content, flags=re.IGNORECASE)
            content = re.sub(r'<br\s*/?>', '\n', content, flags=re.IGNORECASE)
            content = re.sub(r'<h[1-6][^>]*>(.*?)</h[1-6]>', r'# \1\n\n', content, flags=re.IGNORECASE | re.DOTALL)
            
            # –£–±–∏—Ä–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è HTML —Ç–µ–≥–∏
            content = re.sub(r'<[^>]+>', '', content)
            
            # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
            content = re.sub(r'\n\s*\n\s*\n+', '\n\n', content)
            content = re.sub(r'[ \t]+', ' ', content)
            
            return content.strip()
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è body –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
        logger.info("   –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç")
        return html_content

def format_glossary_for_prompt(glossary_data: dict, text_content: str = None, use_dynamic_glossary: bool = True) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≥–ª–æ—Å—Å–∞—Ä–∏–π –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
    if not glossary_data:
        logger.info("üìö –ì–ª–æ—Å—Å–∞—Ä–∏–π –ø—É—Å—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
        return ""
        
    logger.info(f"üìö –ò—Å—Ö–æ–¥–Ω—ã–π –≥–ª–æ—Å—Å–∞—Ä–∏–π —Å–æ–¥–µ—Ä–∂–∏—Ç {len(glossary_data)} —Ç–µ—Ä–º–∏–Ω–æ–≤")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ç–µ–∫—Å—Ç –∏ –≤–∫–ª—é—á–µ–Ω–∞ –æ–ø—Ü–∏—è
    glossary_to_use = glossary_data
    if text_content and use_dynamic_glossary and glossary_data:
        glossary_to_use = DynamicGlossaryFilter.filter_glossary_for_text(
            glossary_data, text_content
        )
        logger.info(f"üîç –ü–æ—Å–ª–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª—Å—è {len(glossary_to_use)} —Ç–µ—Ä–º–∏–Ω–æ–≤")
        
    if not glossary_to_use:
        logger.info("üìö –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≥–ª–æ—Å—Å–∞—Ä–∏–π –ø—É—Å—Ç")
        return ""
        
    glossary_lines = []
    for original, translation in glossary_to_use.items():
        glossary_lines.append(f"  {original} = {translation}")
        
    glossary_text = f"\n\n**–ì–õ–û–°–°–ê–†–ò–ô:**\n" + "\n".join(glossary_lines)
    logger.info(f"üìö –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –≥–ª–æ—Å—Å–∞—Ä–∏–π –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞: {len(glossary_lines)} —Ç–µ—Ä–º–∏–Ω–æ–≤")
    
    return glossary_text

class DynamicGlossaryFilterBot:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –≥–ª–æ—Å—Å–∞—Ä–∏—è –¥–ª—è –±–æ—Ç–∞ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏"""
    
    @staticmethod
    def filter_glossary_for_text(full_glossary, text, min_word_length=3):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –≥–ª–æ—Å—Å–∞—Ä–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ —Ç–µ–∫—Å—Ç–µ
        
        Args:
            full_glossary: –ø–æ–ª–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –≥–ª–æ—Å—Å–∞—Ä–∏—è {–æ—Ä–∏–≥–∏–Ω–∞–ª: –ø–µ—Ä–µ–≤–æ–¥}
            text: —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            min_word_length: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ—Ä–º–∏–Ω–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        """
        if not full_glossary or not text:
            return {}
            
        filtered_glossary = {}
        text_lower = text.lower()
        
        for original, translation in full_glossary.items():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
            if len(original) < min_word_length:
                continue
                
            # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤ —Ç–µ–∫—Å—Ç–µ
            if original.lower() in text_lower:
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                import re
                # –°–æ–∑–¥–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–µ–ª–æ–≥–æ —Å–ª–æ–≤–∞/—Ñ—Ä–∞–∑—ã
                pattern = r'\b' + re.escape(original) + r'\b'
                if re.search(pattern, text, re.IGNORECASE):
                    filtered_glossary[original] = translation
                    
        return filtered_glossary

class DynamicWorker(Worker):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π Worker —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≥–ª–æ—Å—Å–∞—Ä–∏—è"""
    
    def __init__(self, *args, **kwargs):
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –≥–ª–æ—Å—Å–∞—Ä–∏—è
        self.glossary_data = kwargs.pop('glossary_data', None)
        self.use_dynamic_glossary = kwargs.pop('use_dynamic_glossary', True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π Worker
        super().__init__(*args, **kwargs)
        
        logger.info(f"üîß DynamicWorker —Å–æ–∑–¥–∞–Ω:")
        logger.info(f"   üìö –ì–ª–æ—Å—Å–∞—Ä–∏–π: {'–î–∞' if self.glossary_data else '–ù–µ—Ç'}")
        logger.info(f"   üîÑ –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è: {'–í–∫–ª—é—á–µ–Ω–∞' if self.use_dynamic_glossary else '–í—ã–∫–ª—é—á–µ–Ω–∞'}")
        if self.glossary_data:
            logger.info(f"   üìä –†–∞–∑–º–µ—Ä –≥–ª–æ—Å—Å–∞—Ä–∏—è: {len(self.glossary_data)} —Ç–µ—Ä–º–∏–Ω–æ–≤")
    
    def prepare_chunk_prompt(self, chunk_text, base_prompt_template):
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è —á–∞–Ω–∫–∞ —Å —É—á–µ—Ç–æ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≥–ª–æ—Å—Å–∞—Ä–∏—è
        –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º —ç—Ç–æ—Ç –º–µ—Ç–æ–¥ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –≥–ª–æ—Å—Å–∞—Ä–∏—è
        """
        try:
            if not self.glossary_data or not self.use_dynamic_glossary:
                # –ï—Å–ª–∏ –Ω–µ—Ç –≥–ª–æ—Å—Å–∞—Ä–∏—è –∏–ª–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
                return base_prompt_template.replace("{text}", chunk_text)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –≥–ª–æ—Å—Å–∞—Ä–∏—è –¥–ª—è —ç—Ç–æ–≥–æ —á–∞–Ω–∫–∞
            filtered_glossary = DynamicGlossaryFilterBot.filter_glossary_for_text(
                self.glossary_data, chunk_text
            )
            
            original_count = len(self.glossary_data)
            filtered_count = len(filtered_glossary)
            logger.info(f"üîç –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è: {original_count} ‚Üí {filtered_count} —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è —á–∞–Ω–∫–∞")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –≥–ª–æ—Å—Å–∞—Ä–∏–µ–º –¥–ª—è —ç—Ç–æ–≥–æ —á–∞–Ω–∫–∞
            if filtered_glossary:
                dynamic_glossary_text = format_glossary_for_prompt(
                    filtered_glossary, use_dynamic_glossary=False  # –£–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω
                )
                
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –≥–ª–æ—Å—Å–∞—Ä–∏–µ–º
                chunk_prompt = f"""{dynamic_glossary_text}

–¢–ï–ö–°–¢ –î–õ–Ø –ü–ï–†–ï–í–û–î–ê:
{chunk_text}"""
                logger.info(f"üìö –ü—Ä–∏–º–µ–Ω–µ–Ω –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π: {filtered_count} —Ç–µ—Ä–º–∏–Ω–æ–≤")
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç
                chunk_prompt = chunk_text
                logger.info(f"üìö –ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —á–∞–Ω–∫–∞")
            
            return chunk_prompt
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø—Ä–æ–º–ø—Ç–∞ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –≥–ª–æ—Å—Å–∞—Ä–∏–µ–º: {e}")
            # Fallback –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –ø—Ä–æ–º–ø—Ç—É
            return base_prompt_template.replace("{text}", chunk_text)

async def translate_file_with_transgemini(input_file: str, output_file: str, 
                                        input_format: str, output_format: str,
                                        target_language: str, api_key: str, 
                                        model_name: str, progress_callback=None,
                                        start_chapter: int = 1, chapter_count: int = 0,
                                        chapters_info: dict = None, 
                                        glossary_data: dict = None) -> tuple[bool, str]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è TransGemini.py Worker –∫–ª–∞—Å—Å–∞
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—á–Ω–æ —Ç–∞–∫—É—é –∂–µ –ª–æ–≥–∏–∫—É –∫–∞–∫ TransGemini –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤
    """
    
    logger.info(f"üöÄ translate_file_with_transgemini: –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥")
    logger.info(f"üìÅ –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {input_file}")
    logger.info(f"üìÑ –§–æ—Ä–º–∞—Ç: {input_format} -> {output_format}")
    logger.info(f"üìö –ì–ª–æ—Å—Å–∞—Ä–∏–π –ø–µ—Ä–µ–¥–∞–Ω: {'–î–∞' if glossary_data else '–ù–µ—Ç'}")
    if glossary_data:
        logger.info(f"üìö –†–∞–∑–º–µ—Ä –≥–ª–æ—Å—Å–∞—Ä–∏—è: {len(glossary_data)} —Ç–µ—Ä–º–∏–Ω–æ–≤")
    logger.info(f"ü§ñ –ú–æ–¥–µ–ª—å: {model_name}")
    
    start_time = datetime.datetime.now()
    
    def run_worker():
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç Worker –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ"""
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ TransGemini
            from TransGemini import Worker, MODELS
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏
            model_config = MODELS.get(model_name, MODELS.get("Gemini 2.0 Flash", MODELS[list(MODELS.keys())[0]]))
            logger.info(f"ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å: {model_name} —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π: {model_config}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π
            use_dynamic_glossary = bool(glossary_data)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º prompt –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–µ–ª–µ–≤–æ–≥–æ —è–∑—ã–∫–∞
            # –ü—Ä–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–º –≥–ª–æ—Å—Å–∞—Ä–∏–∏ –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π –≤ –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
            if target_language.lower() in ['—Ä—É—Å—Å–∫–∏–π', 'russian', 'ru']:
                base_prompt = """–ü–µ—Ä–µ–≤–µ–¥–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –°–æ—Ö—Ä–∞–Ω–∏ –∏—Å—Ö–æ–¥–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏–∞–ª–æ–≥–æ–≤ –∏ —Ä–∞–∑–±–∏–≤–∫—É –Ω–∞ –∞–±–∑–∞—Ü—ã. –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π –∫ –ø–µ—Ä–µ–≤–æ–¥—É."""
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π –∫ –ø—Ä–æ–º–ø—Ç—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞
                if glossary_data and not use_dynamic_glossary:
                    glossary_text = format_glossary_for_prompt(glossary_data, use_dynamic_glossary=False)
                    base_prompt += glossary_text
                    logger.info("üìö –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π –¥–æ–±–∞–≤–ª–µ–Ω –∫ –ø—Ä–æ–º–ø—Ç—É (RU)")
                elif glossary_data and use_dynamic_glossary:
                    logger.info("üìö –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å—Å—è –∫ –∫–∞–∂–¥–æ–º—É —á–∞–Ω–∫—É (RU)")
                
                prompt_template = base_prompt + "\n\n{text}"
            else:
                base_prompt = f"""Translate the following text to {target_language}. Preserve the original formatting, dialogue structure, and paragraph breaks. Do not add any comments or explanations to the translation."""
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π –∫ –ø—Ä–æ–º–ø—Ç—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞
                if glossary_data and not use_dynamic_glossary:
                    glossary_text = format_glossary_for_prompt(glossary_data, use_dynamic_glossary=False)
                    base_prompt += glossary_text
                    logger.info("üìö –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π –¥–æ–±–∞–≤–ª–µ–Ω –∫ –ø—Ä–æ–º–ø—Ç—É (EN)")
                elif glossary_data and use_dynamic_glossary:
                    logger.info("üìö –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å—Å—è –∫ –∫–∞–∂–¥–æ–º—É —á–∞–Ω–∫—É (EN)")
                
                prompt_template = base_prompt + "\n\n{text}"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏–∑ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ output_file
            output_dir = os.path.dirname(output_file)
            if not output_dir:
                output_dir = os.path.dirname(input_file)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ñ–∞–π–ª–∞—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ TransGemini
            # TransGemini –æ–∂–∏–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π: (input_type, filepath, epub_html_path_or_none)
            input_type = input_format.lower()
            files_to_process_data = []
            
            if input_type == 'epub':
                # –î–ª—è EPUB —Ñ–∞–π–ª–æ–≤ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ HTML —Ñ–∞–π–ª–æ–≤ –≤–Ω—É—Ç—Ä–∏
                try:
                    with zipfile.ZipFile(input_file, 'r') as epub_zip:
                        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ HTML —Ñ–∞–π–ª—ã –∫–∞–∫ –≤ TransGemini
                        html_files_in_epub = sorted([
                            name for name in epub_zip.namelist()
                            if name.lower().endswith(('.html', '.xhtml', '.htm'))
                            and not name.startswith(('__MACOSX', 'META-INF/'))
                        ])
                        
                        # –§–∏–ª—å—Ç—Ä—É–µ–º –≥–ª–∞–≤—ã, –∏—Å–∫–ª—é—á–∞—è —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã (–∫–∞–∫ –≤ –∞–Ω–∞–ª–∏–∑–µ)
                        content_files = []
                        for file_path_in_epub in html_files_in_epub:
                            filename_base = Path(file_path_in_epub).stem.split('.')[0].lower()
                            
                            # –°–ø–∏—Å–æ–∫ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–∫–∞–∫ –≤ TransGemini)
                            skip_indicators = ['toc', 'nav', 'ncx', 'cover', 'title', 'index', 'copyright', 'about', 'meta', 'opf',
                                              'masthead', 'colophon', 'imprint', 'acknowledgments', 'dedication',
                                              'glossary', 'bibliography', 'notes', 'annotations', 'epigraph', 'halftitle',
                                              'frontmatter', 'backmatter', 'preface', 'introduction', 'appendix', 'biography',
                                              'isbn', 'legal', 'notice', 'otherbooks', 'prelims', 'team', 'promo', 'bonus']
                            
                            is_skip_file = any(skip_word in filename_base for skip_word in skip_indicators)
                            is_translated = filename_base.endswith('_translated')
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                            try:
                                file_info = epub_zip.getinfo(file_path_in_epub)
                                file_size = file_info.file_size
                            except:
                                file_size = 0
                            
                            # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å–ª—É–∂–µ–±–Ω—ã–π –∏ –Ω–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π, –∏ –∏–º–µ–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                            if not is_skip_file and not is_translated and file_size > 500:
                                content_files.append(file_path_in_epub)
                        
                        logger.info(f"üìù –ù–∞–π–¥–µ–Ω–æ {len(content_files)} HTML —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ EPUB")
                        
                        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ
                        if chapter_count > 0:
                            # –ë–µ—Ä–µ–º —Ñ–∞–π–ª—ã –Ω–∞—á–∏–Ω–∞—è —Å start_chapter
                            start_idx = max(0, start_chapter - 1)
                            end_idx = min(len(content_files), start_idx + chapter_count)
                            selected_files = content_files[start_idx:end_idx]
                            logger.info(f"üìù –í—ã–±—Ä–∞–Ω–æ {len(selected_files)} —Ñ–∞–π–ª–æ–≤ (–≥–ª–∞–≤—ã {start_chapter}-{start_chapter + len(selected_files) - 1})")
                        else:
                            selected_files = content_files
                            logger.info(f"üìù –í—ã–±—Ä–∞–Ω—ã –≤—Å–µ {len(selected_files)} —Ñ–∞–π–ª–æ–≤")
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–∂–¥—ã–π HTML —Ñ–∞–π–ª –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é –∑–∞–¥–∞—á—É
                        for html_file in selected_files:
                            files_to_process_data.append(('epub', input_file, html_file))
                        
                        if not files_to_process_data:
                            logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ HTML —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ EPUB")
                            return False, "–í EPUB —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö HTML —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"
                            
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ EPUB —Ñ–∞–π–ª–∞: {e}")
                    return False, f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ EPUB —Ñ–∞–π–ª–∞: {str(e)}"
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
                files_to_process_data = [(input_type, input_file, None)]
            
            logger.info(f"üìù –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {files_to_process_data}")
            
            # –°–æ–∑–¥–∞–µ–º DynamicWorker —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –≥–ª–æ—Å—Å–∞—Ä–∏—è
            # –î–ª—è EPUB —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç HTML, –∑–∞—Ç–µ–º —Å–æ–±–µ—Ä–µ–º EPUB –æ—Ç–¥–µ–ª—å–Ω–æ
            worker_output_format = 'html' if output_format == 'epub' else output_format
            
            worker = DynamicWorker(
                api_key=api_key,
                out_folder=output_dir,
                prompt_template=prompt_template,
                files_to_process_data=files_to_process_data,
                model_config=model_config,
                max_concurrent_requests=1,  # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ Telegram –±–æ—Ç–∞
                output_format=worker_output_format,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è EPUB
                chunking_enabled_gui=True,
                chunk_limit=900000,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
                chunk_window=500,
                temperature=0.1,
                chunk_delay_seconds=0.5,  # –£–º–µ–Ω—å—à–µ–Ω–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
                proxy_string=None,
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –≥–ª–æ—Å—Å–∞—Ä–∏—è
                glossary_data=glossary_data,
                use_dynamic_glossary=use_dynamic_glossary
            )
            
            logger.info(f"DynamicWorker —Å–æ–∑–¥–∞–Ω —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π: {'–í–∫–ª—é—á–µ–Ω–∞' if use_dynamic_glossary else '–í—ã–∫–ª—é—á–µ–Ω–∞'}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –ª–æ–≥–æ–≤ Worker'–∞
            worker_logs = []
            worker_errors = []
            
            def capture_worker_log(message):
                worker_logs.append(message)
                logger.info(f"Worker Log: {message}")
                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ API –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
                if any(word in message for word in ['[API START]', '[API CALL]', '[API RESPONSE]', '–û–±—Ä–∞–±–æ—Ç–∫–∞', '–ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É', '–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç', '–û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å']):
                    logger.info(f"[PROGRESS] {message}")
                if any(keyword in message.lower() for keyword in ['error', 'failed', 'exception', '–æ—à–∏–±–∫–∞']):
                    worker_errors.append(message)
            
            def extract_progress_info(log_message: str) -> str:
                """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ –∏–∑ –ª–æ–≥-—Å–æ–æ–±—â–µ–Ω–∏—è Worker'–∞"""
                try:
                    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —ç—Ç–∞–ø–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    patterns = [
                        # API –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å - –Ω–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                        (r'\[API START\]\s*([^:]+):\s*–ù–∞—á–∏–Ω–∞–µ–º\s+API\s+–∑–∞–ø—Ä–æ—Å', 
                         lambda m: f"üîÑ **{m.group(1)}**\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º API –∑–∞–ø—Ä–æ—Å..."),
                        
                        (r'\[API CALL\]\s*([^:]+):\s*–û—Ç–ø—Ä–∞–≤–ª—è–µ–º\s+–∑–∞–ø—Ä–æ—Å\s+–∫\s+API', 
                         lambda m: f"üì° **{m.group(1)}**\nü§ñ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Gemini API..."),
                        
                        (r'\[API RESPONSE\]\s*([^:]+):\s*–ü–æ–ª—É—á–µ–Ω\s+–æ—Ç–≤–µ—Ç\s+–æ—Ç\s+API', 
                         lambda m: f"‚úÖ **{m.group(1)}**\nüìù –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç API!"),
                        
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ EPUB —Ñ–∞–π–ª–æ–≤
                        (r'\[INFO\]\s*([^:]+):\s*–û–±—Ä–∞–±–æ—Ç–∫–∞\s+(\d+)/(\d+)\s+—á–∞–Ω–∫–æ–≤', 
                         lambda m: f"üìÑ **{m.group(1)}**\n‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —á–∞–Ω–∫ {m.group(2)} –∏–∑ {m.group(3)}"),
                        
                        # –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
                        (r'\[INFO\]\s*([^:]+):\s*–ù–∞—á–∏–Ω–∞—é\s+–æ–±—Ä–∞–±–æ—Ç–∫—É', 
                         lambda m: f"üöÄ **–ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É**\nüìÑ {m.group(1)}"),
                        
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ HTML —Ñ–∞–π–ª–æ–≤ –∏–∑ EPUB
                        (r'\[INFO\]\s*([^:]+):\s*–ö–æ–Ω—Ç–µ–Ω—Ç\s+\(([^)]+)\).*—Ä–∞–∑–¥–µ–ª—è–µ–º', 
                         lambda m: f"üìñ **{m.group(1)}**\nüîÑ –†–∞–∑–¥–µ–ª—è—é –∫–æ–Ω—Ç–µ–Ω—Ç ({m.group(2)})"),
                        
                        # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ API (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
                        (r'\[INFO\]\s*([^:]+):\s*–û—Ç–ø—Ä–∞–≤–ª—è—é\s+–∑–∞–ø—Ä–æ—Å\s+–≤\s+API', 
                         lambda m: f"ü§ñ **{m.group(1)}**\nüì° –û—Ç–ø—Ä–∞–≤–ª—è—é –≤ Gemini API..."),
                        
                        # –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç API (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
                        (r'\[INFO\]\s*([^:]+):\s*–ü–æ–ª—É—á–µ–Ω\s+–æ—Ç–≤–µ—Ç.*—Å–∏–º–≤–æ–ª–æ–≤', 
                         lambda m: f"‚úÖ **{m.group(1)}**\nüìù –ü–æ–ª—É—á–µ–Ω –ø–µ—Ä–µ–≤–æ–¥ –æ—Ç Gemini"),
                        
                        # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                        (r'\[INFO\]\s*([^:]+):\s*–ü—Ä–∏–º–µ–Ω—è–µ–º\s+–∑–∞–¥–µ—Ä–∂–∫—É\s+([\d.]+)\s+—Å–µ–∫', 
                         lambda m: f"‚è∞ **{m.group(1)}**\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {m.group(2)} —Å–µ–∫..."),
                        
                        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
                        (r'\[INFO\]\s*([^:]+):\s*–û–±—Ä–∞–±–æ—Ç–∫–∞\s+–∑–∞–≤–µ—Ä—à–µ–Ω–∞', 
                         lambda m: f"‚úÖ **{m.group(1)}**\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"),
                        
                        # –ü—Ä–æ–≥—Ä–µ—Å—Å —á–∞–Ω–∫–æ–≤
                        (r'Chunk\s+(\d+)/(\d+)', 
                         lambda m: f"üìù **–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞**\nüî¢ {m.group(1)} –∏–∑ {m.group(2)}"),
                    ]
                    
                    for pattern, formatter in patterns:
                        match = re.search(pattern, log_message, re.IGNORECASE)
                        if match:
                            try:
                                return formatter(match)
                            except Exception as e:
                                logger.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")
                                return f"üìã {log_message}"
                    
                    return None
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")
                    return None
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –ª–æ–≥–æ–≤
            worker.log_message.connect(capture_worker_log)
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω
            if progress_callback:
                def on_log_message(message):
                    progress_info = extract_progress_info(message)
                    if progress_info:
                        try:
                            # –ó–∞–ø—É—Å–∫–∞–µ–º callback –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
                            asyncio.run_coroutine_threadsafe(
                                progress_callback(progress_info), 
                                asyncio.get_event_loop()
                            )
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ progress_callback: {e}")
                
                worker.log_message.connect(on_log_message)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
            logger.info("üèÉ –ó–∞–ø—É—Å–∫–∞–µ–º Worker.run()...")
            worker.run()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if worker_errors:
                error_msg = f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ—à–∏–±–∫–∏ –≤–æ –≤—Ä–µ–º—è –ø–µ—Ä–µ–≤–æ–¥–∞: {'; '.join(worker_errors[:3])}"
                logger.error(f"‚ùå {error_msg}")
                return False, error_msg

            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è EPUB - —Å–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π EPUB —Å –∑–∞–º–µ–Ω–æ–π —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö –≥–ª–∞–≤
            if output_format == 'epub' and input_format == 'epub':
                logger.info("üìö –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä–∫—É –ø–æ–ª–Ω–æ–≥–æ EPUB —Ñ–∞–π–ª–∞ —Å —á–∞—Å—Ç–∏—á–Ω—ã–º –ø–µ—Ä–µ–≤–æ–¥–æ–º (–∫–∞–∫ –≤ TransGemini)...")
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                logger.info(f"üìÅ –§–∞–π–ª—ã –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {output_dir}:")
                for file in os.listdir(output_dir):
                    file_path = os.path.join(output_dir, file)
                    if os.path.isfile(file_path):
                        file_size = os.path.getsize(file_path)
                        logger.info(f"   - {file} (—Ä–∞–∑–º–µ—Ä: {file_size})")
                
                logger.info(f"üìù –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
                for i, (ftype, fpath, html_path) in enumerate(files_to_process_data):
                    logger.info(f"   {i+1}. Type: {ftype}, File: {Path(fpath).name}, HTML: {html_path}")
                
                try:
                    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Å–±–æ—Ä–∫–∏ EPUB –∏–∑ TransGemini
                    from TransGemini import write_to_epub
                    
                    # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                    translation_mapping = {}
                    translated_files_found = []
                    
                    logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö HTML —Ñ–∞–π–ª–æ–≤ –≤ {output_dir}...")
                    
                    for file in os.listdir(output_dir):
                        if file.endswith('_translated.html'):
                            file_path = os.path.join(output_dir, file)
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è –±–µ–∑ _translated.html
                            base_name = file.replace('_translated.html', '')
                            
                            logger.info(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file} (–±–∞–∑–æ–≤–æ–µ –∏–º—è: {base_name})")
                            
                            # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
                            with open(file_path, 'r', encoding='utf-8') as f:
                                raw_translated_content = f.read()
                            
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ <body> –∏–∑ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ HTML, 
                            # —É–¥–∞–ª—è—è CSS —Å—Ç–∏–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ <head>
                            translated_content = extract_body_content_from_html(raw_translated_content)
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                            raw_content_preview = raw_translated_content[:300].replace('\n', ' ') if raw_translated_content else "–ø—É—Å—Ç–æ–π"
                            logger.info(f"üîç –ì–ª–∞–≤–∞ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞: {file}")
                            logger.info(f"üìù –†–∞–∑–º–µ—Ä –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(raw_translated_content) if raw_translated_content else 0} —Å–∏–º–≤–æ–ª–æ–≤")
                            logger.info(f"üìñ –ü—Ä–µ–≤—å—é –∏—Å—Ö–æ–¥–Ω–æ–≥–æ: {raw_content_preview}...")
                            
                            content_preview = translated_content[:300].replace('\n', ' ') if translated_content else "–ø—É—Å—Ç–æ–π"
                            logger.info(f"üìù –†–∞–∑–º–µ—Ä –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(translated_content) if translated_content else 0} —Å–∏–º–≤–æ–ª–æ–≤")
                            logger.info(f"üìñ –ü—Ä–µ–≤—å—é –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ: {content_preview}...")
                            
                            if len(translated_content) < 100:
                                logger.warning(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–π –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –≤ {file}: {translated_content}")
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤ –æ—á–∏—â–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–Ω—Ç–µ –Ω–µ—Ç CSS —Å—Ç–∏–ª–µ–π –∏ HTML —Ç–µ–≥–æ–≤
                            if 'font-family' in translated_content or 'line-height' in translated_content:
                                logger.warning(f"‚ö†Ô∏è –í –æ—á–∏—â–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–Ω—Ç–µ –≤—Å—ë –µ—â—ë –µ—Å—Ç—å CSS —Å—Ç–∏–ª–∏: {file}")
                                logger.info(f"   –ù–∞—á–∞–ª–æ: {translated_content[:500]}")
                            elif '<p>' in translated_content or '<div>' in translated_content or '<br' in translated_content:
                                logger.warning(f"‚ö†Ô∏è –í –æ—á–∏—â–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–Ω—Ç–µ –≤—Å—ë –µ—â—ë –µ—Å—Ç—å HTML —Ç–µ–≥–∏: {file}")
                                logger.info(f"   –ù–∞—á–∞–ª–æ: {translated_content[:500]}")
                            else:
                                logger.info(f"‚úÖ –û—á–∏—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç CSS —Å—Ç–∏–ª–µ–π –∏ HTML —Ç–µ–≥–æ–≤")
                            
                            # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π HTML —Ñ–∞–π–ª –≤ —Å–ø–∏—Å–∫–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
                            matched_original_path = None
                            
                            # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ stem –∏–º–µ–Ω–∏
                            for (ftype, fpath, html_path) in files_to_process_data:
                                if html_path:
                                    html_stem = Path(html_path).stem
                                    if html_stem == base_name:
                                        matched_original_path = html_path
                                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {base_name} -> {html_path}")
                                        break
                            
                            # –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—â–µ–º –ø–æ –±–æ–ª–µ–µ –≥–∏–±–∫–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
                            if not matched_original_path:
                                logger.info(f"‚ö†Ô∏è –¢–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª—è {base_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—â–µ–º –ø–æ –≥–∏–±–∫–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º...")
                                
                                for (ftype, fpath, html_path) in files_to_process_data:
                                    if html_path:
                                        html_stem = Path(html_path).stem.lower()
                                        base_name_lower = base_name.lower()
                                        
                                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
                                        if (html_stem == base_name_lower or 
                                            html_stem.replace('_', '-') == base_name_lower.replace('_', '-') or
                                            html_stem.replace('-', '_') == base_name_lower.replace('-', '_') or
                                            base_name_lower in html_stem or 
                                            html_stem in base_name_lower):
                                            matched_original_path = html_path
                                            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –≥–∏–±–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {base_name} -> {html_path}")
                                            break
                            
                            if matched_original_path:
                                translation_mapping[matched_original_path] = translated_content
                                translated_files_found.append(file)
                                
                                # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                                content_preview = translated_content[:200].replace('\n', ' ') if translated_content else "–ø—É—Å—Ç–æ–π"
                                logger.info(f"‚úÖ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file} -> {matched_original_path}")
                                logger.info(f"üîç –ì–ª–∞–≤–∞ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞: {len(translated_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                                logger.info(f"üìù –ü—Ä–µ–≤—å—é –ø–µ—Ä–µ–≤–æ–¥–∞: {content_preview}...")
                            else:
                                logger.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª—è –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {file}")
                                logger.info(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ HTML –ø—É—Ç–∏ –≤ files_to_process_data:")
                                for (ftype, fpath, html_path) in files_to_process_data:
                                    if html_path:
                                        logger.info(f"     - {html_path} (stem: {Path(html_path).stem})")
                    
                    logger.info(f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–∑–¥–∞–Ω–∏—è –º–∞–ø–ø–∏–Ω–≥–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤:")
                    logger.info(f"   –ù–∞–π–¥–µ–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(translation_mapping)}")
                    for orig_path, content in translation_mapping.items():
                        content_preview = content[:100].replace('\n', ' ') if content else "–ø—É—Å—Ç–æ–π"
                        logger.info(f"   - {orig_path} ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤): {content_preview}...")
                    
                    if not translation_mapping:
                        logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–±–æ—Ä–∫–∏ EPUB!")
                        logger.info("üìã –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ Worker —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–ª –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ HTML —Ñ–∞–π–ª—ã")
                        return False, "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–±–æ—Ä–∫–∏ EPUB"
                    
                    if translation_mapping:
                        # –¢–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π EPUB —Ñ–∞–π–ª: –±–µ—Ä–µ–º –í–°–ï —Ñ–∞–π–ª—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ EPUB
                        # –∏ –∑–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –±—ã–ª–∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã
                        
                        logger.info("üìñ –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π EPUB —Å —á–∞—Å—Ç–∏—á–Ω—ã–º –ø–µ—Ä–µ–≤–æ–¥–æ–º...")
                        
                        # –ü–æ–ª—É—á–∞–µ–º –í–°–ï HTML —Ñ–∞–π–ª—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ EPUB
                        all_epub_parts = []
                        with zipfile.ZipFile(input_file, 'r') as epub_zip:
                            all_html_files = sorted([
                                name for name in epub_zip.namelist()
                                if name.lower().endswith(('.html', '.xhtml', '.htm'))
                                and not name.startswith(('__MACOSX', 'META-INF/'))
                            ])
                            
                            logger.info(f"üìö –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ HTML —Ñ–∞–π–ª—ã –≤ EPUB ({len(all_html_files)} —Ñ–∞–π–ª–æ–≤):")
                            
                            for html_file in all_html_files:
                                try:
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–µ—Ä–µ–≤–æ–¥ –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
                                    if html_file in translation_mapping:
                                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (—Å—Ç—Ä–æ–∫–∞)
                                        content = translation_mapping[html_file]
                                        status = "–ü–ï–†–ï–í–ï–î–ï–ù"
                                        logger.info(f"   ‚úÖ {html_file} - {status} ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
                                    else:
                                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (–±–∞–π—Ç—ã –¥–ª—è TransGemini)
                                        with epub_zip.open(html_file) as f:
                                            content = f.read()  # –û—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ bytes –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                                        status = "–û–†–ò–ì–ò–ù–ê–õ"
                                        logger.info(f"   üìÑ {html_file} - {status} ({len(content)} –±–∞–π—Ç)")
                                    
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π
                                    is_translated = html_file in translation_mapping
                                    
                                    all_epub_parts.append({
                                        'original_filename': html_file,
                                        'content_to_write': content,  # str –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤, bytes –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤
                                        'image_map': {},  # –ü—É—Å—Ç–∞—è –∫–∞—Ä—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                                        'is_original_content': not is_translated,
                                        'translation_warning': None
                                    })
                                    
                                except Exception as e:
                                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {html_file}: {e}")
                                    # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª (–Ω–æ –ª—É—á—à–µ –±—ã –¥–æ–±–∞–≤–∏—Ç—å –∫–∞–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª)
                                    try:
                                        with epub_zip.open(html_file) as f:
                                            content = f.read()  # –û—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ bytes –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                                        all_epub_parts.append({
                                            'original_filename': html_file,
                                            'content_to_write': content,  # bytes –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                                            'image_map': {},
                                            'is_original_content': True,
                                            'translation_warning': f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}"
                                        })
                                        logger.info(f"   üìÑ {html_file} - –û–†–ò–ì–ò–ù–ê–õ (–ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏, {len(content)} –±–∞–π—Ç)")
                                    except Exception as e2:
                                        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å —Ñ–∞–π–ª–æ–º {html_file}: {e2}")
                        
                        logger.info(f"üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –ø–æ–ª–Ω—ã–π EPUB —Å {len(all_epub_parts)} HTML —Ñ–∞–π–ª–∞–º–∏:")
                        logger.info(f"   –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(translation_mapping)}")
                        logger.info(f"   –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(all_epub_parts) - len(translation_mapping)}")
                        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è —Å—Ç—Ä–æ–∫ –∏ –±–∞–π—Ç–æ–≤
                        total_content_size = 0
                        for part in all_epub_parts:
                            content = part.get('content_to_write', '')
                            if isinstance(content, bytes):
                                total_content_size += len(content)
                            elif isinstance(content, str):
                                total_content_size += len(content)
                        logger.info(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {total_content_size} —Å–∏–º–≤–æ–ª–æ–≤/–±–∞–π—Ç")
                        
                        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π EPUB —Ñ–∞–π–ª
                        final_epub_path = os.path.join(output_dir, f"{Path(input_file).stem}_translated.epub")
                        
                        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–±–æ—Ä–∫–∏ EPUB - —á–∏—Ç–∞–µ–º –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                        build_metadata = extract_epub_metadata(input_file)
                        
                        # –î–æ–ø–æ–ª–Ω—è–µ–º/–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è
                        build_metadata.update({
                            'title': f"{Path(input_file).stem}_translated",
                            'author': 'TransGemini Bot',
                            'combined_image_map': {}  # –ü—É—Å—Ç–∞—è –∫–∞—Ä—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                        })
                        
                        # –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Å–±–æ—Ä–∫–∏ EPUB —Å –ø–æ–ª–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º —Ñ–∞–π–ª–æ–≤
                        logger.info("üîß –í—ã–∑—ã–≤–∞–µ–º write_to_epub –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ EPUB...")
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∫ –≤—ã –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏
                        logger.info(f"üìÑ processed_epub_parts: {[p['original_filename'] for p in all_epub_parts]}")
                        logger.info(f"üìä –í—Å–µ–≥–æ —á–∞—Å—Ç–µ–π: {len(all_epub_parts)}")
                        logger.info(f"üìÅ –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π EPUB: {input_file}")
                        logger.info(f"üìÅ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {final_epub_path}")
                        logger.info(f"üîß build_metadata: {build_metadata}")
                        
                        success, error_msg = write_to_epub(
                            out_path=final_epub_path,
                            processed_epub_parts=all_epub_parts,  # –í–°–ï —Ñ–∞–π–ª—ã (–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ + –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ)
                            original_epub_path=input_file,
                            build_metadata=build_metadata,
                            book_title_override=None
                        )
                        
                        if success and os.path.exists(final_epub_path):
                            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π EPUB —Ñ–∞–π–ª –≤ –Ω—É–∂–Ω–æ–µ –º–µ—Å—Ç–æ
                            if final_epub_path != output_file:
                                try:
                                    os.makedirs(os.path.dirname(output_file), exist_ok=True)
                                    shutil.move(final_epub_path, output_file)
                                    final_output_path = output_file
                                except Exception as e:
                                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å EPUB: {e}")
                                    final_output_path = final_epub_path
                            else:
                                final_output_path = final_epub_path
                            
                            # –û—á–∏—â–∞–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ HTML —Ñ–∞–π–ª—ã
                            for file in translated_files_found:
                                try:
                                    file_path = os.path.join(output_dir, file)
                                    os.remove(file_path)
                                    logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª: {file}")
                                except Exception as e:
                                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª {file}: {e}")
                            
                            file_size = os.path.getsize(final_output_path)
                            end_time = datetime.datetime.now()
                            duration = end_time - start_time
                            
                            logger.info(f"‚úÖ –ü–æ–ª–Ω—ã–π EPUB —Ñ–∞–π–ª —Å —á–∞—Å—Ç–∏—á–Ω—ã–º –ø–µ—Ä–µ–≤–æ–¥–æ–º —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
                            logger.info(f"üìÅ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {final_output_path}")
                            logger.info(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç ({file_size // 1024} KB)")
                            logger.info(f"üìñ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ –≥–ª–∞–≤: {len(translation_mapping)}")
                            logger.info(f"üìÑ –í—Å–µ–≥–æ –≥–ª–∞–≤ –≤ EPUB: {len(all_epub_parts)}")
                            logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration}")
                            
                            return True, f"EPUB –ø–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω. –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {os.path.basename(final_output_path)} ({file_size} –±–∞–π—Ç)"
                        else:
                            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∫–∏ EPUB: {error_msg}")
                            return False, f"–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∫–∏ EPUB: {error_msg}"
                    else:
                        logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö HTML —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–±–æ—Ä–∫–∏ EPUB")
                        
                        # –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
                        logger.info("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏:")
                        logger.info(f"   üìÅ –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
                        logger.info(f"   üìÑ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(files_to_process_data)}")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                        logger.info("   üìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
                        for file in os.listdir(output_dir):
                            file_path = os.path.join(output_dir, file)
                            if os.path.isfile(file_path):
                                file_size = os.path.getsize(file_path)
                                logger.info(f"     - {file} ({file_size} –±–∞–π—Ç)")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                        logger.info("   üìã –°–ø–∏—Å–æ–∫ files_to_process_data:")
                        for i, (ftype, fpath, html_path) in enumerate(files_to_process_data):
                            logger.info(f"     {i+1}. Type: {ftype}, File: {Path(fpath).name}, HTML: {html_path}")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤
                        logger.info("   üîç –ü–æ–∏—Å–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:")
                        alternative_patterns = [
                            "*_translated.html",
                            "*_translated.txt", 
                            "*_translated.*",
                            f"{Path(input_file).stem}*"
                        ]
                        
                        import glob
                        for pattern in alternative_patterns:
                            pattern_path = os.path.join(output_dir, pattern)
                            matches = glob.glob(pattern_path)
                            if matches:
                                logger.info(f"     –ü–∞—Ç—Ç–µ—Ä–Ω '{pattern}': –Ω–∞–π–¥–µ–Ω–æ {len(matches)} —Ñ–∞–π–ª–æ–≤")
                                for match in matches[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                                    match_size = os.path.getsize(match) if os.path.exists(match) else 0
                                    logger.info(f"       - {Path(match).name} ({match_size} –±–∞–π—Ç)")
                            else:
                                logger.info(f"     –ü–∞—Ç—Ç–µ—Ä–Ω '{pattern}': —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                        
                        return False, "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö HTML —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–±–æ—Ä–∫–∏ EPUB. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏."
                        
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–∫–µ EPUB: {e}", exc_info=True)
                    return False, f"–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∫–∏ EPUB: {str(e)}"
            
            # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –Ω–µ-EPUB —Ñ–∞–π–ª–æ–≤
            worker_output_ext = 'html' if output_format == 'epub' else output_format
            
            # –ò—â–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            # Worker —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª—ã —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º _translated
            input_name = Path(input_file).stem
            expected_output_name = f"{input_name}_translated.{worker_output_ext}"
            expected_output_path = os.path.join(output_dir, expected_output_name)
            
            if os.path.exists(expected_output_path):
                # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å —Ñ–∞–π–ª
                final_output_path = expected_output_path
                if expected_output_path != output_file:
                    try:
                        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
                        os.makedirs(os.path.dirname(output_file), exist_ok=True)
                        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª
                        shutil.move(expected_output_path, output_file)
                        logger.info(f"‚úÖ –§–∞–π–ª –ø–µ—Ä–µ–º–µ—â–µ–Ω —Å {expected_output_path} –Ω–∞ {output_file}")
                        final_output_path = output_file
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —Ñ–∞–π–ª: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—É—Ç—å")
                        final_output_path = expected_output_path
                
                file_size = os.path.getsize(final_output_path)
                end_time = datetime.datetime.now()
                duration = end_time - start_time
                
                logger.info(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                logger.info(f"üìÅ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {final_output_path}")
                logger.info(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
                logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration}")
                
                return True, f"–ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω. –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {os.path.basename(final_output_path)} ({file_size} –±–∞–π—Ç)"
            else:
                # –ò—â–µ–º –ª—é–±—ã–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å _translated
                created_files = []
                for file in os.listdir(output_dir):
                    if '_translated' in file and file.endswith(f'.{output_format}'):
                        created_files.append(os.path.join(output_dir, file))
                
                if created_files:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    actual_output = created_files[0]
                    logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω —Å–æ–∑–¥–∞–Ω–Ω—ã–π —Ñ–∞–π–ª: {actual_output}")
                    
                    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –∫ –Ω—É–∂–Ω–æ–º—É –∏–º–µ–Ω–∏
                    final_output_path = actual_output
                    if actual_output != output_file:
                        try:
                            shutil.move(actual_output, output_file)
                            logger.info(f"‚úÖ –§–∞–π–ª –ø–µ—Ä–µ–º–µ—â–µ–Ω –Ω–∞ {output_file}")
                            final_output_path = output_file
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —Ñ–∞–π–ª: {e}")
                            final_output_path = actual_output
                    
                    file_size = os.path.getsize(final_output_path)
                    return True, f"–ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω. –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {os.path.basename(final_output_path)} ({file_size} –±–∞–π—Ç)"
                else:
                    error_msg = f"–§–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω. –û–∂–∏–¥–∞–ª—Å—è: {expected_output_path}"
                    logger.error(f"‚ùå {error_msg}")
                    return False, error_msg
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ Worker: {e}", exc_info=True)
            return False, f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º Worker –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    try:
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(None, run_worker)
        return result
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}", exc_info=True)
        return False, f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {str(e)}"


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ –ø–æ–º–æ—â–∏"""
    help_text = """
ü§ñ **TransGemini Telegram Bot** - –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Ñ–∞–π–ª–æ–≤

üìñ **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:**
‚Ä¢ EPUB (—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏)
‚Ä¢ TXT (—Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã)
‚Ä¢ DOCX (–¥–æ–∫—É–º–µ–Ω—Ç—ã Word)
‚Ä¢ HTML (–≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã)

üîß **–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –±–æ—Ç—É
2. –í—ã–±–µ—Ä–∏—Ç–µ –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç
3. –í–≤–µ–¥–∏—Ç–µ API –∫–ª—é—á Gemini
4. –í—ã–±–µ—Ä–∏—Ç–µ –≥–ª–∞–≤—ã –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
5. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–µ–≤–æ–¥–∞
6. –ü–æ–ª—É—á–∏—Ç–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª

‚ú® **–ù–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
‚Ä¢ `/settings` - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤—Å–µ–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –±–æ—Ç–∞
‚Ä¢ `/apikeys` - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ API –∫–ª—é—á–∞–º–∏
‚Ä¢ `/addkey –í–ê–®_–ö–õ–Æ–ß` - –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π API –∫–ª—é—á
‚Ä¢ `/removekey –ù–û–ú–ï–†` - —É–¥–∞–ª–∏—Ç—å API –∫–ª—é—á –ø–æ –Ω–æ–º–µ—Ä—É
‚Ä¢ `/clearkeys` - —É–¥–∞–ª–∏—Ç—å –≤—Å–µ API –∫–ª—é—á–∏
‚Ä¢ `/rotation on/off` - –≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Ä–æ—Ç–∞—Ü–∏—é –∫–ª—é—á–µ–π

üîÑ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–æ—Ç–∞—Ü–∏—è –∫–ª—é—á–µ–π:**
–ü—Ä–∏ –≤–∫–ª—é—á–µ–Ω–Ω–æ–π —Ä–æ—Ç–∞—Ü–∏–∏ –±–æ—Ç –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –º–µ–∂–¥—É –≤–∞—à–∏–º–∏ API –∫–ª—é—á–∞–º–∏ –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–æ–≤ –∏–ª–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –æ—à–∏–±–æ–∫.

‚öôÔ∏è **–ö–æ–º–∞–Ω–¥—ã:**
/start - –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É
/help - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É
/cancel - –æ—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â—É—é –æ–ø–µ—Ä–∞—Ü–∏—é

üîë **–ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–∞:**
1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ ai.google.dev
2. –°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ–µ–∫—Ç –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π
3. –ü–æ–ª—É—á–∏—Ç–µ API –∫–ª—é—á –¥–ª—è Gemini
4. –í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á –≤ –±–æ—Ç–µ

üí° **–°–æ–≤–µ—Ç:** –ë–æ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç TransGemini.py –¥–ª—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    """
    await update.message.reply_text(help_text, parse_mode='Markdown')


async def cancel_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ –æ—Ç–º–µ–Ω—ã"""
    user_id = update.effective_user.id
    reset_user_state(user_id)
    
    await update.message.reply_text(
        "‚ùå –¢–µ–∫—É—â–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞.\n"
        "üìé –û—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start",
        reply_markup=InlineKeyboardMarkup([])
    )


async def send_translated_file(update: Update, state: UserState, translated_file_path: str):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""
    try:
        file_path = Path(translated_file_path)
        
        if not file_path.exists():
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–µ—Ä–µ–∑ –∫–∞–∫–æ–π –º–µ—Ç–æ–¥ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
            if hasattr(update, 'edit_message_text'):
                # –≠—Ç–æ CallbackQuery
                await update.edit_message_text("‚ùå –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            else:
                # –≠—Ç–æ –æ–±—ã—á–Ω—ã–π Update
                await update.message.reply_text("‚ùå –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ Telegram - 50MB)
        file_size = file_path.stat().st_size
        if file_size > 50 * 1024 * 1024:  # 50 MB
            error_msg = (f"‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({file_size / 1024 / 1024:.1f} MB). "
                        f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è Telegram: 50 MB")
            
            if hasattr(update, 'edit_message_text'):
                await update.edit_message_text(error_msg)
            else:
                await update.message.reply_text(error_msg)
            return
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—ä–µ–∫—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–∞
        if hasattr(update, 'message') and update.message:
            # CallbackQuery —Å message
            message_obj = update.message
        elif hasattr(update, 'callback_query') and update.callback_query and update.callback_query.message:
            # Update —Å callback_query
            message_obj = update.callback_query.message
        else:
            # –ü—Ä—è–º–æ–π Update
            message_obj = update.message
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª
        with open(file_path, 'rb') as f:
            await message_obj.reply_document(
                document=f,
                filename=file_path.name,
                caption=f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω!\n"
                       f"üìÑ –§–∞–π–ª: {file_path.name}\n"
                       f"üìä –†–∞–∑–º–µ—Ä: {file_size / 1024:.1f} KB\n"
                       f"üéØ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ —Å –ø–æ–º–æ—â—å—é TransGemini"
            )
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_id = update.effective_user.id if hasattr(update, 'effective_user') else update.from_user.id
        reset_user_state(user_id)
        
        logger.info(f"‚úÖ –§–∞–π–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {file_path.name}")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–∞: {e}", exc_info=True)
        
        error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞: {str(e)}"
        
        try:
            if hasattr(update, 'edit_message_text'):
                await update.edit_message_text(error_msg)
            elif hasattr(update, 'callback_query') and update.callback_query.message:
                await update.callback_query.message.reply_text(error_msg)
            else:
                await update.message.reply_text(error_msg)
        except Exception as send_error:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ: {send_error}")


def load_env_file():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞"""
    env_path = Path('.env')
    if env_path.exists():
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞"""
    print("ü§ñ –ó–∞–ø—É—Å–∫ Telegram –±–æ—Ç–∞ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞ —Ñ–∞–π–ª–æ–≤")
    print("üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç TransGemini.py –¥–ª—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º .env —Ñ–∞–π–ª –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    load_env_file()
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –±–æ—Ç–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
    
    if not bot_token:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω —Ç–æ–∫–µ–Ω –±–æ—Ç–∞!")
        print("–°–æ–∑–¥–∞–π—Ç–µ –±–æ—Ç–∞ —á–µ—Ä–µ–∑ @BotFather –≤ Telegram –∏ –ø–æ–ª—É—á–∏—Ç–µ —Ç–æ–∫–µ–Ω")
        print("=" * 40)
        
        # –ü–æ–ø—Ä–æ—Å–∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤–≤–µ—Å—Ç–∏ —Ç–æ–∫–µ–Ω
        bot_token = input("–í–≤–µ–¥–∏—Ç–µ —Ç–æ–∫–µ–Ω –±–æ—Ç–∞: ").strip()
        if not bot_token:
            print("–¢–æ–∫–µ–Ω –Ω–µ –≤–≤–µ–¥–µ–Ω. –í—ã—Ö–æ–¥.")
            sys.exit(1)
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    application = Application.builder().token(bot_token).build()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("cancel", cancel_command))
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è API –∫–ª—é—á–∞–º–∏
    application.add_handler(CommandHandler("apikeys", handle_apikeys_command))
    application.add_handler(CommandHandler("addkey", handle_addkey_command))
    application.add_handler(CommandHandler("removekey", handle_removekey_command))
    application.add_handler(CommandHandler("clearkeys", handle_clearkeys_command))
    application.add_handler(CommandHandler("rotation", handle_rotation_command))
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã –Ω–∞—Å—Ç—Ä–æ–µ–∫
    application.add_handler(CommandHandler("settings", handle_settings_command))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ–∞–π–ª–æ–≤
    application.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ API –∫–ª—é—á–∞ –∏ –≤–≤–æ–¥–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≥–ª–∞–≤ (—Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è)
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_input))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ callback –∫–Ω–æ–ø–æ–∫
    application.add_handler(CallbackQueryHandler(handle_format_selection, pattern=r"^action_"))
    application.add_handler(CallbackQueryHandler(handle_output_format_selection, pattern=r"^(format_.*|back_to_action_selection)$"))
    application.add_handler(CallbackQueryHandler(handle_chapter_selection, pattern=r"^(chapters_|skip_chapters|back_to_chapter_selection|show_all_chapters|setup_glossary_from_chapter_selection)"))
    application.add_handler(CallbackQueryHandler(handle_chapter_range_selection, pattern=r"^(range_|back_to_chapters)"))
    application.add_handler(CallbackQueryHandler(handle_translation_options, pattern=r"^(lang_|select_model$|model_|back_to_translation_options$|start_translation$)"))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è –≥–ª–æ—Å—Å–∞—Ä–∏—è
    application.add_handler(CallbackQueryHandler(handle_glossary_model_selection, pattern=r"^glossary_model_"))
    application.add_handler(CallbackQueryHandler(handle_glossary_options, pattern=r"^(start_glossary_creation|change_glossary_model|back_to_action_selection)$"))
    
    # –ù–æ–≤—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ callback –∫–Ω–æ–ø–æ–∫ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
    application.add_handler(CallbackQueryHandler(handle_keys_callback, pattern=r"^(confirm_clear_keys|cancel_clear_keys)"))
    application.add_handler(CallbackQueryHandler(handle_settings_callback, pattern=r"^(settings_|set_model_|set_temp_|toggle_rotation|set_custom_prompt|reset_prompt|upload_glossary|remove_glossary|set_proxy|reset_proxy)"))
    
    print(f"‚úÖ –ë–æ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω —Å —Ç–æ–∫–µ–Ω–æ–º: {bot_token[:10]}...")
    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.")
    print("üéØ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –±–æ—Ç—É —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ–≤–æ–¥–∞!")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()
